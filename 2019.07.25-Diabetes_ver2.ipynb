{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# 수치미분 함수\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad\n",
    "\n",
    "# sigmoid 함수\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes Class\n",
    "\n",
    "class Diabetes:\n",
    "    \n",
    "    # 생성자\n",
    "    # xdata, tdata => numpy.array(...)\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        \n",
    "        # 2층 hidden layer unit \n",
    "        # 가중치 W, 바이어스 b 초기화\n",
    "        self.W2 = np.random.rand(input_nodes, hidden_nodes)  \n",
    "        self.b2 = np.random.rand(hidden_nodes)\n",
    "        \n",
    "        # 3층 output layer unit : 1 개 \n",
    "        self.W3 = np.random.rand(hidden_nodes,output_nodes)\n",
    "        self.b3 = np.random.rand(output_nodes)\n",
    "                        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        print(\"Diabetes object is created !!!\")\n",
    "        \n",
    "    # 손실함수\n",
    "    def feed_forward(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z1 = np.dot(self.input_data, self.W2) + self.b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.W3) + self.b3\n",
    "        y = sigmoid(z2)\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # obtain W and b\n",
    "    def get_W_b(self):\n",
    "        \n",
    "        return self.W2,  self.b2, self.W3, self.b3\n",
    "    \n",
    "    # 손실 값 계산\n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z1 = np.dot(self.input_data, self.W2) + self.b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.W3) + self.b3\n",
    "        y = sigmoid(z2)\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.target_data*np.log(y + delta) + (1-self.target_data)*np.log((1 - y)+delta ) )\n",
    "    \n",
    "    # query, 즉 미래 값 예측 함수\n",
    "    def predict(self, input_data):    \n",
    "        \n",
    "        z1 = np.dot(input_data, self.W2) + self.b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.W3) + self.b3\n",
    "        y = sigmoid(z2)\n",
    "    \n",
    "        if y >= 0.5:\n",
    "            result = 1  # True\n",
    "        else:\n",
    "            result = 0  # False\n",
    "    \n",
    "        return y, result\n",
    "\n",
    "    # accuracy method 1\n",
    "    def accuracy1(self, input_data, target_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        index_label_prediction_list = []\n",
    "        \n",
    "        for index in range(len(input_data)):\n",
    "            \n",
    "            (real_val, logical_val) = self.predict(input_data[index])\n",
    "            \n",
    "            if logical_val == target_data[index]:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "            index_label_prediction_list.append([index,target_data[index],logical_val])    \n",
    "            \n",
    "        accuracy_result = len(matched_list) / len(input_data)\n",
    "        \n",
    "        print(\"Accuracy => \", accuracy_result)\n",
    "        \n",
    "        return matched_list, not_matched_list, index_label_prediction_list\n",
    "    \n",
    "    # accuracy method 2\n",
    "    def accuracy2(self, test_data):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "                \n",
    "        input_data = test_data[ :, 0:-1 ]\n",
    "        target_data = test_data[ :, -1 ]\n",
    "        \n",
    "        for index in range(len(input_data)):\n",
    "            \n",
    "            (real_val, logical_val) = self.predict(input_data[index])\n",
    "            \n",
    "            if logical_val == target_data[index]:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "        accuracy_result = len(matched_list) / len(input_data)\n",
    "        \n",
    "        print(\"Accuracy => \", accuracy_result)\n",
    "        \n",
    "        return matched_list, not_matched_list\n",
    "    \n",
    "        \n",
    "    # 수치미분을 이용하여 손실함수가 최소가 될때 까지 학습하는 함수\n",
    "    def train(self, input_data, target_data):\n",
    "        \n",
    "        self.input_data = input_data\n",
    "        self.target_data = target_data\n",
    "        \n",
    "        f = lambda x : self.feed_forward()\n",
    "        \n",
    "        self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\n",
    "    \n",
    "        self.b2 -= self.learning_rate * numerical_derivative(f, self.b2)\n",
    "        \n",
    "        self.W3 -= self.learning_rate * numerical_derivative(f, self.W3)\n",
    "    \n",
    "        self.b3 -= self.learning_rate * numerical_derivative(f, self.b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = np.loadtxt('./diabetes (1).csv',delimiter=',')\n",
    "\n",
    "total_xdata = load_data[:,0:-1]\n",
    "total_tdata = load_data[:,[-1]]\n",
    "# training data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531.3\n",
      "x_data.ndim =  2 , x_data.shape =  (531, 8)\n",
      "t_data.ndim =  2 , t_data.shape =  (531, 1)\n",
      "test_x_data.ndim =  2 , test_x_data.shape =  (228, 8)\n",
      "test_t_data.ndim =  2 , test_t_data.shape =  (228, 1)\n"
     ]
    }
   ],
   "source": [
    "print(load_data.shape[0] * 0.7)\n",
    "x_data = load_data[:int(load_data.shape[0]*0.7),0:-1]\n",
    "t_data = load_data[:int(load_data.shape[0]*0.7),[-1]]\n",
    "test_x_data = load_data[int(load_data.shape[0]*0.7):,0:-1]\n",
    "test_t_data = load_data[int(load_data.shape[0]*0.7):,[-1]]\n",
    "test_data = load_data[int(load_data.shape[0]*0.7):,:]\n",
    "training_data = load_data[:int(load_data.shape[0]*0.7),:]\n",
    "print(\"x_data.ndim = \", x_data.ndim,\", x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.ndim = \", t_data.ndim,\", t_data.shape = \", t_data.shape)\n",
    "print(\"test_x_data.ndim = \", test_x_data.ndim,\", test_x_data.shape = \", test_x_data.shape)\n",
    "print(\"test_t_data.ndim = \", test_t_data.ndim,\", test_t_data.shape = \", test_t_data.shape)\n",
    "np.savetxt('./test_data.csv',test_data,delimiter = ',')\n",
    "np.savetxt('./training_data.csv',training_data,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes object is created !!!\n",
      "Neural Network Learning using Numerical Derivative...\n",
      "epochs =  0 loss value =  0.3357524534402149\n",
      "epochs =  5 loss value =  0.40544235781644444\n",
      "epochs =  10 loss value =  0.43032354768482955\n",
      "epochs =  15 loss value =  0.47498453881436226\n",
      "epochs =  20 loss value =  0.5385274105277263\n",
      "epochs =  25 loss value =  0.6077835890681008\n",
      "epochs =  30 loss value =  0.6691096353507288\n",
      "epochs =  35 loss value =  0.7157947753028845\n",
      "epochs =  40 loss value =  0.7476593902548853\n",
      "epochs =  45 loss value =  0.7676304916633545\n",
      "\n",
      "Elapsed Time =>  0:01:31.504595\n"
     ]
    }
   ],
   "source": [
    "# training data \n",
    "training_data = np.loadtxt('./training_data.csv', delimiter=',',dtype = np.float32)\n",
    "#print(\"training_data = \", training_data.shape)\n",
    "\n",
    "#hyper-parameter\n",
    "i_nodes = 8    # input nodes 개수\n",
    "h1_nodes = 10  # hidden nodes 개수\n",
    "o_nodes = 1    # output nodes 개수\n",
    "lr = 1e-2      # learning rate\n",
    "epochs = 50   # 반복횟수\n",
    "\n",
    "# Diabetes 객체 생성\n",
    "obj = Diabetes(i_nodes, h1_nodes, o_nodes, lr)\n",
    "\n",
    "print(\"Neural Network Learning using Numerical Derivative...\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in range(epochs):\n",
    "    \n",
    "    for index in range(len(training_data)):\n",
    "        \n",
    "        input_data = training_data[index, 0:-1]\n",
    "        target_data = training_data[index, [-1]]\n",
    "        \n",
    "        obj.train(input_data, target_data)\n",
    "        \n",
    "    if (step % 5 == 0):\n",
    "        print(\"epochs = \", step, \"loss value = \", obj.loss_val())\n",
    "\n",
    "end_time = datetime.now()\n",
    "        \n",
    "print(\"\")\n",
    "print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data.shape =  (228, 9)\n",
      "Accuracy =>  0.7719298245614035\n",
      "Accuracy =>  0.7719298245614035\n"
     ]
    }
   ],
   "source": [
    "test_data = np.loadtxt('./test_data.csv', delimiter=',')\n",
    "print(\"test_data.shape = \", test_data.shape)\n",
    "\n",
    "test_input_data = test_data[ :, 0:-1 ]\n",
    "test_target_data = test_data[ :, -1 ]\n",
    "\n",
    "(true_list, false_list, index_label_prediction_list) = obj.accuracy1(test_input_data, test_target_data)\n",
    "\n",
    "(true_list, false_list) = obj.accuracy2(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0.0, 1], [1, 0.0, 1], [2, 0.0, 1], [3, 0.0, 1], [4, 1.0, 1], [5, 1.0, 1], [6, 0.0, 0], [7, 0.0, 0], [8, 1.0, 1], [9, 1.0, 1], [10, 1.0, 0], [11, 1.0, 1], [12, 1.0, 1], [13, 1.0, 1], [14, 1.0, 1], [15, 1.0, 1], [16, 1.0, 1], [17, 1.0, 1], [18, 1.0, 1], [19, 1.0, 1], [20, 1.0, 1], [21, 0.0, 1], [22, 0.0, 0], [23, 1.0, 1], [24, 1.0, 1], [25, 1.0, 1], [26, 1.0, 1], [27, 1.0, 1], [28, 1.0, 1], [29, 1.0, 1], [30, 0.0, 1], [31, 1.0, 1], [32, 1.0, 1], [33, 1.0, 1], [34, 1.0, 1], [35, 1.0, 1], [36, 1.0, 1], [37, 1.0, 1], [38, 0.0, 1], [39, 1.0, 1], [40, 0.0, 0], [41, 0.0, 0], [42, 1.0, 1], [43, 1.0, 1], [44, 1.0, 1], [45, 0.0, 1], [46, 1.0, 1], [47, 0.0, 1], [48, 1.0, 1], [49, 0.0, 0], [50, 1.0, 1], [51, 0.0, 0], [52, 1.0, 1], [53, 0.0, 1], [54, 1.0, 1], [55, 1.0, 1], [56, 0.0, 0], [57, 1.0, 1], [58, 1.0, 1], [59, 0.0, 0], [60, 1.0, 1], [61, 1.0, 1], [62, 1.0, 1], [63, 1.0, 1], [64, 0.0, 0], [65, 0.0, 0], [66, 1.0, 1], [67, 0.0, 0], [68, 1.0, 1], [69, 1.0, 0], [70, 1.0, 1], [71, 1.0, 1], [72, 0.0, 0], [73, 0.0, 0], [74, 1.0, 1], [75, 0.0, 1], [76, 1.0, 1], [77, 1.0, 1], [78, 1.0, 1], [79, 0.0, 1], [80, 0.0, 1], [81, 1.0, 1], [82, 1.0, 1], [83, 1.0, 0], [84, 1.0, 1], [85, 1.0, 1], [86, 1.0, 1], [87, 1.0, 1], [88, 1.0, 1], [89, 1.0, 1], [90, 1.0, 1], [91, 0.0, 1], [92, 1.0, 1], [93, 1.0, 1], [94, 1.0, 1], [95, 1.0, 1], [96, 0.0, 1], [97, 1.0, 1], [98, 1.0, 1], [99, 0.0, 1], [100, 1.0, 1], [101, 1.0, 1], [102, 1.0, 1], [103, 0.0, 1], [104, 1.0, 1], [105, 1.0, 1], [106, 1.0, 0], [107, 0.0, 1], [108, 0.0, 0], [109, 0.0, 1], [110, 1.0, 1], [111, 1.0, 1], [112, 1.0, 1], [113, 1.0, 1], [114, 1.0, 1], [115, 1.0, 1], [116, 0.0, 1], [117, 1.0, 1], [118, 1.0, 1], [119, 0.0, 1], [120, 1.0, 0], [121, 0.0, 0], [122, 0.0, 0], [123, 0.0, 0], [124, 0.0, 1], [125, 1.0, 1], [126, 0.0, 1], [127, 0.0, 1], [128, 1.0, 1], [129, 1.0, 1], [130, 1.0, 0], [131, 1.0, 1], [132, 1.0, 1], [133, 1.0, 0], [134, 1.0, 1], [135, 0.0, 0], [136, 0.0, 0], [137, 1.0, 1], [138, 0.0, 1], [139, 1.0, 1], [140, 1.0, 1], [141, 0.0, 0], [142, 1.0, 1], [143, 0.0, 1], [144, 1.0, 1], [145, 1.0, 1], [146, 1.0, 1], [147, 1.0, 1], [148, 1.0, 1], [149, 0.0, 0], [150, 1.0, 1], [151, 0.0, 0], [152, 1.0, 1], [153, 0.0, 1], [154, 1.0, 1], [155, 0.0, 1], [156, 0.0, 1], [157, 1.0, 1], [158, 1.0, 1], [159, 1.0, 0], [160, 1.0, 1], [161, 0.0, 1], [162, 0.0, 0], [163, 1.0, 1], [164, 1.0, 1], [165, 1.0, 1], [166, 0.0, 1], [167, 1.0, 1], [168, 0.0, 0], [169, 0.0, 1], [170, 1.0, 1], [171, 1.0, 1], [172, 0.0, 0], [173, 1.0, 1], [174, 1.0, 1], [175, 0.0, 0], [176, 0.0, 0], [177, 1.0, 1], [178, 1.0, 1], [179, 0.0, 1], [180, 1.0, 1], [181, 1.0, 1], [182, 0.0, 1], [183, 1.0, 1], [184, 1.0, 1], [185, 1.0, 1], [186, 1.0, 1], [187, 1.0, 0], [188, 1.0, 0], [189, 1.0, 1], [190, 0.0, 1], [191, 0.0, 1], [192, 0.0, 0], [193, 1.0, 1], [194, 1.0, 1], [195, 1.0, 1], [196, 1.0, 1], [197, 1.0, 1], [198, 1.0, 1], [199, 0.0, 1], [200, 0.0, 0], [201, 1.0, 1], [202, 1.0, 1], [203, 0.0, 0], [204, 1.0, 0], [205, 1.0, 1], [206, 0.0, 0], [207, 1.0, 1], [208, 0.0, 0], [209, 0.0, 1], [210, 0.0, 0], [211, 1.0, 1], [212, 1.0, 1], [213, 0.0, 0], [214, 0.0, 0], [215, 0.0, 1], [216, 1.0, 1], [217, 0.0, 1], [218, 1.0, 1], [219, 0.0, 0], [220, 1.0, 1], [221, 0.0, 0], [222, 1.0, 1], [223, 1.0, 1], [224, 1.0, 1], [225, 1.0, 1], [226, 0.0, 1], [227, 1.0, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
