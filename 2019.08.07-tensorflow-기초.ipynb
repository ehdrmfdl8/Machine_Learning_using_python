{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "!cat /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python 3.6.9 :: Anaconda, Inc.\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로를 이용한 프로그램 작성 시,\n",
    "### 1. 상수, 변수, 텐서연산 등의 노드와 엣지를 먼저 정의하고,\n",
    "### 2. 세션을 만들고 그 세션을 통해 노드간의 데이터(텐서) 연산 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상수 노드 - tf.constant()\n",
    "상수 노드 정의 , 한번정하면 바꿀수가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a_4:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add_13:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_4:0\", shape=(2, 2), dtype=float32)\n",
      "a, b =  [1.0, 2.0]\n",
      "c =  [[1. 2.]\n",
      " [3. 4.]]\n",
      "a + b =  [3.0]\n",
      "c + 1 [[2. 3.]\n",
      " [4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#상수값을 저장하는 노드를 만들기 위해서 상수 노드 tf.constant 정의\n",
    "a = tf.constant(1.0, name = 'a')\n",
    "b = tf.constant(2.0, name = 'b')\n",
    "c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "#세션을 만들지 않고 print 와 같은 명령문을 실행하면, 저장된 값이 아닌\n",
    "#현재 정의 되어 있는 노드의 상태(노드타입, shape 등) 출력됨\n",
    "print(a)\n",
    "print(a+b)\n",
    "print(c)\n",
    "#노드간의 연산을 위해 세션 생성\n",
    "sess = tf.Session()\n",
    "#세션을 통해(sess.run()) 노드에 값이 할당되고 노드간의 텐서를 흘려보내면서\n",
    "#tensor flow 연산과 명령문 등이 실행됨\n",
    "print(\"a, b = \", sess.run([a,b]))\n",
    "print(\"c = \",sess.run(c))\n",
    "print(\"a + b = \",sess.run([a+b]))\n",
    "print(\"c + 1\",sess.run(c+1.0))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수노드 - tf.Varialbe()\n",
    "가중치나 바이어스처럼 계속 업데이트되는 변수는 텐서플로에서 변수 노드로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 , W1 =  [0.77462286] , b1 =  [-0.9277637]\n",
      "step =  0 , W2 =  [[0.64589316 1.508661  ]] , b2 =  [[0.1469841 0.7898316]]\n",
      "step =  1 , W1 =  [-0.22537714] , b1 =  [-1.9277637]\n",
      "step =  1 , W2 =  [[-0.35410684  0.50866103]] , b2 =  [[-0.8530159  -0.21016842]]\n",
      "step =  2 , W1 =  [-2.225377] , b1 =  [-3.9277637]\n",
      "step =  2 , W2 =  [[-2.354107 -1.491339]] , b2 =  [[-2.853016  -2.2101684]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# random_uniform 특정 구간에서 랜덤값을 리턴해준다.\n",
    "W1 = tf.Variable(tf.random_normal([1]))  #가우시안 분포를 리턴해준다.\n",
    "b1 = tf.Variable(tf.random_normal([1]))  # b1 = np.random.rand(1) 과 비슷함\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([1,2])) \n",
    "b2 = tf.Variable(tf.random_normal([1,2]))\n",
    "#세션 생성\n",
    "sess = tf.Session()\n",
    "#변수노드 값 초기화를 위해서 반드시 실행\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(3):\n",
    "    W1 = W1 - step\n",
    "    b1 = b1 - step\n",
    "    \n",
    "    W2 = W2 - step\n",
    "    b2 = b2 - step\n",
    "    \n",
    "    print(\"step = \", step, \", W1 = \", sess.run(W1), \", b1 = \", sess.run(b1))\n",
    "    print(\"step = \", step, \", W2 = \", sess.run(W2), \", b2 = \", sess.run(b2))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 플레이스홀더 노드 - tf.placeholder\n",
    "플레이스 홀더 노드는 머신러닝/딥러닝에서 입력데이터(input), 정답데이터(targer)를 넣어주기 위한 용도로 주로 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "[4. 6.]\n",
      "400.0\n",
      "[400. 600.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#플레이스홀더 노드 정의\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "c = a + b\n",
    "\n",
    "sess = tf.Session()\n",
    "#플레이스홀더 노드에 실제 값을 넣어줄때는 sess.run 첫번째 인자로 실행하고자 하는 연산을 넣어주고,\n",
    "#두번째 인자에는 실제로 넣을 값들을 Dictionary형태로 넣어주는 feed_dict을 선언하고,feed_dict부분에\n",
    "#플레이스홀더에 넣을 값을 지정해줌.\n",
    "print(sess.run(c, feed_dict = {a: 1.0, b: 3.0}))\n",
    "print(sess.run(c, feed_dict = {a: [1.0, 2.0], b: [3.0, 4.0]}))\n",
    "\n",
    "d = 100 * c\n",
    "\n",
    "print(sess.run(d, feed_dict={a: 1.0, b: 3.0}))\n",
    "print(sess.run(d, feed_dict={a: [1.0,2.0], b: [3.0,4.0]}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression (multi-variable example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (25, 3)\n",
      "t_data.shape =  (25, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "loaded_data = np.loadtxt('./data-01.csv', delimiter = ',')\n",
    "\n",
    "x_data = loaded_data[ :, 0:-1]\n",
    "t_data = loaded_data[ :, [-1]]\n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치 노드 W, 바이어스 노드 b를 정의하고 feed_dict을 통해 데이터를 넣어주기 위해서 입력데이터 노드와 정답데이터 노드를 정의함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([3,1]))\n",
    "b = tf.Variable(tf.random_normal([1]))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None,3])\n",
    "T = tf.placeholder(tf.float32, [None,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 현재의 X,W,b를 바탕으로 선형회귀 값 y를 계산하고, y와 정답 T를 이용하여 손실함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.matmul(X, W) + b\n",
    "loss = tf.reduce_mean(tf.square(y - T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치 W, 바이어스 b를 최적화 하기 위해서 경사하강법(Gradient Descent Algorithm)을 적용한 optimizer 정의함 이처럼 TensorFlow는 다양한 optimizer를 적용하여 손실함수를 최소화 하고, 최종적으로 W,b를 최적화 시킴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 노드 / 연산 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 , loss_val =  69650.984\n",
      "step =  400 , loss_val =  69.80117\n",
      "step =  800 , loss_val =  52.150166\n",
      "step =  1200 , loss_val =  39.528126\n",
      "step =  1600 , loss_val =  30.475906\n",
      "step =  2000 , loss_val =  23.962696\n",
      "step =  2400 , loss_val =  19.25942\n",
      "step =  2800 , loss_val =  15.849609\n",
      "step =  3200 , loss_val =  13.36681\n",
      "step =  3600 , loss_val =  11.5505295\n",
      "step =  4000 , loss_val =  10.215109\n",
      "step =  4400 , loss_val =  9.228001\n",
      "step =  4800 , loss_val =  8.494263\n",
      "step =  5200 , loss_val =  7.945661\n",
      "step =  5600 , loss_val =  7.533046\n",
      "step =  6000 , loss_val =  7.220804\n",
      "step =  6400 , loss_val =  6.983103\n",
      "step =  6800 , loss_val =  6.801017\n",
      "step =  7200 , loss_val =  6.6607203\n",
      "step =  7600 , loss_val =  6.55201\n",
      "step =  8000 , loss_val =  6.4673157\n",
      "\n",
      "prediction is  [[180.93687]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(8001):\n",
    "        # _ 하나만 사용하면 쓸모없는 데이타로 정의한다.\n",
    "        loss_val, y_val, _ = sess.run([loss, y, train], feed_dict = {X: x_data, T: t_data})  \n",
    "        \n",
    "        if step % 400 == 0:\n",
    "            print(\"step = \", step, \", loss_val = \", loss_val)\n",
    "    \n",
    "    print(\"\\nprediction is \", sess.run(y, feed_dict= {X: [[100, 98, 81] ]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
