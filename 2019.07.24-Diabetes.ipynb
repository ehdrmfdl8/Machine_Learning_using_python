{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes class 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class Diabetes:\n",
    "    def __init__(self,name,xdata,tdata,i_node,h1_node,o_node,learning_rate,iteration_count):\n",
    "        self.name = name\n",
    "        self.xdata = xdata\n",
    "        if xdata.ndim == 1:\n",
    "            self.xdata = xdata.reshape(-1,1)\n",
    "            self.tdata = tdata.reshape(-1,1)\n",
    "        elif xdata.ndim == 2:\n",
    "            self.xdata = xdata\n",
    "            self.tdata = tdata.reshape(-1,1)\n",
    "        self.i_node = i_node\n",
    "        self.h1_node = h1_node\n",
    "        self.o_node = o_node\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iteration_count = iteration_count\n",
    "        \n",
    "        self.W2 = np.random.rand(self.i_node,self.h1_node)\n",
    "        self.b2 = np.random.rand(self.h1_node)\n",
    "        \n",
    "        self.W3 = np.random.rand(self.h1_node,self.o_node)\n",
    "        self.b3 = np.random.rand(self.o_node)\n",
    "    \n",
    "    def loss_func(self):\n",
    "        delta = 1e-7\n",
    "        \n",
    "        z2 = np.dot(self.xdata, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2,self.W3) + self.b3\n",
    "        y = a3 = sigmoid(z3) \n",
    "        \n",
    "        return -np.sum(self.tdata * np.log(y + delta) + (1 - self.tdata) * np.log((1 - y) + delta))\n",
    "    \n",
    "    def predict(self,test_xdata):\n",
    "        z2 = np.dot(test_xdata, self.W2) + self.b2\n",
    "        a2 = sigmoid(z2)\n",
    "        \n",
    "        z3 = np.dot(a2,self.W3) + self.b3\n",
    "        y = a3 = sigmoid(z3)\n",
    "        \n",
    "        if y >= 0.5:\n",
    "            result = 1\n",
    "        else:\n",
    "            result = 0\n",
    "        \n",
    "        return y, result\n",
    "    \n",
    "    def accuracy(self,test_xdata,test_tdata):\n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        index_label_prediction_list = []\n",
    "        for index in range(len(test_xdata)):\n",
    "            (real_val, logical_val) = self.predict(test_xdata[index])\n",
    "            if logical_val == test_tdata[index]:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "            index_label_prediction_list.append([index,test_tdata[index][0],logical_val])\n",
    "\n",
    "        print(\"accuracy => \", len(matched_list) / len(test_xdata))\n",
    "        return matched_list, not_matched_list, index_label_prediction_list\n",
    "    \n",
    "    def train(self):\n",
    "        f = lambda x : self.loss_func()\n",
    "        strat_time = datetime.now()\n",
    "        for step in range(self.iteration_count):\n",
    "            self.W2 -= self.learning_rate * numerical_derivative(f,self.W2)\n",
    "            self.b2 -= self.learning_rate * numerical_derivative(f,self.b2)\n",
    "            \n",
    "            self.W3 -= self.learning_rate * numerical_derivative(f,self.W3)\n",
    "            self.b3 -= self.learning_rate * numerical_derivative(f,self.b3)\n",
    "            \n",
    "            if (step % 400) == 0:\n",
    "                print(\"step = \", step, \"error_val = \", self.loss_func())\n",
    "        end_time = datetime.now()\n",
    "        print(\"\")\n",
    "        print(\"elasped time: \", end_time - strat_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.ndim =  2 , x_data.shape =  (500, 8)\n",
      "t_data.ndim =  2 , t_data.shape =  (500, 1)\n"
     ]
    }
   ],
   "source": [
    "load_data = np.loadtxt('./diabetes (1).csv',delimiter=',', dtype = np.float32)\n",
    "x_data = load_data[0:500,0:-1]\n",
    "t_data = load_data[0:500,[-1]]\n",
    "\n",
    "test_x_data = load_data[501:,0:-1]\n",
    "test_t_data = load_data[501:,[-1]].reshape(-1,1)\n",
    "\n",
    "#데이터 차원 및 shape 확인\n",
    "print(\"x_data.ndim = \", x_data.ndim,\", x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.ndim = \", t_data.ndim,\", t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 error_val =  341.01968111273607\n",
      "step =  400 error_val =  251.27160499357288\n",
      "step =  800 error_val =  245.64925105179938\n",
      "step =  1200 error_val =  244.43623719395242\n",
      "step =  1600 error_val =  243.73477151324545\n",
      "step =  2000 error_val =  243.17441109237794\n",
      "step =  2400 error_val =  242.67169377638385\n",
      "step =  2800 error_val =  242.19142379831072\n",
      "step =  3200 error_val =  241.69005994980267\n",
      "step =  3600 error_val =  241.10705177665017\n",
      "step =  4000 error_val =  240.39944434293272\n",
      "step =  4400 error_val =  239.60660072459217\n",
      "step =  4800 error_val =  238.82828454112934\n",
      "step =  5200 error_val =  238.13430731151107\n",
      "step =  5600 error_val =  237.52864926579997\n",
      "step =  6000 error_val =  236.97319358217442\n",
      "step =  6400 error_val =  236.4209562512928\n",
      "step =  6800 error_val =  235.83434381950735\n",
      "step =  7200 error_val =  235.19262304141495\n",
      "step =  7600 error_val =  234.49595806719498\n",
      "step =  8000 error_val =  233.76831009444282\n",
      "step =  8400 error_val =  233.05803687739905\n",
      "step =  8800 error_val =  232.4285094428614\n",
      "step =  9200 error_val =  231.93134755479446\n",
      "step =  9600 error_val =  231.5801712824025\n",
      "step =  10000 error_val =  231.3526722682927\n",
      "\n",
      "elasped time:  0:00:22.715209\n"
     ]
    }
   ],
   "source": [
    "i_node = x_data.shape[1]\n",
    "h1_node = 2\n",
    "o_node = t_data.shape[1]\n",
    "\n",
    "lr = 1e-3\n",
    "iter_count = 10001\n",
    "\n",
    "obj = Diabetes(\"Diabetes\",x_data,t_data,i_node,h1_node,o_node,lr,iter_count)\n",
    "obj.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =>  0.8255813953488372\n",
      "[[0, 1.0, 1], [1, 1.0, 1], [2, 0.0, 1], [3, 1.0, 1], [4, 1.0, 1], [5, 1.0, 1], [6, 1.0, 1], [7, 0.0, 0], [8, 0.0, 0], [9, 1.0, 1], [10, 1.0, 1], [11, 1.0, 1], [12, 1.0, 1], [13, 1.0, 1], [14, 0.0, 0], [15, 1.0, 1], [16, 1.0, 1], [17, 1.0, 1], [18, 1.0, 1], [19, 1.0, 1], [20, 1.0, 1], [21, 1.0, 1], [22, 1.0, 1], [23, 1.0, 1], [24, 1.0, 1], [25, 1.0, 1], [26, 0.0, 1], [27, 1.0, 1], [28, 1.0, 1], [29, 1.0, 1], [30, 0.0, 0], [31, 0.0, 1], [32, 0.0, 1], [33, 0.0, 1], [34, 1.0, 1], [35, 1.0, 1], [36, 0.0, 0], [37, 0.0, 0], [38, 1.0, 1], [39, 1.0, 0], [40, 1.0, 0], [41, 1.0, 1], [42, 1.0, 1], [43, 1.0, 1], [44, 1.0, 1], [45, 1.0, 1], [46, 1.0, 1], [47, 1.0, 1], [48, 1.0, 1], [49, 1.0, 0], [50, 1.0, 1], [51, 0.0, 1], [52, 0.0, 0], [53, 1.0, 1], [54, 1.0, 1], [55, 1.0, 1], [56, 1.0, 1], [57, 1.0, 1], [58, 1.0, 1], [59, 1.0, 0], [60, 0.0, 1], [61, 1.0, 1], [62, 1.0, 1], [63, 1.0, 1], [64, 1.0, 1], [65, 1.0, 1], [66, 1.0, 1], [67, 1.0, 1], [68, 0.0, 0], [69, 1.0, 0], [70, 0.0, 0], [71, 0.0, 0], [72, 1.0, 1], [73, 1.0, 1], [74, 1.0, 1], [75, 0.0, 0], [76, 1.0, 1], [77, 0.0, 0], [78, 1.0, 1], [79, 0.0, 0], [80, 1.0, 1], [81, 0.0, 0], [82, 1.0, 1], [83, 0.0, 0], [84, 1.0, 1], [85, 1.0, 0], [86, 0.0, 0], [87, 1.0, 1], [88, 1.0, 1], [89, 0.0, 0], [90, 1.0, 1], [91, 1.0, 1], [92, 1.0, 1], [93, 1.0, 1], [94, 0.0, 0], [95, 0.0, 0], [96, 1.0, 1], [97, 0.0, 0], [98, 1.0, 1], [99, 1.0, 0], [100, 1.0, 1], [101, 1.0, 1], [102, 0.0, 0], [103, 0.0, 0], [104, 1.0, 1], [105, 0.0, 0], [106, 1.0, 1], [107, 1.0, 1], [108, 1.0, 1], [109, 0.0, 0], [110, 0.0, 1], [111, 1.0, 1], [112, 1.0, 1], [113, 1.0, 0], [114, 1.0, 1], [115, 1.0, 1], [116, 1.0, 1], [117, 1.0, 1], [118, 1.0, 0], [119, 1.0, 0], [120, 1.0, 1], [121, 0.0, 0], [122, 1.0, 1], [123, 1.0, 1], [124, 1.0, 1], [125, 1.0, 1], [126, 0.0, 0], [127, 1.0, 1], [128, 1.0, 1], [129, 0.0, 0], [130, 1.0, 1], [131, 1.0, 1], [132, 1.0, 1], [133, 0.0, 0], [134, 1.0, 1], [135, 1.0, 1], [136, 1.0, 0], [137, 0.0, 0], [138, 0.0, 0], [139, 0.0, 0], [140, 1.0, 1], [141, 1.0, 1], [142, 1.0, 1], [143, 1.0, 1], [144, 1.0, 1], [145, 1.0, 1], [146, 0.0, 0], [147, 1.0, 1], [148, 1.0, 0], [149, 0.0, 1], [150, 1.0, 0], [151, 0.0, 0], [152, 0.0, 0], [153, 0.0, 0], [154, 0.0, 1], [155, 1.0, 1], [156, 0.0, 1], [157, 0.0, 1], [158, 1.0, 1], [159, 1.0, 0], [160, 1.0, 0], [161, 1.0, 1], [162, 1.0, 1], [163, 1.0, 1], [164, 1.0, 1], [165, 0.0, 0], [166, 0.0, 0], [167, 1.0, 1], [168, 0.0, 1], [169, 1.0, 1], [170, 1.0, 1], [171, 0.0, 0], [172, 1.0, 1], [173, 0.0, 1], [174, 1.0, 1], [175, 1.0, 1], [176, 1.0, 1], [177, 1.0, 1], [178, 1.0, 1], [179, 0.0, 0], [180, 1.0, 1], [181, 0.0, 0], [182, 1.0, 1], [183, 0.0, 0], [184, 1.0, 1], [185, 0.0, 0], [186, 0.0, 0], [187, 1.0, 1], [188, 1.0, 1], [189, 1.0, 0], [190, 1.0, 1], [191, 0.0, 1], [192, 0.0, 0], [193, 1.0, 0], [194, 1.0, 1], [195, 1.0, 1], [196, 0.0, 0], [197, 1.0, 1], [198, 0.0, 0], [199, 0.0, 1], [200, 1.0, 1], [201, 1.0, 1], [202, 0.0, 0], [203, 1.0, 1], [204, 1.0, 1], [205, 0.0, 0], [206, 0.0, 0], [207, 1.0, 1], [208, 1.0, 1], [209, 0.0, 1], [210, 1.0, 1], [211, 1.0, 1], [212, 0.0, 1], [213, 1.0, 1], [214, 1.0, 1], [215, 1.0, 0], [216, 1.0, 1], [217, 1.0, 1], [218, 1.0, 1], [219, 1.0, 1], [220, 0.0, 1], [221, 0.0, 1], [222, 0.0, 0], [223, 1.0, 1], [224, 1.0, 1], [225, 1.0, 1], [226, 1.0, 1], [227, 1.0, 1], [228, 1.0, 1], [229, 0.0, 1], [230, 0.0, 0], [231, 1.0, 1], [232, 1.0, 1], [233, 0.0, 0], [234, 1.0, 0], [235, 1.0, 1], [236, 0.0, 1], [237, 1.0, 1], [238, 0.0, 0], [239, 0.0, 0], [240, 0.0, 1], [241, 1.0, 1], [242, 1.0, 1], [243, 0.0, 0], [244, 0.0, 0], [245, 0.0, 0], [246, 1.0, 0], [247, 0.0, 1], [248, 1.0, 1], [249, 0.0, 0], [250, 1.0, 1], [251, 0.0, 0], [252, 1.0, 1], [253, 1.0, 1], [254, 1.0, 1], [255, 1.0, 1], [256, 0.0, 1], [257, 1.0, 1]]\n"
     ]
    }
   ],
   "source": [
    "(matched_list,not_not_matched_list, index_label_prediction_list) = obj.accuracy(test_x_data,test_t_data)\n",
    "print(index_label_prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
