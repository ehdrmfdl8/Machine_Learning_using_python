{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-37edfc5623ff>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      " 55000 10000 5000\n",
      "\n",
      "train image shape =  (55000, 784)\n",
      "train label shape =  (55000, 10)\n",
      "test image shape =  (10000, 784)\n",
      "test label shape =  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
    "\n",
    "# read_data_sets() 를 통해 데이터를 객체형태로 받아오고\n",
    "# one_hot 옵션을 통해 정답(label) 을 one-hot 인코딩된 형태로 받아옴\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# mnist 데이터 셋은 train, test, validation 3개의 데이터 셋으로 구성되어 있으며.\n",
    "# num_examples 값을 통해 데이터의 갯수 확인 가능함\n",
    "\n",
    "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
    "\n",
    "# 데이터는 784(28x28)개의 픽셀을 가지는 이미지와\n",
    "# 10(0~9)개 클래스를 가지는 one-hot 인코딩된 레이블(정답)을 가지고 있음\n",
    "\n",
    "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
    "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
    "print(\"test image shape = \", np.shape(mnist.test.images))\n",
    "print(\"test label shape = \", np.shape(mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "T = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "A1 = tf.reshape(X, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "W2 = tf.Variable(tf.random_normal([4, 4, 1, 32], stddev = 0.01))\n",
    "\n",
    "b2 = tf.Variable(tf.constant(0.1, shape = [32]))\n",
    "\n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "Z2 = tf.nn.relu(C2 + b2)\n",
    "\n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize = [1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.Variable(tf.random_normal([5, 5, 32, 64], stddev = 0.01))\n",
    "\n",
    "b3 = tf.Variable(tf.constant(0.1, shape = [64]))\n",
    "\n",
    "C3 = tf.nn.conv2d(A2, W3, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "Z3 = tf.nn.relu(C3 + b3)\n",
    "\n",
    "A3 = P3 = tf.nn.max_pool(Z3, ksize = [1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev = 0.01))\n",
    "\n",
    "b4 = tf.Variable(tf.constant(0.1, shape = [128]))\n",
    "\n",
    "C4 = tf.nn.conv2d(A3, W4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "Z4 = tf.nn.relu(C4 + b4)\n",
    "\n",
    "A4 = P4 = tf.nn.max_pool(Z4, ksize= [1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "A4_flat = P4_flat = tf.reshape(A4, [-1,4*4*128])\n",
    "\n",
    "W5 = tf.Variable(tf.random_normal([4*4*128, 256], stddev = 0.01))\n",
    "\n",
    "b5 = tf.Variable(tf.random_normal([256]))\n",
    "\n",
    "Z5 = tf.matmul(A4_flat, W5) + b5\n",
    "\n",
    "A5 = tf.nn.relu(Z5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W6 = tf.Variable(tf.random_normal([256, 10], stddev = 0.01))\n",
    "\n",
    "b6 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "Z6 = tf.matmul(A5, W6) + b6\n",
    "\n",
    "y = A6 = tf.nn.softmax(Z6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = T, logits = y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_val = tf.equal(tf.argmax(y , 1), tf.argmax(T, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype = tf.float32))\n",
    "\n",
    "accuracy_index = tf.cast(predicted_val, dtype = tf.float32)\n",
    "\n",
    "predicted_list = tf.argmax(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.3147464\n",
      "epochs =  0 , step =  100 , loss_val =  2.2853103\n",
      "epochs =  0 , step =  200 , loss_val =  1.7986329\n",
      "epochs =  0 , step =  300 , loss_val =  1.7546494\n",
      "epochs =  0 , step =  400 , loss_val =  1.6616068\n",
      "epochs =  0 , step =  500 , loss_val =  1.7262326\n",
      "epochs =  1 , step =  0 , loss_val =  1.7194513\n",
      "epochs =  1 , step =  100 , loss_val =  1.6371994\n",
      "epochs =  1 , step =  200 , loss_val =  1.6545683\n",
      "epochs =  1 , step =  300 , loss_val =  1.6603076\n",
      "epochs =  1 , step =  400 , loss_val =  1.6633972\n",
      "epochs =  1 , step =  500 , loss_val =  1.7195795\n",
      "epochs =  2 , step =  0 , loss_val =  1.7055119\n",
      "epochs =  2 , step =  100 , loss_val =  1.690294\n",
      "epochs =  2 , step =  200 , loss_val =  1.6358464\n",
      "epochs =  2 , step =  300 , loss_val =  1.7215387\n",
      "epochs =  2 , step =  400 , loss_val =  1.5898101\n",
      "epochs =  2 , step =  500 , loss_val =  1.582427\n",
      "epochs =  3 , step =  0 , loss_val =  1.5778165\n",
      "epochs =  3 , step =  100 , loss_val =  1.5619453\n",
      "epochs =  3 , step =  200 , loss_val =  1.523434\n",
      "epochs =  3 , step =  300 , loss_val =  1.5786668\n",
      "epochs =  3 , step =  400 , loss_val =  1.6218038\n",
      "epochs =  3 , step =  500 , loss_val =  1.6213005\n",
      "epochs =  4 , step =  0 , loss_val =  1.6303849\n",
      "epochs =  4 , step =  100 , loss_val =  1.5918038\n",
      "epochs =  4 , step =  200 , loss_val =  1.5613567\n",
      "epochs =  4 , step =  300 , loss_val =  1.5688677\n",
      "epochs =  4 , step =  400 , loss_val =  1.5862294\n",
      "epochs =  4 , step =  500 , loss_val =  1.4948425\n",
      "epochs =  5 , step =  0 , loss_val =  1.4705136\n",
      "epochs =  5 , step =  100 , loss_val =  1.4751151\n",
      "epochs =  5 , step =  200 , loss_val =  1.4978743\n",
      "epochs =  5 , step =  300 , loss_val =  1.5012558\n",
      "epochs =  5 , step =  400 , loss_val =  1.4670786\n",
      "epochs =  5 , step =  500 , loss_val =  1.4729123\n",
      "epochs =  6 , step =  0 , loss_val =  1.4821963\n",
      "epochs =  6 , step =  100 , loss_val =  1.4781656\n",
      "epochs =  6 , step =  200 , loss_val =  1.5016202\n",
      "epochs =  6 , step =  300 , loss_val =  1.5002398\n",
      "epochs =  6 , step =  400 , loss_val =  1.4847962\n",
      "epochs =  6 , step =  500 , loss_val =  1.4815726\n",
      "epochs =  7 , step =  0 , loss_val =  1.4862816\n",
      "epochs =  7 , step =  100 , loss_val =  1.4813062\n",
      "epochs =  7 , step =  200 , loss_val =  1.4651382\n",
      "epochs =  7 , step =  300 , loss_val =  1.4612405\n",
      "epochs =  7 , step =  400 , loss_val =  1.4862683\n",
      "epochs =  7 , step =  500 , loss_val =  1.472775\n",
      "epochs =  8 , step =  0 , loss_val =  1.4708575\n",
      "epochs =  8 , step =  100 , loss_val =  1.4614863\n",
      "epochs =  8 , step =  200 , loss_val =  1.4756213\n",
      "epochs =  8 , step =  300 , loss_val =  1.4725543\n",
      "epochs =  8 , step =  400 , loss_val =  1.462803\n",
      "epochs =  8 , step =  500 , loss_val =  1.4714149\n",
      "epochs =  9 , step =  0 , loss_val =  1.4711529\n",
      "epochs =  9 , step =  100 , loss_val =  1.4696269\n",
      "epochs =  9 , step =  200 , loss_val =  1.4902502\n",
      "epochs =  9 , step =  300 , loss_val =  1.4812616\n",
      "epochs =  9 , step =  400 , loss_val =  1.4713831\n",
      "epochs =  9 , step =  500 , loss_val =  1.4611508\n",
      "epochs =  10 , step =  0 , loss_val =  1.4789599\n",
      "epochs =  10 , step =  100 , loss_val =  1.4711542\n",
      "epochs =  10 , step =  200 , loss_val =  1.4756904\n",
      "epochs =  10 , step =  300 , loss_val =  1.4617229\n",
      "epochs =  10 , step =  400 , loss_val =  1.471492\n",
      "epochs =  10 , step =  500 , loss_val =  1.4786141\n",
      "epochs =  11 , step =  0 , loss_val =  1.4611504\n",
      "epochs =  11 , step =  100 , loss_val =  1.4634128\n",
      "epochs =  11 , step =  200 , loss_val =  1.4755765\n",
      "epochs =  11 , step =  300 , loss_val =  1.4737073\n",
      "epochs =  11 , step =  400 , loss_val =  1.4892621\n",
      "epochs =  11 , step =  500 , loss_val =  1.4611608\n",
      "epochs =  12 , step =  0 , loss_val =  1.480501\n",
      "epochs =  12 , step =  100 , loss_val =  1.4810779\n",
      "epochs =  12 , step =  200 , loss_val =  1.471151\n",
      "epochs =  12 , step =  300 , loss_val =  1.4611504\n",
      "epochs =  12 , step =  400 , loss_val =  1.4845481\n",
      "epochs =  12 , step =  500 , loss_val =  1.4754175\n",
      "epochs =  13 , step =  0 , loss_val =  1.4830776\n",
      "epochs =  13 , step =  100 , loss_val =  1.490809\n",
      "epochs =  13 , step =  200 , loss_val =  1.4714551\n",
      "epochs =  13 , step =  300 , loss_val =  1.4864321\n",
      "epochs =  13 , step =  400 , loss_val =  1.4651474\n",
      "epochs =  13 , step =  500 , loss_val =  1.4811093\n",
      "epochs =  14 , step =  0 , loss_val =  1.4711729\n",
      "epochs =  14 , step =  100 , loss_val =  1.4611511\n",
      "epochs =  14 , step =  200 , loss_val =  1.4976544\n",
      "epochs =  14 , step =  300 , loss_val =  1.4711553\n",
      "epochs =  14 , step =  400 , loss_val =  1.4662677\n",
      "epochs =  14 , step =  500 , loss_val =  1.4611511\n",
      "epochs =  15 , step =  0 , loss_val =  1.4612356\n",
      "epochs =  15 , step =  100 , loss_val =  1.4616377\n",
      "epochs =  15 , step =  200 , loss_val =  1.4611535\n",
      "epochs =  15 , step =  300 , loss_val =  1.4807384\n",
      "epochs =  15 , step =  400 , loss_val =  1.4798737\n",
      "epochs =  15 , step =  500 , loss_val =  1.4640536\n",
      "epochs =  16 , step =  0 , loss_val =  1.4640512\n",
      "epochs =  16 , step =  100 , loss_val =  1.4611505\n",
      "epochs =  16 , step =  200 , loss_val =  1.4910523\n",
      "epochs =  16 , step =  300 , loss_val =  1.4620166\n",
      "epochs =  16 , step =  400 , loss_val =  1.4711545\n",
      "epochs =  16 , step =  500 , loss_val =  1.473879\n",
      "epochs =  17 , step =  0 , loss_val =  1.4726653\n",
      "epochs =  17 , step =  100 , loss_val =  1.4810184\n",
      "epochs =  17 , step =  200 , loss_val =  1.4655014\n",
      "epochs =  17 , step =  300 , loss_val =  1.50102\n",
      "epochs =  17 , step =  400 , loss_val =  1.4611611\n",
      "epochs =  17 , step =  500 , loss_val =  1.4708252\n",
      "epochs =  18 , step =  0 , loss_val =  1.4811422\n",
      "epochs =  18 , step =  100 , loss_val =  1.482297\n",
      "epochs =  18 , step =  200 , loss_val =  1.4611816\n",
      "epochs =  18 , step =  300 , loss_val =  1.4791483\n",
      "epochs =  18 , step =  400 , loss_val =  1.4711485\n",
      "epochs =  18 , step =  500 , loss_val =  1.4698275\n",
      "epochs =  19 , step =  0 , loss_val =  1.4611505\n",
      "epochs =  19 , step =  100 , loss_val =  1.4709762\n",
      "epochs =  19 , step =  200 , loss_val =  1.4711511\n",
      "epochs =  19 , step =  300 , loss_val =  1.4712166\n",
      "epochs =  19 , step =  400 , loss_val =  1.4711974\n",
      "epochs =  19 , step =  500 , loss_val =  1.4611505\n",
      "epochs =  20 , step =  0 , loss_val =  1.4642259\n",
      "epochs =  20 , step =  100 , loss_val =  1.4611707\n",
      "epochs =  20 , step =  200 , loss_val =  1.4611504\n",
      "epochs =  20 , step =  300 , loss_val =  1.4711504\n",
      "epochs =  20 , step =  400 , loss_val =  1.4611679\n",
      "epochs =  20 , step =  500 , loss_val =  1.4658551\n",
      "epochs =  21 , step =  0 , loss_val =  1.461151\n",
      "epochs =  21 , step =  100 , loss_val =  1.4711502\n",
      "epochs =  21 , step =  200 , loss_val =  1.469611\n",
      "epochs =  21 , step =  300 , loss_val =  1.4811487\n",
      "epochs =  21 , step =  400 , loss_val =  1.4811462\n",
      "epochs =  21 , step =  500 , loss_val =  1.4711652\n",
      "epochs =  22 , step =  0 , loss_val =  1.4611508\n",
      "epochs =  22 , step =  100 , loss_val =  1.4619719\n",
      "epochs =  22 , step =  200 , loss_val =  1.4744141\n",
      "epochs =  22 , step =  300 , loss_val =  1.461151\n",
      "epochs =  22 , step =  400 , loss_val =  1.4811578\n",
      "epochs =  22 , step =  500 , loss_val =  1.4611505\n",
      "epochs =  23 , step =  0 , loss_val =  1.4611515\n",
      "epochs =  23 , step =  100 , loss_val =  1.4730742\n",
      "epochs =  23 , step =  200 , loss_val =  1.4728122\n",
      "epochs =  23 , step =  300 , loss_val =  1.471151\n",
      "epochs =  23 , step =  400 , loss_val =  1.4611502\n",
      "epochs =  23 , step =  500 , loss_val =  1.4611505\n",
      "epochs =  24 , step =  0 , loss_val =  1.4711587\n",
      "epochs =  24 , step =  100 , loss_val =  1.4711474\n",
      "epochs =  24 , step =  200 , loss_val =  1.4711592\n",
      "epochs =  24 , step =  300 , loss_val =  1.4646823\n",
      "epochs =  24 , step =  400 , loss_val =  1.4611654\n",
      "epochs =  24 , step =  500 , loss_val =  1.4611505\n",
      "epochs =  25 , step =  0 , loss_val =  1.4611504\n",
      "epochs =  25 , step =  100 , loss_val =  1.4711505\n",
      "epochs =  25 , step =  200 , loss_val =  1.4715905\n",
      "epochs =  25 , step =  300 , loss_val =  1.4611502\n",
      "epochs =  25 , step =  400 , loss_val =  1.4611506\n",
      "epochs =  25 , step =  500 , loss_val =  1.4711897\n",
      "epochs =  26 , step =  0 , loss_val =  1.4611502\n",
      "epochs =  26 , step =  100 , loss_val =  1.4611821\n",
      "epochs =  26 , step =  200 , loss_val =  1.4611502\n",
      "epochs =  26 , step =  300 , loss_val =  1.4611505\n",
      "epochs =  26 , step =  400 , loss_val =  1.4611504\n",
      "epochs =  26 , step =  500 , loss_val =  1.4611505\n",
      "epochs =  27 , step =  0 , loss_val =  1.479061\n",
      "epochs =  27 , step =  100 , loss_val =  1.4711504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  27 , step =  200 , loss_val =  1.4736856\n",
      "epochs =  27 , step =  300 , loss_val =  1.4611502\n",
      "epochs =  27 , step =  400 , loss_val =  1.4611505\n",
      "epochs =  27 , step =  500 , loss_val =  1.4611505\n",
      "epochs =  28 , step =  0 , loss_val =  1.471151\n",
      "epochs =  28 , step =  100 , loss_val =  1.4611505\n",
      "epochs =  28 , step =  200 , loss_val =  1.4711167\n",
      "epochs =  28 , step =  300 , loss_val =  1.4611502\n",
      "epochs =  28 , step =  400 , loss_val =  1.462934\n",
      "epochs =  28 , step =  500 , loss_val =  1.4611504\n",
      "epochs =  29 , step =  0 , loss_val =  1.4612008\n",
      "epochs =  29 , step =  100 , loss_val =  1.4615614\n",
      "epochs =  29 , step =  200 , loss_val =  1.4811515\n",
      "epochs =  29 , step =  300 , loss_val =  1.4619435\n",
      "epochs =  29 , step =  400 , loss_val =  1.4702731\n",
      "epochs =  29 , step =  500 , loss_val =  1.4679621\n",
      "\n",
      "elapsed time =  0:43:44.791910\n"
     ]
    }
   ],
   "source": [
    "save_path = './CNN_train_model1.ckpt'\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        for step in range(total_batch):\n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val,_ = sess.run([loss, train], feed_dict = {X : batch_x_data, T : batch_t_data})\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i ,\", step = \", step, \", loss_val = \", loss_val)\n",
    "    end_time = datetime.now()\n",
    "    print(\"\\nelapsed time = \", end_time - start_time)\n",
    "    saver.save(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./CNN_train_model1.ckpt\n",
      "\n",
      "Accuracy =  0.9904\n",
      "type(accuracy_val) =  <class 'numpy.float32'> , type(predicted_list_val) =  <class 'numpy.ndarray'> , type(index_label) =  <class 'numpy.ndarray'>\n",
      "index_label.shape =  (10000,)\n",
      "length of index_label_list =  10000\n",
      "false label count =  96\n",
      "\n",
      "length of index_label_false_list 96\n"
     ]
    }
   ],
   "source": [
    "index_label_prediction_list = []\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_path)\n",
    "    test_x_data = mnist.test.images\n",
    "    test_t_data = mnist.test.labels\n",
    "    \n",
    "    accuracy_val , predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict = {X : test_x_data, T : test_t_data})\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Accuracy = \", accuracy_val)\n",
    "    print(\"type(accuracy_val) = \", type(accuracy_val), ', type(predicted_list_val) = ', type(predicted_list_val), ', type(index_label) = ', type(index_label))\n",
    "    print(\"index_label.shape = \", index_label.shape)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    \n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "    \n",
    "    # numpy type으로 디버그\n",
    "    temp_list = []\n",
    "    \n",
    "    for index in range(len(index_label)):\n",
    "        \n",
    "        if index_label[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_prediction_list.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "    \n",
    "    print(\"\\nlength of index_label_false_list\", len(index_label_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[321, 2, 7], [336, 9, 4], [340, 5, 3], [445, 6, 0], [449, 3, 5], [471, 9, 7], [582, 8, 2], [583, 2, 7], [646, 2, 6], [659, 2, 1], [674, 5, 3], [716, 1, 7], [717, 0, 5], [726, 7, 3], [916, 4, 2], [924, 2, 7], [947, 8, 9], [1014, 6, 5], [1232, 9, 4], [1247, 9, 5], [1299, 5, 7], [1393, 5, 3], [1394, 8, 2], [1459, 2, 7], [1522, 7, 9], [1527, 1, 3], [1654, 2, 7], [1709, 9, 8], [1790, 2, 7], [1878, 8, 3], [1901, 9, 4], [1909, 1, 7], [2018, 1, 7], [2093, 8, 2], [2098, 2, 0], [2118, 6, 0], [2129, 9, 8], [2130, 4, 9], [2135, 6, 1], [2182, 1, 3], [2293, 9, 4], [2582, 9, 7], [2597, 5, 3], [2654, 6, 1], [2896, 8, 0], [2927, 3, 7], [2939, 9, 5], [2953, 3, 5], [2959, 2, 3], [3060, 9, 7], [3062, 8, 3], [3343, 8, 2], [3422, 6, 0], [3475, 3, 7], [3520, 6, 4], [3559, 8, 5], [3599, 2, 7], [3626, 8, 3], [3780, 4, 6], [3794, 8, 3], [3808, 7, 2], [3850, 9, 4], [3853, 6, 0], [3859, 9, 4], [3906, 1, 3], [4078, 9, 8], [4163, 9, 7], [4176, 2, 7], [4201, 1, 7], [4207, 8, 2], [4369, 9, 4], [4497, 8, 7], [4507, 1, 7], [4740, 3, 5], [4761, 9, 4], [4823, 9, 4], [4874, 9, 0], [4879, 8, 6], [4939, 2, 7], [4990, 3, 2], [5654, 7, 2], [5937, 5, 3], [5955, 3, 8], [6560, 9, 5], [6571, 9, 7], [6576, 7, 1], [6597, 0, 7], [6625, 8, 7], [7216, 0, 6], [8332, 9, 7], [8408, 8, 5], [9638, 9, 7], [9642, 9, 7], [9664, 2, 7], [9692, 9, 7], [9729, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "70 image is saved now\n",
      "80 image is saved now\n",
      "90 image is saved now\n",
      "Elapsed Time =  0:00:22.867830\n",
      "Total  96  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "\n",
    "#image 저장할 디렉토리 생성, 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "algorithm_name = 'CNN_1Conv_Adam_'\n",
    "dir_name = algorithm_name + str(now.year) + '-' + str(now.month) + '-' +str(now.day) + '-' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "os.mkdir(dir_name)\n",
    "\n",
    "# change dir\n",
    "os.chdir(dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_prediction_list:\n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "    \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)\n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + ', prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "        \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed Time = ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
