{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.num =  55000\n",
      "test.num =  10000\n",
      "validation.num =  5000\n"
     ]
    }
   ],
   "source": [
    "print(\"train.num = \", mnist.train.num_examples)\n",
    "print(\"test.num = \", mnist.test.num_examples)\n",
    "print(\"validation.num = \", mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shape 및 type(mnist) 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(mnist) =  <class 'tensorflow.contrib.learn.python.learn.datasets.base.Datasets'>\n",
      "type(mnist.train.images) =  <class 'numpy.ndarray'>\n",
      "type(minst.train.labels) =  <class 'numpy.ndarray'>\n",
      "\n",
      "train image shape =  (55000, 784)\n",
      "train label shape =  (55000, 10)\n",
      "test image shape =  (10000, 784)\n",
      "test label shape =  (10000, 10)\n",
      "\n",
      "train image shape =  (55000, 784)\n",
      "test image shape =  (10000, 784)\n",
      "validation image shape =  (5000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"type(mnist) = \", type(mnist))\n",
    "print(\"type(mnist.train.images) = \", type(mnist.train.images))\n",
    "print(\"type(minst.train.labels) = \", type(mnist.train.labels))\n",
    "\n",
    "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
    "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
    "print(\"test image shape = \", np.shape(mnist.test.images))\n",
    "print(\"test label shape = \", np.shape(mnist.test.labels))\n",
    "\n",
    "print(\"\\ntrain image shape = \", mnist.train.images.shape)\n",
    "print(\"test image shape = \", mnist.test.images.shape)\n",
    "print(\"validation image shape = \", mnist.validation.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train data 정규화 및 label의 one-hot encoding 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of mnist.train.images =  55000\n",
      "\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.3803922  0.37647063 0.3019608\n",
      " 0.46274513 0.2392157  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.3529412\n",
      " 0.5411765  0.9215687  0.9215687  0.9215687  0.9215687  0.9215687\n",
      " 0.9215687  0.9843138  0.9843138  0.9725491  0.9960785  0.9607844\n",
      " 0.9215687  0.74509805 0.08235294 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.54901963 0.9843138  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.7411765  0.09019608 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.8862746  0.9960785  0.81568635 0.7803922  0.7803922  0.7803922\n",
      " 0.7803922  0.54509807 0.2392157  0.2392157  0.2392157  0.2392157\n",
      " 0.2392157  0.5019608  0.8705883  0.9960785  0.9960785  0.7411765\n",
      " 0.08235294 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.14901961 0.32156864\n",
      " 0.0509804  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.13333334 0.8352942  0.9960785  0.9960785  0.45098042 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32941177\n",
      " 0.9960785  0.9960785  0.9176471  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.32941177 0.9960785  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4156863  0.6156863  0.9960785  0.9960785  0.95294124 0.20000002\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.09803922\n",
      " 0.45882356 0.8941177  0.8941177  0.8941177  0.9921569  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.94117653 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.26666668 0.4666667  0.86274517 0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.5568628  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.14509805 0.73333335 0.9921569\n",
      " 0.9960785  0.9960785  0.9960785  0.8745099  0.8078432  0.8078432\n",
      " 0.29411766 0.26666668 0.8431373  0.9960785  0.9960785  0.45882356\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4431373  0.8588236  0.9960785  0.9490197  0.89019614 0.45098042\n",
      " 0.34901962 0.12156864 0.         0.         0.         0.\n",
      " 0.7843138  0.9960785  0.9450981  0.16078432 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.6627451  0.9960785\n",
      " 0.6901961  0.24313727 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.18823531 0.9058824  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.07058824 0.48627454 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.32941177 0.9960785  0.9960785  0.6509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.54509807\n",
      " 0.9960785  0.9333334  0.22352943 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.8235295  0.9803922  0.9960785  0.65882355\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.9490197  0.9960785  0.93725497 0.22352943 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.34901962 0.9843138  0.9450981\n",
      " 0.3372549  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01960784 0.8078432  0.96470594 0.6156863  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01568628 0.45882356\n",
      " 0.27058825 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# 정규화 확인\n",
    "print(\"length of mnist.train.images = \", len(mnist.train.images))\n",
    "\n",
    "for index in range(len(mnist.train.images)):\n",
    "    min_val = np.min(mnist.train.images[index])\n",
    "    max_val = np.max(mnist.train.images[index])\n",
    "    \n",
    "    if min_val < 0.0:\n",
    "        print(\"min value is \", min_val, \", index = \", index)\n",
    "        break\n",
    "    \n",
    "    if max_val > 1.0:\n",
    "        print(\"max value is \", max_val, \", index = \", index)\n",
    "        break\n",
    "\n",
    "print(\"\")\n",
    "print(mnist.train.images[0]) #정규화 확인을 위한 테스트 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of mnist.train.images =  55000\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding 확인\n",
    "\n",
    "print(\"length of mnist.train.images = \", len(mnist.train.labels))\n",
    "\n",
    "for index in range (len(mnist.train.labels)):\n",
    "    min_val = np.min(mnist.train.labels[index])\n",
    "    max_val = np.max(mnist.train.labels[index])\n",
    "    \n",
    "    if min_val < 0.0:\n",
    "        print(\"min value is \", min_val, \", index = \", index)\n",
    "        break\n",
    "    \n",
    "    if max_val > 1.0:\n",
    "        print(\"max value is \", max_val, \", index = \", index)\n",
    "        break\n",
    "\n",
    "print(\"\")\n",
    "print(mnist.train.labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력노드, 은닉노드, 출력노드, 학습율, 반복횟수, 배치 개수 등 설정\n",
    "learning_rate = 0.1 #학습률\n",
    "epochs = 100        #반복횟수\n",
    "batch_size = 100    #한번에 입력으로 주어지는 MNIST 개수\n",
    "\n",
    "input_nodes = 784   #입력노드 개수\n",
    "hidden_nodes = 100  #은닉노드 개수\n",
    "output_nodes = 10   #출력노드 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입력과 출력을 위한 플레이스홀더 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력과 출력을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, input_nodes])\n",
    "T = tf.placeholder(tf.float32, [None, output_nodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가중치, 바이어스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.random_normal([input_nodes, hidden_nodes]))\n",
    "b2 = tf.Variable(tf.random_normal([hidden_nodes]))\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([hidden_nodes, output_nodes]))\n",
    "b3 = tf.Variable(tf.random_normal([output_nodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2 = tf.matmul(X, W2) + b2\n",
    "A2 = tf.nn.relu(Z2)\n",
    "\n",
    "Z3 = logits = tf.matmul(A2, W3) + b3\n",
    "y = A3 = tf.nn.softmax(Z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z3, labels = T))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size x 10 데이터에 대해 argmax를 통해 행단위로 비교함 \n",
    "predicted_val = tf.equal(tf.argmax(A3, 1), tf.argmax(T, 1))\n",
    "\n",
    "# batch_size x 10의 True, False를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype = tf.float32))\n",
    "\n",
    "# index list 출력\n",
    "accuracy_index = tf.cast(predicted_val, dtype = tf.float32)\n",
    "\n",
    "# 예측값 처리 2번째 인자가 1이면 긱행 기준으로 생각함 반대로 0이면 각열 기준으로 생각\n",
    "predicted_list = tf.argmax(A3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(predicted_val) =  <class 'tensorflow.python.framework.ops.Tensor'> , type(accuracy) =  <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "type(accuracy_index) =  <class 'tensorflow.python.framework.ops.Tensor'> , type(predicted_list) =  <class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# Type Check\n",
    "print('type(predicted_val) = ', type(predicted_val), ', type(accuracy) = ', type(accuracy))\n",
    "print('type(accuracy_index) = ', type(accuracy_index), ', type(predicted_list) = ', type(predicted_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  148.92368\n",
      "epochs =  0 , step =  100 , loss_val =  3.5064178\n",
      "epochs =  0 , step =  200 , loss_val =  2.0015757\n",
      "epochs =  0 , step =  300 , loss_val =  2.0953112\n",
      "epochs =  0 , step =  400 , loss_val =  1.9735348\n",
      "epochs =  0 , step =  500 , loss_val =  1.2826327\n",
      "epochs =  1 , step =  0 , loss_val =  1.5203656\n",
      "epochs =  1 , step =  100 , loss_val =  0.76752394\n",
      "epochs =  1 , step =  200 , loss_val =  1.1341565\n",
      "epochs =  1 , step =  300 , loss_val =  0.5123117\n",
      "epochs =  1 , step =  400 , loss_val =  1.6768105\n",
      "epochs =  1 , step =  500 , loss_val =  0.8775003\n",
      "epochs =  2 , step =  0 , loss_val =  0.86026376\n",
      "epochs =  2 , step =  100 , loss_val =  0.66688645\n",
      "epochs =  2 , step =  200 , loss_val =  0.57560956\n",
      "epochs =  2 , step =  300 , loss_val =  0.80362815\n",
      "epochs =  2 , step =  400 , loss_val =  1.0634013\n",
      "epochs =  2 , step =  500 , loss_val =  0.69381315\n",
      "epochs =  3 , step =  0 , loss_val =  0.48783362\n",
      "epochs =  3 , step =  100 , loss_val =  0.5592836\n",
      "epochs =  3 , step =  200 , loss_val =  0.8260049\n",
      "epochs =  3 , step =  300 , loss_val =  0.5675826\n",
      "epochs =  3 , step =  400 , loss_val =  0.38180518\n",
      "epochs =  3 , step =  500 , loss_val =  0.55680287\n",
      "epochs =  4 , step =  0 , loss_val =  0.36146104\n",
      "epochs =  4 , step =  100 , loss_val =  0.7655742\n",
      "epochs =  4 , step =  200 , loss_val =  0.45718932\n",
      "epochs =  4 , step =  300 , loss_val =  0.5234244\n",
      "epochs =  4 , step =  400 , loss_val =  0.52982193\n",
      "epochs =  4 , step =  500 , loss_val =  0.37296802\n",
      "epochs =  5 , step =  0 , loss_val =  0.2186411\n",
      "epochs =  5 , step =  100 , loss_val =  0.5820244\n",
      "epochs =  5 , step =  200 , loss_val =  0.4974685\n",
      "epochs =  5 , step =  300 , loss_val =  0.3592538\n",
      "epochs =  5 , step =  400 , loss_val =  0.34645057\n",
      "epochs =  5 , step =  500 , loss_val =  0.5654407\n",
      "epochs =  6 , step =  0 , loss_val =  0.38942432\n",
      "epochs =  6 , step =  100 , loss_val =  0.25428033\n",
      "epochs =  6 , step =  200 , loss_val =  0.35120162\n",
      "epochs =  6 , step =  300 , loss_val =  0.40634438\n",
      "epochs =  6 , step =  400 , loss_val =  0.35309273\n",
      "epochs =  6 , step =  500 , loss_val =  0.42214668\n",
      "epochs =  7 , step =  0 , loss_val =  0.37082222\n",
      "epochs =  7 , step =  100 , loss_val =  0.5146417\n",
      "epochs =  7 , step =  200 , loss_val =  0.37975487\n",
      "epochs =  7 , step =  300 , loss_val =  0.31487006\n",
      "epochs =  7 , step =  400 , loss_val =  0.45682815\n",
      "epochs =  7 , step =  500 , loss_val =  0.544758\n",
      "epochs =  8 , step =  0 , loss_val =  0.18899462\n",
      "epochs =  8 , step =  100 , loss_val =  0.37140197\n",
      "epochs =  8 , step =  200 , loss_val =  0.4230081\n",
      "epochs =  8 , step =  300 , loss_val =  0.33652684\n",
      "epochs =  8 , step =  400 , loss_val =  0.29931536\n",
      "epochs =  8 , step =  500 , loss_val =  0.16422416\n",
      "epochs =  9 , step =  0 , loss_val =  0.45455092\n",
      "epochs =  9 , step =  100 , loss_val =  0.5064957\n",
      "epochs =  9 , step =  200 , loss_val =  0.44569954\n",
      "epochs =  9 , step =  300 , loss_val =  0.25780377\n",
      "epochs =  9 , step =  400 , loss_val =  0.27881292\n",
      "epochs =  9 , step =  500 , loss_val =  0.3279254\n",
      "epochs =  10 , step =  0 , loss_val =  0.23081914\n",
      "epochs =  10 , step =  100 , loss_val =  0.38147533\n",
      "epochs =  10 , step =  200 , loss_val =  0.33495253\n",
      "epochs =  10 , step =  300 , loss_val =  0.19069208\n",
      "epochs =  10 , step =  400 , loss_val =  0.3867855\n",
      "epochs =  10 , step =  500 , loss_val =  0.48441756\n",
      "epochs =  11 , step =  0 , loss_val =  0.2825886\n",
      "epochs =  11 , step =  100 , loss_val =  0.57226175\n",
      "epochs =  11 , step =  200 , loss_val =  0.4633781\n",
      "epochs =  11 , step =  300 , loss_val =  0.16261253\n",
      "epochs =  11 , step =  400 , loss_val =  0.47226882\n",
      "epochs =  11 , step =  500 , loss_val =  0.3166845\n",
      "epochs =  12 , step =  0 , loss_val =  0.1890028\n",
      "epochs =  12 , step =  100 , loss_val =  0.30099636\n",
      "epochs =  12 , step =  200 , loss_val =  0.38012862\n",
      "epochs =  12 , step =  300 , loss_val =  0.35619986\n",
      "epochs =  12 , step =  400 , loss_val =  0.14785676\n",
      "epochs =  12 , step =  500 , loss_val =  0.35040706\n",
      "epochs =  13 , step =  0 , loss_val =  0.53051144\n",
      "epochs =  13 , step =  100 , loss_val =  0.29867753\n",
      "epochs =  13 , step =  200 , loss_val =  0.35023522\n",
      "epochs =  13 , step =  300 , loss_val =  0.23419403\n",
      "epochs =  13 , step =  400 , loss_val =  0.19718547\n",
      "epochs =  13 , step =  500 , loss_val =  0.2348921\n",
      "epochs =  14 , step =  0 , loss_val =  0.2578218\n",
      "epochs =  14 , step =  100 , loss_val =  0.17201643\n",
      "epochs =  14 , step =  200 , loss_val =  0.30303213\n",
      "epochs =  14 , step =  300 , loss_val =  0.2682329\n",
      "epochs =  14 , step =  400 , loss_val =  0.28285664\n",
      "epochs =  14 , step =  500 , loss_val =  0.15120113\n",
      "epochs =  15 , step =  0 , loss_val =  0.15491165\n",
      "epochs =  15 , step =  100 , loss_val =  0.19711278\n",
      "epochs =  15 , step =  200 , loss_val =  0.33872846\n",
      "epochs =  15 , step =  300 , loss_val =  0.1850474\n",
      "epochs =  15 , step =  400 , loss_val =  0.2765247\n",
      "epochs =  15 , step =  500 , loss_val =  0.22629188\n",
      "epochs =  16 , step =  0 , loss_val =  0.27944106\n",
      "epochs =  16 , step =  100 , loss_val =  0.20046262\n",
      "epochs =  16 , step =  200 , loss_val =  0.29538247\n",
      "epochs =  16 , step =  300 , loss_val =  0.29719937\n",
      "epochs =  16 , step =  400 , loss_val =  0.46653396\n",
      "epochs =  16 , step =  500 , loss_val =  0.14438568\n",
      "epochs =  17 , step =  0 , loss_val =  0.35919785\n",
      "epochs =  17 , step =  100 , loss_val =  0.24968499\n",
      "epochs =  17 , step =  200 , loss_val =  0.33074212\n",
      "epochs =  17 , step =  300 , loss_val =  0.5219631\n",
      "epochs =  17 , step =  400 , loss_val =  0.12408678\n",
      "epochs =  17 , step =  500 , loss_val =  0.22050433\n",
      "epochs =  18 , step =  0 , loss_val =  0.24151883\n",
      "epochs =  18 , step =  100 , loss_val =  0.15483545\n",
      "epochs =  18 , step =  200 , loss_val =  0.26919416\n",
      "epochs =  18 , step =  300 , loss_val =  0.15989737\n",
      "epochs =  18 , step =  400 , loss_val =  0.16310363\n",
      "epochs =  18 , step =  500 , loss_val =  0.32748204\n",
      "epochs =  19 , step =  0 , loss_val =  0.2939454\n",
      "epochs =  19 , step =  100 , loss_val =  0.2971608\n",
      "epochs =  19 , step =  200 , loss_val =  0.20088196\n",
      "epochs =  19 , step =  300 , loss_val =  0.22660397\n",
      "epochs =  19 , step =  400 , loss_val =  0.30416098\n",
      "epochs =  19 , step =  500 , loss_val =  0.15700775\n",
      "epochs =  20 , step =  0 , loss_val =  0.2864526\n",
      "epochs =  20 , step =  100 , loss_val =  0.06331234\n",
      "epochs =  20 , step =  200 , loss_val =  0.18220958\n",
      "epochs =  20 , step =  300 , loss_val =  0.3854245\n",
      "epochs =  20 , step =  400 , loss_val =  0.45621505\n",
      "epochs =  20 , step =  500 , loss_val =  0.10268192\n",
      "epochs =  21 , step =  0 , loss_val =  0.4903508\n",
      "epochs =  21 , step =  100 , loss_val =  0.14889742\n",
      "epochs =  21 , step =  200 , loss_val =  0.12092467\n",
      "epochs =  21 , step =  300 , loss_val =  0.20299481\n",
      "epochs =  21 , step =  400 , loss_val =  0.20503107\n",
      "epochs =  21 , step =  500 , loss_val =  0.13657464\n",
      "epochs =  22 , step =  0 , loss_val =  0.30933478\n",
      "epochs =  22 , step =  100 , loss_val =  0.14133112\n",
      "epochs =  22 , step =  200 , loss_val =  0.17610379\n",
      "epochs =  22 , step =  300 , loss_val =  0.08620754\n",
      "epochs =  22 , step =  400 , loss_val =  0.17912678\n",
      "epochs =  22 , step =  500 , loss_val =  0.38188812\n",
      "epochs =  23 , step =  0 , loss_val =  0.28603992\n",
      "epochs =  23 , step =  100 , loss_val =  0.25698873\n",
      "epochs =  23 , step =  200 , loss_val =  0.2228159\n",
      "epochs =  23 , step =  300 , loss_val =  0.21150257\n",
      "epochs =  23 , step =  400 , loss_val =  0.2812096\n",
      "epochs =  23 , step =  500 , loss_val =  0.24211198\n",
      "epochs =  24 , step =  0 , loss_val =  0.24040885\n",
      "epochs =  24 , step =  100 , loss_val =  0.17667118\n",
      "epochs =  24 , step =  200 , loss_val =  0.26535642\n",
      "epochs =  24 , step =  300 , loss_val =  0.19176342\n",
      "epochs =  24 , step =  400 , loss_val =  0.20101017\n",
      "epochs =  24 , step =  500 , loss_val =  0.2696261\n",
      "epochs =  25 , step =  0 , loss_val =  0.21637306\n",
      "epochs =  25 , step =  100 , loss_val =  0.23591965\n",
      "epochs =  25 , step =  200 , loss_val =  0.20710708\n",
      "epochs =  25 , step =  300 , loss_val =  0.15395993\n",
      "epochs =  25 , step =  400 , loss_val =  0.14316554\n",
      "epochs =  25 , step =  500 , loss_val =  0.18582407\n",
      "epochs =  26 , step =  0 , loss_val =  0.18835144\n",
      "epochs =  26 , step =  100 , loss_val =  0.23110554\n",
      "epochs =  26 , step =  200 , loss_val =  0.31854284\n",
      "epochs =  26 , step =  300 , loss_val =  0.18075268\n",
      "epochs =  26 , step =  400 , loss_val =  0.1598692\n",
      "epochs =  26 , step =  500 , loss_val =  0.20625049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  27 , step =  0 , loss_val =  0.33764198\n",
      "epochs =  27 , step =  100 , loss_val =  0.13445811\n",
      "epochs =  27 , step =  200 , loss_val =  0.14936538\n",
      "epochs =  27 , step =  300 , loss_val =  0.14142327\n",
      "epochs =  27 , step =  400 , loss_val =  0.15093659\n",
      "epochs =  27 , step =  500 , loss_val =  0.13623142\n",
      "epochs =  28 , step =  0 , loss_val =  0.13159099\n",
      "epochs =  28 , step =  100 , loss_val =  0.18605797\n",
      "epochs =  28 , step =  200 , loss_val =  0.21578528\n",
      "epochs =  28 , step =  300 , loss_val =  0.17678145\n",
      "epochs =  28 , step =  400 , loss_val =  0.09629306\n",
      "epochs =  28 , step =  500 , loss_val =  0.21652234\n",
      "epochs =  29 , step =  0 , loss_val =  0.26583955\n",
      "epochs =  29 , step =  100 , loss_val =  0.21280062\n",
      "epochs =  29 , step =  200 , loss_val =  0.11761295\n",
      "epochs =  29 , step =  300 , loss_val =  0.24856365\n",
      "epochs =  29 , step =  400 , loss_val =  0.23730916\n",
      "epochs =  29 , step =  500 , loss_val =  0.28632012\n",
      "epochs =  30 , step =  0 , loss_val =  0.15602332\n",
      "epochs =  30 , step =  100 , loss_val =  0.19301331\n",
      "epochs =  30 , step =  200 , loss_val =  0.10219425\n",
      "epochs =  30 , step =  300 , loss_val =  0.14680882\n",
      "epochs =  30 , step =  400 , loss_val =  0.21059257\n",
      "epochs =  30 , step =  500 , loss_val =  0.18424836\n",
      "epochs =  31 , step =  0 , loss_val =  0.20382492\n",
      "epochs =  31 , step =  100 , loss_val =  0.22994742\n",
      "epochs =  31 , step =  200 , loss_val =  0.18923408\n",
      "epochs =  31 , step =  300 , loss_val =  0.38485116\n",
      "epochs =  31 , step =  400 , loss_val =  0.16120613\n",
      "epochs =  31 , step =  500 , loss_val =  0.23088008\n",
      "epochs =  32 , step =  0 , loss_val =  0.13570738\n",
      "epochs =  32 , step =  100 , loss_val =  0.16928345\n",
      "epochs =  32 , step =  200 , loss_val =  0.2013549\n",
      "epochs =  32 , step =  300 , loss_val =  0.2393367\n",
      "epochs =  32 , step =  400 , loss_val =  0.16233273\n",
      "epochs =  32 , step =  500 , loss_val =  0.19998966\n",
      "epochs =  33 , step =  0 , loss_val =  0.11448851\n",
      "epochs =  33 , step =  100 , loss_val =  0.14080067\n",
      "epochs =  33 , step =  200 , loss_val =  0.23244327\n",
      "epochs =  33 , step =  300 , loss_val =  0.15219314\n",
      "epochs =  33 , step =  400 , loss_val =  0.25041398\n",
      "epochs =  33 , step =  500 , loss_val =  0.12423838\n",
      "epochs =  34 , step =  0 , loss_val =  0.0999284\n",
      "epochs =  34 , step =  100 , loss_val =  0.13607252\n",
      "epochs =  34 , step =  200 , loss_val =  0.12070733\n",
      "epochs =  34 , step =  300 , loss_val =  0.19065338\n",
      "epochs =  34 , step =  400 , loss_val =  0.07218195\n",
      "epochs =  34 , step =  500 , loss_val =  0.2583573\n",
      "epochs =  35 , step =  0 , loss_val =  0.09260299\n",
      "epochs =  35 , step =  100 , loss_val =  0.11866148\n",
      "epochs =  35 , step =  200 , loss_val =  0.206944\n",
      "epochs =  35 , step =  300 , loss_val =  0.116843395\n",
      "epochs =  35 , step =  400 , loss_val =  0.27549195\n",
      "epochs =  35 , step =  500 , loss_val =  0.11327273\n",
      "epochs =  36 , step =  0 , loss_val =  0.17322499\n",
      "epochs =  36 , step =  100 , loss_val =  0.14495745\n",
      "epochs =  36 , step =  200 , loss_val =  0.11805037\n",
      "epochs =  36 , step =  300 , loss_val =  0.18680899\n",
      "epochs =  36 , step =  400 , loss_val =  0.16614623\n",
      "epochs =  36 , step =  500 , loss_val =  0.14733288\n",
      "epochs =  37 , step =  0 , loss_val =  0.1642788\n",
      "epochs =  37 , step =  100 , loss_val =  0.1637147\n",
      "epochs =  37 , step =  200 , loss_val =  0.34801716\n",
      "epochs =  37 , step =  300 , loss_val =  0.11323635\n",
      "epochs =  37 , step =  400 , loss_val =  0.053228483\n",
      "epochs =  37 , step =  500 , loss_val =  0.11268213\n",
      "epochs =  38 , step =  0 , loss_val =  0.07848364\n",
      "epochs =  38 , step =  100 , loss_val =  0.15965872\n",
      "epochs =  38 , step =  200 , loss_val =  0.18284346\n",
      "epochs =  38 , step =  300 , loss_val =  0.15054022\n",
      "epochs =  38 , step =  400 , loss_val =  0.17047963\n",
      "epochs =  38 , step =  500 , loss_val =  0.06606431\n",
      "epochs =  39 , step =  0 , loss_val =  0.16318959\n",
      "epochs =  39 , step =  100 , loss_val =  0.15298326\n",
      "epochs =  39 , step =  200 , loss_val =  0.38776436\n",
      "epochs =  39 , step =  300 , loss_val =  0.08822113\n",
      "epochs =  39 , step =  400 , loss_val =  0.14887702\n",
      "epochs =  39 , step =  500 , loss_val =  0.06913806\n",
      "epochs =  40 , step =  0 , loss_val =  0.1282531\n",
      "epochs =  40 , step =  100 , loss_val =  0.23536368\n",
      "epochs =  40 , step =  200 , loss_val =  0.17530058\n",
      "epochs =  40 , step =  300 , loss_val =  0.2916961\n",
      "epochs =  40 , step =  400 , loss_val =  0.11860087\n",
      "epochs =  40 , step =  500 , loss_val =  0.13856697\n",
      "epochs =  41 , step =  0 , loss_val =  0.15493776\n",
      "epochs =  41 , step =  100 , loss_val =  0.22037385\n",
      "epochs =  41 , step =  200 , loss_val =  0.05679462\n",
      "epochs =  41 , step =  300 , loss_val =  0.041652605\n",
      "epochs =  41 , step =  400 , loss_val =  0.10378556\n",
      "epochs =  41 , step =  500 , loss_val =  0.2795034\n",
      "epochs =  42 , step =  0 , loss_val =  0.13862659\n",
      "epochs =  42 , step =  100 , loss_val =  0.13997366\n",
      "epochs =  42 , step =  200 , loss_val =  0.19162412\n",
      "epochs =  42 , step =  300 , loss_val =  0.16173336\n",
      "epochs =  42 , step =  400 , loss_val =  0.1303031\n",
      "epochs =  42 , step =  500 , loss_val =  0.18535936\n",
      "epochs =  43 , step =  0 , loss_val =  0.08800309\n",
      "epochs =  43 , step =  100 , loss_val =  0.21438366\n",
      "epochs =  43 , step =  200 , loss_val =  0.2052955\n",
      "epochs =  43 , step =  300 , loss_val =  0.11310285\n",
      "epochs =  43 , step =  400 , loss_val =  0.13580917\n",
      "epochs =  43 , step =  500 , loss_val =  0.10393194\n",
      "epochs =  44 , step =  0 , loss_val =  0.2798134\n",
      "epochs =  44 , step =  100 , loss_val =  0.1951926\n",
      "epochs =  44 , step =  200 , loss_val =  0.16609472\n",
      "epochs =  44 , step =  300 , loss_val =  0.2086256\n",
      "epochs =  44 , step =  400 , loss_val =  0.071446694\n",
      "epochs =  44 , step =  500 , loss_val =  0.14906356\n",
      "epochs =  45 , step =  0 , loss_val =  0.16237989\n",
      "epochs =  45 , step =  100 , loss_val =  0.07664562\n",
      "epochs =  45 , step =  200 , loss_val =  0.08352525\n",
      "epochs =  45 , step =  300 , loss_val =  0.060941886\n",
      "epochs =  45 , step =  400 , loss_val =  0.15603133\n",
      "epochs =  45 , step =  500 , loss_val =  0.13445291\n",
      "epochs =  46 , step =  0 , loss_val =  0.06006316\n",
      "epochs =  46 , step =  100 , loss_val =  0.14965601\n",
      "epochs =  46 , step =  200 , loss_val =  0.14021464\n",
      "epochs =  46 , step =  300 , loss_val =  0.13812122\n",
      "epochs =  46 , step =  400 , loss_val =  0.1421666\n",
      "epochs =  46 , step =  500 , loss_val =  0.11728243\n",
      "epochs =  47 , step =  0 , loss_val =  0.070097595\n",
      "epochs =  47 , step =  100 , loss_val =  0.1109896\n",
      "epochs =  47 , step =  200 , loss_val =  0.13173826\n",
      "epochs =  47 , step =  300 , loss_val =  0.12368679\n",
      "epochs =  47 , step =  400 , loss_val =  0.135281\n",
      "epochs =  47 , step =  500 , loss_val =  0.12466598\n",
      "epochs =  48 , step =  0 , loss_val =  0.15482706\n",
      "epochs =  48 , step =  100 , loss_val =  0.14102764\n",
      "epochs =  48 , step =  200 , loss_val =  0.1591385\n",
      "epochs =  48 , step =  300 , loss_val =  0.1797846\n",
      "epochs =  48 , step =  400 , loss_val =  0.034940835\n",
      "epochs =  48 , step =  500 , loss_val =  0.37023556\n",
      "epochs =  49 , step =  0 , loss_val =  0.24706043\n",
      "epochs =  49 , step =  100 , loss_val =  0.18772657\n",
      "epochs =  49 , step =  200 , loss_val =  0.1172962\n",
      "epochs =  49 , step =  300 , loss_val =  0.18635587\n",
      "epochs =  49 , step =  400 , loss_val =  0.3771392\n",
      "epochs =  49 , step =  500 , loss_val =  0.25630105\n",
      "epochs =  50 , step =  0 , loss_val =  0.11294992\n",
      "epochs =  50 , step =  100 , loss_val =  0.20563744\n",
      "epochs =  50 , step =  200 , loss_val =  0.05774342\n",
      "epochs =  50 , step =  300 , loss_val =  0.08634723\n",
      "epochs =  50 , step =  400 , loss_val =  0.17236428\n",
      "epochs =  50 , step =  500 , loss_val =  0.056976937\n",
      "epochs =  51 , step =  0 , loss_val =  0.1040412\n",
      "epochs =  51 , step =  100 , loss_val =  0.050135225\n",
      "epochs =  51 , step =  200 , loss_val =  0.15757698\n",
      "epochs =  51 , step =  300 , loss_val =  0.087972276\n",
      "epochs =  51 , step =  400 , loss_val =  0.13107169\n",
      "epochs =  51 , step =  500 , loss_val =  0.07771399\n",
      "epochs =  52 , step =  0 , loss_val =  0.050392076\n",
      "epochs =  52 , step =  100 , loss_val =  0.15246457\n",
      "epochs =  52 , step =  200 , loss_val =  0.1280828\n",
      "epochs =  52 , step =  300 , loss_val =  0.18780062\n",
      "epochs =  52 , step =  400 , loss_val =  0.09209797\n",
      "epochs =  52 , step =  500 , loss_val =  0.20895663\n",
      "epochs =  53 , step =  0 , loss_val =  0.07461538\n",
      "epochs =  53 , step =  100 , loss_val =  0.10479348\n",
      "epochs =  53 , step =  200 , loss_val =  0.059179097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  53 , step =  300 , loss_val =  0.107924774\n",
      "epochs =  53 , step =  400 , loss_val =  0.06888231\n",
      "epochs =  53 , step =  500 , loss_val =  0.092082046\n",
      "epochs =  54 , step =  0 , loss_val =  0.12451239\n",
      "epochs =  54 , step =  100 , loss_val =  0.13977276\n",
      "epochs =  54 , step =  200 , loss_val =  0.08595316\n",
      "epochs =  54 , step =  300 , loss_val =  0.059320845\n",
      "epochs =  54 , step =  400 , loss_val =  0.10619841\n",
      "epochs =  54 , step =  500 , loss_val =  0.14009032\n",
      "epochs =  55 , step =  0 , loss_val =  0.12671046\n",
      "epochs =  55 , step =  100 , loss_val =  0.08521189\n",
      "epochs =  55 , step =  200 , loss_val =  0.106811106\n",
      "epochs =  55 , step =  300 , loss_val =  0.08055915\n",
      "epochs =  55 , step =  400 , loss_val =  0.082001284\n",
      "epochs =  55 , step =  500 , loss_val =  0.33866334\n",
      "epochs =  56 , step =  0 , loss_val =  0.09275665\n",
      "epochs =  56 , step =  100 , loss_val =  0.25343814\n",
      "epochs =  56 , step =  200 , loss_val =  0.084559985\n",
      "epochs =  56 , step =  300 , loss_val =  0.036792684\n",
      "epochs =  56 , step =  400 , loss_val =  0.027325034\n",
      "epochs =  56 , step =  500 , loss_val =  0.21247536\n",
      "epochs =  57 , step =  0 , loss_val =  0.03841992\n",
      "epochs =  57 , step =  100 , loss_val =  0.11406295\n",
      "epochs =  57 , step =  200 , loss_val =  0.12753755\n",
      "epochs =  57 , step =  300 , loss_val =  0.06836757\n",
      "epochs =  57 , step =  400 , loss_val =  0.115944296\n",
      "epochs =  57 , step =  500 , loss_val =  0.092823684\n",
      "epochs =  58 , step =  0 , loss_val =  0.08587484\n",
      "epochs =  58 , step =  100 , loss_val =  0.07884009\n",
      "epochs =  58 , step =  200 , loss_val =  0.15162262\n",
      "epochs =  58 , step =  300 , loss_val =  0.17038849\n",
      "epochs =  58 , step =  400 , loss_val =  0.11605621\n",
      "epochs =  58 , step =  500 , loss_val =  0.121994905\n",
      "epochs =  59 , step =  0 , loss_val =  0.12904078\n",
      "epochs =  59 , step =  100 , loss_val =  0.13095304\n",
      "epochs =  59 , step =  200 , loss_val =  0.099654205\n",
      "epochs =  59 , step =  300 , loss_val =  0.09571495\n",
      "epochs =  59 , step =  400 , loss_val =  0.07557053\n",
      "epochs =  59 , step =  500 , loss_val =  0.113762856\n",
      "epochs =  60 , step =  0 , loss_val =  0.12812613\n",
      "epochs =  60 , step =  100 , loss_val =  0.2916391\n",
      "epochs =  60 , step =  200 , loss_val =  0.26948455\n",
      "epochs =  60 , step =  300 , loss_val =  0.18711588\n",
      "epochs =  60 , step =  400 , loss_val =  0.11157835\n",
      "epochs =  60 , step =  500 , loss_val =  0.1223492\n",
      "epochs =  61 , step =  0 , loss_val =  0.14940637\n",
      "epochs =  61 , step =  100 , loss_val =  0.16106448\n",
      "epochs =  61 , step =  200 , loss_val =  0.094211124\n",
      "epochs =  61 , step =  300 , loss_val =  0.12993938\n",
      "epochs =  61 , step =  400 , loss_val =  0.23347941\n",
      "epochs =  61 , step =  500 , loss_val =  0.09510312\n",
      "epochs =  62 , step =  0 , loss_val =  0.12070135\n",
      "epochs =  62 , step =  100 , loss_val =  0.16749023\n",
      "epochs =  62 , step =  200 , loss_val =  0.1531849\n",
      "epochs =  62 , step =  300 , loss_val =  0.023981951\n",
      "epochs =  62 , step =  400 , loss_val =  0.034446105\n",
      "epochs =  62 , step =  500 , loss_val =  0.07079308\n",
      "epochs =  63 , step =  0 , loss_val =  0.20815855\n",
      "epochs =  63 , step =  100 , loss_val =  0.18353672\n",
      "epochs =  63 , step =  200 , loss_val =  0.12715998\n",
      "epochs =  63 , step =  300 , loss_val =  0.18441841\n",
      "epochs =  63 , step =  400 , loss_val =  0.08165887\n",
      "epochs =  63 , step =  500 , loss_val =  0.10386677\n",
      "epochs =  64 , step =  0 , loss_val =  0.15316048\n",
      "epochs =  64 , step =  100 , loss_val =  0.14033389\n",
      "epochs =  64 , step =  200 , loss_val =  0.14755529\n",
      "epochs =  64 , step =  300 , loss_val =  0.09400136\n",
      "epochs =  64 , step =  400 , loss_val =  0.047858022\n",
      "epochs =  64 , step =  500 , loss_val =  0.059491105\n",
      "epochs =  65 , step =  0 , loss_val =  0.14516042\n",
      "epochs =  65 , step =  100 , loss_val =  0.056605473\n",
      "epochs =  65 , step =  200 , loss_val =  0.051875144\n",
      "epochs =  65 , step =  300 , loss_val =  0.23412712\n",
      "epochs =  65 , step =  400 , loss_val =  0.06226306\n",
      "epochs =  65 , step =  500 , loss_val =  0.16501547\n",
      "epochs =  66 , step =  0 , loss_val =  0.084022276\n",
      "epochs =  66 , step =  100 , loss_val =  0.01851585\n",
      "epochs =  66 , step =  200 , loss_val =  0.07920612\n",
      "epochs =  66 , step =  300 , loss_val =  0.120600335\n",
      "epochs =  66 , step =  400 , loss_val =  0.2017295\n",
      "epochs =  66 , step =  500 , loss_val =  0.055079125\n",
      "epochs =  67 , step =  0 , loss_val =  0.043481037\n",
      "epochs =  67 , step =  100 , loss_val =  0.21657658\n",
      "epochs =  67 , step =  200 , loss_val =  0.11259928\n",
      "epochs =  67 , step =  300 , loss_val =  0.042481642\n",
      "epochs =  67 , step =  400 , loss_val =  0.22638932\n",
      "epochs =  67 , step =  500 , loss_val =  0.06950262\n",
      "epochs =  68 , step =  0 , loss_val =  0.05180773\n",
      "epochs =  68 , step =  100 , loss_val =  0.055623278\n",
      "epochs =  68 , step =  200 , loss_val =  0.15425731\n",
      "epochs =  68 , step =  300 , loss_val =  0.099797934\n",
      "epochs =  68 , step =  400 , loss_val =  0.13985294\n",
      "epochs =  68 , step =  500 , loss_val =  0.03873206\n",
      "epochs =  69 , step =  0 , loss_val =  0.050731964\n",
      "epochs =  69 , step =  100 , loss_val =  0.1277122\n",
      "epochs =  69 , step =  200 , loss_val =  0.038838755\n",
      "epochs =  69 , step =  300 , loss_val =  0.046306506\n",
      "epochs =  69 , step =  400 , loss_val =  0.16693753\n",
      "epochs =  69 , step =  500 , loss_val =  0.24575095\n",
      "epochs =  70 , step =  0 , loss_val =  0.07239199\n",
      "epochs =  70 , step =  100 , loss_val =  0.2728382\n",
      "epochs =  70 , step =  200 , loss_val =  0.07791823\n",
      "epochs =  70 , step =  300 , loss_val =  0.19182675\n",
      "epochs =  70 , step =  400 , loss_val =  0.11478094\n",
      "epochs =  70 , step =  500 , loss_val =  0.055140153\n",
      "epochs =  71 , step =  0 , loss_val =  0.044614542\n",
      "epochs =  71 , step =  100 , loss_val =  0.16021433\n",
      "epochs =  71 , step =  200 , loss_val =  0.17828193\n",
      "epochs =  71 , step =  300 , loss_val =  0.048169203\n",
      "epochs =  71 , step =  400 , loss_val =  0.040994205\n",
      "epochs =  71 , step =  500 , loss_val =  0.085382976\n",
      "epochs =  72 , step =  0 , loss_val =  0.18530273\n",
      "epochs =  72 , step =  100 , loss_val =  0.025918767\n",
      "epochs =  72 , step =  200 , loss_val =  0.13395835\n",
      "epochs =  72 , step =  300 , loss_val =  0.16610014\n",
      "epochs =  72 , step =  400 , loss_val =  0.14622466\n",
      "epochs =  72 , step =  500 , loss_val =  0.046594154\n",
      "epochs =  73 , step =  0 , loss_val =  0.1290736\n",
      "epochs =  73 , step =  100 , loss_val =  0.24041317\n",
      "epochs =  73 , step =  200 , loss_val =  0.08866724\n",
      "epochs =  73 , step =  300 , loss_val =  0.19013481\n",
      "epochs =  73 , step =  400 , loss_val =  0.089180015\n",
      "epochs =  73 , step =  500 , loss_val =  0.051140223\n",
      "epochs =  74 , step =  0 , loss_val =  0.04952031\n",
      "epochs =  74 , step =  100 , loss_val =  0.14579113\n",
      "epochs =  74 , step =  200 , loss_val =  0.03330767\n",
      "epochs =  74 , step =  300 , loss_val =  0.12219476\n",
      "epochs =  74 , step =  400 , loss_val =  0.058224104\n",
      "epochs =  74 , step =  500 , loss_val =  0.07704708\n",
      "epochs =  75 , step =  0 , loss_val =  0.03166699\n",
      "epochs =  75 , step =  100 , loss_val =  0.020082913\n",
      "epochs =  75 , step =  200 , loss_val =  0.16310193\n",
      "epochs =  75 , step =  300 , loss_val =  0.096730195\n",
      "epochs =  75 , step =  400 , loss_val =  0.07188566\n",
      "epochs =  75 , step =  500 , loss_val =  0.21889603\n",
      "epochs =  76 , step =  0 , loss_val =  0.067344874\n",
      "epochs =  76 , step =  100 , loss_val =  0.11421125\n",
      "epochs =  76 , step =  200 , loss_val =  0.054366313\n",
      "epochs =  76 , step =  300 , loss_val =  0.1339677\n",
      "epochs =  76 , step =  400 , loss_val =  0.080821045\n",
      "epochs =  76 , step =  500 , loss_val =  0.035654187\n",
      "epochs =  77 , step =  0 , loss_val =  0.10634457\n",
      "epochs =  77 , step =  100 , loss_val =  0.091134876\n",
      "epochs =  77 , step =  200 , loss_val =  0.04290128\n",
      "epochs =  77 , step =  300 , loss_val =  0.10109844\n",
      "epochs =  77 , step =  400 , loss_val =  0.069292285\n",
      "epochs =  77 , step =  500 , loss_val =  0.050335437\n",
      "epochs =  78 , step =  0 , loss_val =  0.013522084\n",
      "epochs =  78 , step =  100 , loss_val =  0.2351524\n",
      "epochs =  78 , step =  200 , loss_val =  0.10754952\n",
      "epochs =  78 , step =  300 , loss_val =  0.048311315\n",
      "epochs =  78 , step =  400 , loss_val =  0.17663752\n",
      "epochs =  78 , step =  500 , loss_val =  0.057189178\n",
      "epochs =  79 , step =  0 , loss_val =  0.025572574\n",
      "epochs =  79 , step =  100 , loss_val =  0.20066188\n",
      "epochs =  79 , step =  200 , loss_val =  0.11032625\n",
      "epochs =  79 , step =  300 , loss_val =  0.30632722\n",
      "epochs =  79 , step =  400 , loss_val =  0.06679873\n",
      "epochs =  79 , step =  500 , loss_val =  0.087008625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  80 , step =  0 , loss_val =  0.020421034\n",
      "epochs =  80 , step =  100 , loss_val =  0.12468552\n",
      "epochs =  80 , step =  200 , loss_val =  0.050950002\n",
      "epochs =  80 , step =  300 , loss_val =  0.12551923\n",
      "epochs =  80 , step =  400 , loss_val =  0.0711909\n",
      "epochs =  80 , step =  500 , loss_val =  0.23583202\n",
      "epochs =  81 , step =  0 , loss_val =  0.10618237\n",
      "epochs =  81 , step =  100 , loss_val =  0.043490183\n",
      "epochs =  81 , step =  200 , loss_val =  0.09239317\n",
      "epochs =  81 , step =  300 , loss_val =  0.1124493\n",
      "epochs =  81 , step =  400 , loss_val =  0.15708047\n",
      "epochs =  81 , step =  500 , loss_val =  0.031167962\n",
      "epochs =  82 , step =  0 , loss_val =  0.090639\n",
      "epochs =  82 , step =  100 , loss_val =  0.0900324\n",
      "epochs =  82 , step =  200 , loss_val =  0.08878086\n",
      "epochs =  82 , step =  300 , loss_val =  0.16917332\n",
      "epochs =  82 , step =  400 , loss_val =  0.0745435\n",
      "epochs =  82 , step =  500 , loss_val =  0.024458423\n",
      "epochs =  83 , step =  0 , loss_val =  0.06057944\n",
      "epochs =  83 , step =  100 , loss_val =  0.1678338\n",
      "epochs =  83 , step =  200 , loss_val =  0.099447295\n",
      "epochs =  83 , step =  300 , loss_val =  0.25317627\n",
      "epochs =  83 , step =  400 , loss_val =  0.035946652\n",
      "epochs =  83 , step =  500 , loss_val =  0.19118972\n",
      "epochs =  84 , step =  0 , loss_val =  0.047566634\n",
      "epochs =  84 , step =  100 , loss_val =  0.10053194\n",
      "epochs =  84 , step =  200 , loss_val =  0.031871915\n",
      "epochs =  84 , step =  300 , loss_val =  0.14125614\n",
      "epochs =  84 , step =  400 , loss_val =  0.10499742\n",
      "epochs =  84 , step =  500 , loss_val =  0.12567194\n",
      "epochs =  85 , step =  0 , loss_val =  0.019164417\n",
      "epochs =  85 , step =  100 , loss_val =  0.058458034\n",
      "epochs =  85 , step =  200 , loss_val =  0.11157131\n",
      "epochs =  85 , step =  300 , loss_val =  0.11138303\n",
      "epochs =  85 , step =  400 , loss_val =  0.09683964\n",
      "epochs =  85 , step =  500 , loss_val =  0.051068068\n",
      "epochs =  86 , step =  0 , loss_val =  0.05611551\n",
      "epochs =  86 , step =  100 , loss_val =  0.14581218\n",
      "epochs =  86 , step =  200 , loss_val =  0.27171886\n",
      "epochs =  86 , step =  300 , loss_val =  0.0740869\n",
      "epochs =  86 , step =  400 , loss_val =  0.12267659\n",
      "epochs =  86 , step =  500 , loss_val =  0.22675262\n",
      "epochs =  87 , step =  0 , loss_val =  0.05283974\n",
      "epochs =  87 , step =  100 , loss_val =  0.088265255\n",
      "epochs =  87 , step =  200 , loss_val =  0.06923968\n",
      "epochs =  87 , step =  300 , loss_val =  0.11316941\n",
      "epochs =  87 , step =  400 , loss_val =  0.04218612\n",
      "epochs =  87 , step =  500 , loss_val =  0.049036402\n",
      "epochs =  88 , step =  0 , loss_val =  0.014839565\n",
      "epochs =  88 , step =  100 , loss_val =  0.13169283\n",
      "epochs =  88 , step =  200 , loss_val =  0.08651155\n",
      "epochs =  88 , step =  300 , loss_val =  0.11550858\n",
      "epochs =  88 , step =  400 , loss_val =  0.16645351\n",
      "epochs =  88 , step =  500 , loss_val =  0.062384196\n",
      "epochs =  89 , step =  0 , loss_val =  0.123149544\n",
      "epochs =  89 , step =  100 , loss_val =  0.05876024\n",
      "epochs =  89 , step =  200 , loss_val =  0.114962146\n",
      "epochs =  89 , step =  300 , loss_val =  0.08771201\n",
      "epochs =  89 , step =  400 , loss_val =  0.13241528\n",
      "epochs =  89 , step =  500 , loss_val =  0.11395836\n",
      "epochs =  90 , step =  0 , loss_val =  0.062263217\n",
      "epochs =  90 , step =  100 , loss_val =  0.060316782\n",
      "epochs =  90 , step =  200 , loss_val =  0.035787545\n",
      "epochs =  90 , step =  300 , loss_val =  0.1950409\n",
      "epochs =  90 , step =  400 , loss_val =  0.12682132\n",
      "epochs =  90 , step =  500 , loss_val =  0.25239033\n",
      "epochs =  91 , step =  0 , loss_val =  0.0512351\n",
      "epochs =  91 , step =  100 , loss_val =  0.05004321\n",
      "epochs =  91 , step =  200 , loss_val =  0.037871942\n",
      "epochs =  91 , step =  300 , loss_val =  0.07708925\n",
      "epochs =  91 , step =  400 , loss_val =  0.117601134\n",
      "epochs =  91 , step =  500 , loss_val =  0.0352648\n",
      "epochs =  92 , step =  0 , loss_val =  0.10172259\n",
      "epochs =  92 , step =  100 , loss_val =  0.17359965\n",
      "epochs =  92 , step =  200 , loss_val =  0.0637427\n",
      "epochs =  92 , step =  300 , loss_val =  0.11792969\n",
      "epochs =  92 , step =  400 , loss_val =  0.09395504\n",
      "epochs =  92 , step =  500 , loss_val =  0.07037155\n",
      "epochs =  93 , step =  0 , loss_val =  0.08541723\n",
      "epochs =  93 , step =  100 , loss_val =  0.13310914\n",
      "epochs =  93 , step =  200 , loss_val =  0.13585064\n",
      "epochs =  93 , step =  300 , loss_val =  0.07915414\n",
      "epochs =  93 , step =  400 , loss_val =  0.09957201\n",
      "epochs =  93 , step =  500 , loss_val =  0.037282236\n",
      "epochs =  94 , step =  0 , loss_val =  0.10816271\n",
      "epochs =  94 , step =  100 , loss_val =  0.20149422\n",
      "epochs =  94 , step =  200 , loss_val =  0.21074127\n",
      "epochs =  94 , step =  300 , loss_val =  0.04157909\n",
      "epochs =  94 , step =  400 , loss_val =  0.030370822\n",
      "epochs =  94 , step =  500 , loss_val =  0.08430037\n",
      "epochs =  95 , step =  0 , loss_val =  0.11500206\n",
      "epochs =  95 , step =  100 , loss_val =  0.12229435\n",
      "epochs =  95 , step =  200 , loss_val =  0.22234534\n",
      "epochs =  95 , step =  300 , loss_val =  0.06919855\n",
      "epochs =  95 , step =  400 , loss_val =  0.0364294\n",
      "epochs =  95 , step =  500 , loss_val =  0.07853676\n",
      "epochs =  96 , step =  0 , loss_val =  0.07135571\n",
      "epochs =  96 , step =  100 , loss_val =  0.10959063\n",
      "epochs =  96 , step =  200 , loss_val =  0.055066336\n",
      "epochs =  96 , step =  300 , loss_val =  0.02821947\n",
      "epochs =  96 , step =  400 , loss_val =  0.06451315\n",
      "epochs =  96 , step =  500 , loss_val =  0.10843708\n",
      "epochs =  97 , step =  0 , loss_val =  0.110488504\n",
      "epochs =  97 , step =  100 , loss_val =  0.02918445\n",
      "epochs =  97 , step =  200 , loss_val =  0.20313211\n",
      "epochs =  97 , step =  300 , loss_val =  0.03761901\n",
      "epochs =  97 , step =  400 , loss_val =  0.090751894\n",
      "epochs =  97 , step =  500 , loss_val =  0.0129803885\n",
      "epochs =  98 , step =  0 , loss_val =  0.109160215\n",
      "epochs =  98 , step =  100 , loss_val =  0.05375248\n",
      "epochs =  98 , step =  200 , loss_val =  0.073266946\n",
      "epochs =  98 , step =  300 , loss_val =  0.049304523\n",
      "epochs =  98 , step =  400 , loss_val =  0.04933649\n",
      "epochs =  98 , step =  500 , loss_val =  0.24772476\n",
      "epochs =  99 , step =  0 , loss_val =  0.063616596\n",
      "epochs =  99 , step =  100 , loss_val =  0.03548033\n",
      "epochs =  99 , step =  200 , loss_val =  0.055583056\n",
      "epochs =  99 , step =  300 , loss_val =  0.07395302\n",
      "epochs =  99 , step =  400 , loss_val =  0.04240866\n",
      "epochs =  99 , step =  500 , loss_val =  0.09055372\n",
      "\n",
      "Elapsed Time :  0:01:02.396924\n",
      "\n",
      "\n",
      "Accuracy =  0.9533\n",
      "type(accuracy_val) =  <class 'numpy.float32'> , type(predicted_list_val) =  <class 'numpy.ndarray'> , type(index_label) =  [1. 1. 1. ... 1. 1. 1.]\n",
      "index_label.shape =  (10000,)\n",
      "length of index_label_list =  10000\n",
      "false label count =  467\n",
      "\n",
      "length of index_label_false_list_2 467\n",
      "\n",
      "length of index_label_false_list_2 467\n"
     ]
    }
   ],
   "source": [
    "index_label_false_list_1 = []\n",
    "index_label_false_list_2 = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs): # 100번 반복수행\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size) # 55,000 / 100\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            \n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict = {X : batch_x_data, T : batch_t_data})\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i ,\", step = \", step, \", loss_val = \", loss_val)\n",
    "            \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Elapsed Time : \", end_time - start_time)\n",
    "    print(\"\")\n",
    "    \n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images # 10000 x 784\n",
    "    test_t_data = mnist.test.labels # 10000 x 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, \n",
    "                    predicted_list, accuracy_index], feed_dict = {X : test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy = \", accuracy_val)\n",
    "    print(\"type(accuracy_val) = \", type(accuracy_val), \n",
    "          \", type(predicted_list_val) = \", type(predicted_list_val)\n",
    "         , ', type(index_label) = ', index_label)\n",
    "    print(\"index_label.shape = \", index_label.shape)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "    \n",
    "    #list type 으로 디버그\n",
    "    \n",
    "    for index in range(len(index_label_list)):\n",
    "        \n",
    "        if index_label_list[index] == 0:\n",
    "            \n",
    "            index_label_false_list_1.append([index, np.argmax(test_t_data[index]), predicted_list_val[index]])\n",
    "            \n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list_2\", len(index_label_false_list_1))\n",
    "\n",
    "    # numpy type 으로 디버그\n",
    "    \n",
    "    for index in range(len(index_label)):\n",
    "        \n",
    "        if index_label[index] == 0:\n",
    "            \n",
    "            index_label_false_list_2.append([index, np.argmax(test_t_data[index]), predicted_list_val[index]])\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list_2\", len(index_label_false_list_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 5, 8], [20, 9, 7], [92, 9, 4], [149, 2, 9], [151, 9, 8], [195, 3, 5], [241, 9, 5], [247, 4, 2], [259, 6, 0], [320, 9, 7], [321, 2, 7], [326, 2, 6], [340, 5, 3], [341, 6, 2], [381, 3, 7], [439, 6, 5], [445, 6, 0], [449, 3, 5], [511, 4, 8], [528, 3, 7], [542, 8, 5], [551, 7, 3], [565, 4, 9], [582, 8, 1], [591, 8, 3], [610, 4, 2], [613, 2, 8], [629, 2, 4], [646, 2, 6], [655, 8, 2], [659, 2, 3], [684, 7, 3], [691, 8, 4], [707, 4, 9], [717, 0, 6], [720, 5, 8], [740, 4, 9], [774, 4, 9], [810, 7, 2], [832, 7, 9], [839, 8, 3], [844, 8, 7], [866, 5, 8], [877, 8, 5], [882, 9, 4], [900, 1, 3], [938, 3, 5], [951, 5, 4], [956, 1, 2], [1003, 5, 3], [1014, 6, 5], [1017, 6, 2], [1032, 5, 8], [1050, 2, 4], [1092, 3, 5], [1107, 9, 8], [1114, 3, 2], [1124, 8, 1], [1125, 8, 9], [1128, 3, 7], [1147, 4, 7], [1156, 7, 3], [1181, 6, 1], [1182, 6, 8], [1184, 2, 1], [1194, 7, 9], [1200, 8, 3], [1206, 7, 2], [1226, 7, 2], [1228, 9, 3], [1232, 9, 6], [1234, 8, 5], [1242, 4, 9], [1247, 9, 0], [1248, 8, 2], [1260, 7, 1], [1274, 4, 6], [1283, 7, 2], [1289, 5, 4], [1290, 3, 5], [1299, 5, 7], [1326, 7, 2], [1328, 7, 8], [1348, 2, 6], [1355, 7, 1], [1356, 2, 8], [1364, 8, 2], [1453, 4, 9], [1464, 8, 9], [1466, 5, 3], [1476, 5, 3], [1496, 7, 9], [1500, 7, 3], [1520, 7, 2], [1522, 7, 9], [1530, 8, 7], [1531, 3, 5], [1549, 4, 6], [1553, 9, 8], [1554, 9, 7], [1559, 9, 7], [1581, 7, 9], [1597, 9, 7], [1601, 3, 2], [1609, 2, 3], [1611, 3, 1], [1626, 6, 5], [1640, 9, 4], [1653, 5, 3], [1670, 5, 3], [1671, 7, 3], [1678, 2, 0], [1681, 3, 7], [1701, 4, 9], [1702, 8, 2], [1709, 9, 3], [1730, 3, 8], [1751, 4, 2], [1754, 7, 2], [1782, 8, 2], [1790, 2, 9], [1794, 0, 5], [1800, 6, 4], [1855, 8, 3], [1865, 4, 7], [1878, 8, 3], [1883, 7, 9], [1901, 9, 4], [1941, 7, 2], [1942, 8, 4], [1952, 9, 8], [1954, 5, 8], [1955, 8, 2], [1956, 4, 0], [1969, 6, 0], [1970, 5, 3], [1982, 6, 5], [2001, 5, 8], [2016, 7, 2], [2024, 7, 9], [2033, 0, 4], [2035, 5, 3], [2043, 4, 8], [2044, 2, 7], [2067, 0, 6], [2070, 7, 9], [2098, 2, 0], [2109, 3, 7], [2118, 6, 5], [2125, 5, 9], [2129, 9, 2], [2130, 4, 9], [2135, 6, 1], [2179, 8, 3], [2182, 1, 2], [2186, 2, 5], [2189, 9, 1], [2272, 8, 6], [2293, 9, 6], [2299, 2, 8], [2326, 0, 5], [2339, 5, 8], [2369, 5, 8], [2378, 0, 2], [2380, 9, 0], [2387, 9, 1], [2394, 4, 9], [2406, 9, 8], [2408, 3, 9], [2422, 6, 4], [2423, 8, 9], [2425, 8, 3], [2447, 4, 9], [2455, 0, 2], [2514, 4, 9], [2526, 5, 3], [2528, 9, 7], [2532, 6, 5], [2560, 3, 2], [2573, 5, 8], [2574, 5, 7], [2607, 7, 1], [2610, 2, 8], [2648, 9, 5], [2654, 6, 1], [2698, 5, 3], [2720, 9, 4], [2751, 6, 2], [2770, 3, 6], [2771, 4, 9], [2832, 5, 3], [2877, 4, 9], [2896, 8, 0], [2907, 4, 7], [2915, 7, 3], [2919, 5, 2], [2921, 3, 2], [2927, 3, 2], [2939, 9, 7], [2953, 3, 5], [2995, 6, 8], [3001, 9, 8], [3005, 9, 1], [3030, 6, 8], [3073, 1, 2], [3114, 4, 6], [3130, 6, 0], [3132, 1, 2], [3138, 3, 2], [3157, 5, 7], [3206, 8, 3], [3225, 7, 9], [3240, 9, 8], [3269, 6, 0], [3275, 5, 7], [3288, 4, 2], [3289, 8, 9], [3330, 2, 3], [3332, 4, 9], [3333, 7, 9], [3342, 6, 5], [3376, 7, 9], [3384, 2, 5], [3394, 9, 4], [3414, 5, 3], [3422, 6, 0], [3447, 6, 4], [3460, 9, 4], [3475, 3, 7], [3503, 9, 1], [3520, 6, 4], [3533, 4, 7], [3534, 4, 9], [3550, 6, 5], [3558, 5, 0], [3559, 8, 5], [3567, 8, 5], [3580, 7, 1], [3597, 9, 3], [3618, 9, 3], [3629, 8, 3], [3662, 8, 0], [3674, 8, 3], [3685, 4, 2], [3726, 4, 9], [3751, 7, 3], [3767, 7, 8], [3776, 5, 8], [3778, 5, 2], [3780, 4, 2], [3796, 2, 8], [3801, 6, 0], [3806, 5, 8], [3808, 7, 3], [3811, 2, 0], [3833, 8, 3], [3853, 6, 5], [3871, 8, 3], [3893, 5, 6], [3902, 5, 3], [3926, 9, 3], [3941, 4, 2], [3951, 8, 7], [3976, 7, 1], [3988, 8, 4], [4000, 9, 4], [4027, 7, 1], [4065, 0, 9], [4075, 8, 0], [4076, 5, 8], [4078, 9, 2], [4093, 9, 4], [4102, 7, 9], [4140, 8, 2], [4145, 8, 0], [4152, 5, 1], [4163, 9, 0], [4176, 2, 7], [4193, 6, 4], [4199, 7, 9], [4201, 1, 7], [4205, 2, 1], [4211, 6, 5], [4224, 9, 7], [4238, 7, 3], [4248, 2, 4], [4265, 4, 9], [4268, 4, 6], [4271, 5, 3], [4289, 2, 9], [4294, 9, 0], [4306, 3, 2], [4313, 4, 9], [4314, 9, 7], [4355, 5, 3], [4368, 5, 6], [4374, 5, 6], [4380, 8, 5], [4415, 2, 0], [4425, 9, 4], [4433, 7, 2], [4449, 6, 0], [4454, 9, 8], [4477, 0, 6], [4481, 4, 9], [4497, 8, 7], [4500, 9, 1], [4507, 1, 2], [4536, 6, 5], [4567, 4, 9], [4571, 6, 0], [4575, 4, 9], [4578, 7, 9], [4601, 8, 4], [4615, 2, 4], [4635, 3, 5], [4639, 8, 2], [4656, 2, 7], [4690, 7, 2], [4731, 8, 3], [4735, 9, 4], [4761, 9, 7], [4807, 8, 0], [4814, 6, 4], [4823, 9, 6], [4860, 4, 9], [4879, 8, 6], [4880, 0, 8], [4923, 0, 6], [4950, 2, 3], [4956, 8, 4], [4966, 7, 3], [4978, 8, 3], [4990, 3, 2], [5068, 4, 1], [5138, 8, 5], [5237, 3, 2], [5246, 7, 2], [5331, 1, 6], [5457, 1, 8], [5564, 4, 7], [5593, 0, 6], [5600, 7, 9], [5620, 7, 9], [5634, 2, 3], [5642, 1, 8], [5653, 0, 6], [5734, 3, 7], [5736, 6, 2], [5749, 8, 6], [5778, 0, 2], [5842, 4, 7], [5887, 7, 0], [5888, 4, 0], [5891, 5, 3], [5897, 9, 7], [5913, 5, 8], [5918, 0, 8], [5922, 5, 3], [5936, 4, 9], [5955, 3, 8], [5973, 3, 8], [5982, 5, 3], [5985, 5, 8], [6030, 3, 8], [6035, 2, 0], [6043, 5, 3], [6046, 3, 8], [6059, 3, 9], [6065, 3, 1], [6071, 9, 3], [6091, 9, 3], [6101, 1, 8], [6166, 9, 3], [6172, 9, 5], [6238, 8, 2], [6390, 5, 9], [6391, 2, 0], [6424, 0, 6], [6426, 0, 6], [6505, 9, 0], [6554, 2, 8], [6555, 8, 9], [6558, 6, 2], [6560, 9, 3], [6571, 9, 7], [6576, 7, 1], [6597, 0, 7], [6598, 5, 3], [6599, 7, 9], [6625, 8, 7], [6651, 0, 2], [6706, 5, 3], [6765, 8, 5], [6783, 1, 6], [6785, 2, 4], [6847, 6, 4], [6906, 2, 6], [7049, 0, 6], [7404, 6, 4], [7432, 7, 2], [7434, 4, 8], [7441, 6, 4], [7451, 5, 8], [7454, 5, 4], [7473, 4, 5], [7498, 5, 3], [7552, 8, 9], [7800, 3, 2], [7812, 1, 8], [7822, 1, 2], [7849, 3, 2], [7899, 1, 8], [7921, 8, 1], [7991, 9, 8], [8094, 2, 8], [8115, 3, 8], [8123, 6, 2], [8196, 6, 0], [8243, 0, 3], [8246, 3, 5], [8325, 0, 6], [8382, 0, 5], [8444, 5, 8], [8453, 5, 3], [8502, 5, 3], [8519, 7, 2], [8570, 3, 8], [8607, 3, 8], [9009, 7, 2], [9015, 7, 2], [9019, 7, 2], [9022, 3, 2], [9024, 7, 2], [9036, 7, 2], [9045, 7, 2], [9054, 9, 7], [9211, 4, 9], [9482, 5, 3], [9505, 7, 2], [9540, 1, 8], [9556, 1, 2], [9587, 9, 4], [9634, 0, 2], [9642, 9, 7], [9662, 3, 2], [9664, 2, 7], [9669, 4, 7], [9679, 6, 0], [9692, 9, 7], [9729, 5, 6], [9733, 9, 8], [9735, 4, 7], [9745, 4, 2], [9768, 2, 0], [9770, 5, 0], [9777, 5, 0], [9786, 5, 3], [9839, 2, 7], [9856, 9, 5], [9879, 0, 2], [9888, 6, 0], [9892, 8, 6], [9944, 3, 5], [9970, 5, 3], [9975, 3, 2], [9982, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_false_list_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 5, 8], [20, 9, 7], [92, 9, 4], [149, 2, 9], [151, 9, 8], [195, 3, 5], [241, 9, 5], [247, 4, 2], [259, 6, 0], [320, 9, 7], [321, 2, 7], [326, 2, 6], [340, 5, 3], [341, 6, 2], [381, 3, 7], [439, 6, 5], [445, 6, 0], [449, 3, 5], [511, 4, 8], [528, 3, 7], [542, 8, 5], [551, 7, 3], [565, 4, 9], [582, 8, 1], [591, 8, 3], [610, 4, 2], [613, 2, 8], [629, 2, 4], [646, 2, 6], [655, 8, 2], [659, 2, 3], [684, 7, 3], [691, 8, 4], [707, 4, 9], [717, 0, 6], [720, 5, 8], [740, 4, 9], [774, 4, 9], [810, 7, 2], [832, 7, 9], [839, 8, 3], [844, 8, 7], [866, 5, 8], [877, 8, 5], [882, 9, 4], [900, 1, 3], [938, 3, 5], [951, 5, 4], [956, 1, 2], [1003, 5, 3], [1014, 6, 5], [1017, 6, 2], [1032, 5, 8], [1050, 2, 4], [1092, 3, 5], [1107, 9, 8], [1114, 3, 2], [1124, 8, 1], [1125, 8, 9], [1128, 3, 7], [1147, 4, 7], [1156, 7, 3], [1181, 6, 1], [1182, 6, 8], [1184, 2, 1], [1194, 7, 9], [1200, 8, 3], [1206, 7, 2], [1226, 7, 2], [1228, 9, 3], [1232, 9, 6], [1234, 8, 5], [1242, 4, 9], [1247, 9, 0], [1248, 8, 2], [1260, 7, 1], [1274, 4, 6], [1283, 7, 2], [1289, 5, 4], [1290, 3, 5], [1299, 5, 7], [1326, 7, 2], [1328, 7, 8], [1348, 2, 6], [1355, 7, 1], [1356, 2, 8], [1364, 8, 2], [1453, 4, 9], [1464, 8, 9], [1466, 5, 3], [1476, 5, 3], [1496, 7, 9], [1500, 7, 3], [1520, 7, 2], [1522, 7, 9], [1530, 8, 7], [1531, 3, 5], [1549, 4, 6], [1553, 9, 8], [1554, 9, 7], [1559, 9, 7], [1581, 7, 9], [1597, 9, 7], [1601, 3, 2], [1609, 2, 3], [1611, 3, 1], [1626, 6, 5], [1640, 9, 4], [1653, 5, 3], [1670, 5, 3], [1671, 7, 3], [1678, 2, 0], [1681, 3, 7], [1701, 4, 9], [1702, 8, 2], [1709, 9, 3], [1730, 3, 8], [1751, 4, 2], [1754, 7, 2], [1782, 8, 2], [1790, 2, 9], [1794, 0, 5], [1800, 6, 4], [1855, 8, 3], [1865, 4, 7], [1878, 8, 3], [1883, 7, 9], [1901, 9, 4], [1941, 7, 2], [1942, 8, 4], [1952, 9, 8], [1954, 5, 8], [1955, 8, 2], [1956, 4, 0], [1969, 6, 0], [1970, 5, 3], [1982, 6, 5], [2001, 5, 8], [2016, 7, 2], [2024, 7, 9], [2033, 0, 4], [2035, 5, 3], [2043, 4, 8], [2044, 2, 7], [2067, 0, 6], [2070, 7, 9], [2098, 2, 0], [2109, 3, 7], [2118, 6, 5], [2125, 5, 9], [2129, 9, 2], [2130, 4, 9], [2135, 6, 1], [2179, 8, 3], [2182, 1, 2], [2186, 2, 5], [2189, 9, 1], [2272, 8, 6], [2293, 9, 6], [2299, 2, 8], [2326, 0, 5], [2339, 5, 8], [2369, 5, 8], [2378, 0, 2], [2380, 9, 0], [2387, 9, 1], [2394, 4, 9], [2406, 9, 8], [2408, 3, 9], [2422, 6, 4], [2423, 8, 9], [2425, 8, 3], [2447, 4, 9], [2455, 0, 2], [2514, 4, 9], [2526, 5, 3], [2528, 9, 7], [2532, 6, 5], [2560, 3, 2], [2573, 5, 8], [2574, 5, 7], [2607, 7, 1], [2610, 2, 8], [2648, 9, 5], [2654, 6, 1], [2698, 5, 3], [2720, 9, 4], [2751, 6, 2], [2770, 3, 6], [2771, 4, 9], [2832, 5, 3], [2877, 4, 9], [2896, 8, 0], [2907, 4, 7], [2915, 7, 3], [2919, 5, 2], [2921, 3, 2], [2927, 3, 2], [2939, 9, 7], [2953, 3, 5], [2995, 6, 8], [3001, 9, 8], [3005, 9, 1], [3030, 6, 8], [3073, 1, 2], [3114, 4, 6], [3130, 6, 0], [3132, 1, 2], [3138, 3, 2], [3157, 5, 7], [3206, 8, 3], [3225, 7, 9], [3240, 9, 8], [3269, 6, 0], [3275, 5, 7], [3288, 4, 2], [3289, 8, 9], [3330, 2, 3], [3332, 4, 9], [3333, 7, 9], [3342, 6, 5], [3376, 7, 9], [3384, 2, 5], [3394, 9, 4], [3414, 5, 3], [3422, 6, 0], [3447, 6, 4], [3460, 9, 4], [3475, 3, 7], [3503, 9, 1], [3520, 6, 4], [3533, 4, 7], [3534, 4, 9], [3550, 6, 5], [3558, 5, 0], [3559, 8, 5], [3567, 8, 5], [3580, 7, 1], [3597, 9, 3], [3618, 9, 3], [3629, 8, 3], [3662, 8, 0], [3674, 8, 3], [3685, 4, 2], [3726, 4, 9], [3751, 7, 3], [3767, 7, 8], [3776, 5, 8], [3778, 5, 2], [3780, 4, 2], [3796, 2, 8], [3801, 6, 0], [3806, 5, 8], [3808, 7, 3], [3811, 2, 0], [3833, 8, 3], [3853, 6, 5], [3871, 8, 3], [3893, 5, 6], [3902, 5, 3], [3926, 9, 3], [3941, 4, 2], [3951, 8, 7], [3976, 7, 1], [3988, 8, 4], [4000, 9, 4], [4027, 7, 1], [4065, 0, 9], [4075, 8, 0], [4076, 5, 8], [4078, 9, 2], [4093, 9, 4], [4102, 7, 9], [4140, 8, 2], [4145, 8, 0], [4152, 5, 1], [4163, 9, 0], [4176, 2, 7], [4193, 6, 4], [4199, 7, 9], [4201, 1, 7], [4205, 2, 1], [4211, 6, 5], [4224, 9, 7], [4238, 7, 3], [4248, 2, 4], [4265, 4, 9], [4268, 4, 6], [4271, 5, 3], [4289, 2, 9], [4294, 9, 0], [4306, 3, 2], [4313, 4, 9], [4314, 9, 7], [4355, 5, 3], [4368, 5, 6], [4374, 5, 6], [4380, 8, 5], [4415, 2, 0], [4425, 9, 4], [4433, 7, 2], [4449, 6, 0], [4454, 9, 8], [4477, 0, 6], [4481, 4, 9], [4497, 8, 7], [4500, 9, 1], [4507, 1, 2], [4536, 6, 5], [4567, 4, 9], [4571, 6, 0], [4575, 4, 9], [4578, 7, 9], [4601, 8, 4], [4615, 2, 4], [4635, 3, 5], [4639, 8, 2], [4656, 2, 7], [4690, 7, 2], [4731, 8, 3], [4735, 9, 4], [4761, 9, 7], [4807, 8, 0], [4814, 6, 4], [4823, 9, 6], [4860, 4, 9], [4879, 8, 6], [4880, 0, 8], [4923, 0, 6], [4950, 2, 3], [4956, 8, 4], [4966, 7, 3], [4978, 8, 3], [4990, 3, 2], [5068, 4, 1], [5138, 8, 5], [5237, 3, 2], [5246, 7, 2], [5331, 1, 6], [5457, 1, 8], [5564, 4, 7], [5593, 0, 6], [5600, 7, 9], [5620, 7, 9], [5634, 2, 3], [5642, 1, 8], [5653, 0, 6], [5734, 3, 7], [5736, 6, 2], [5749, 8, 6], [5778, 0, 2], [5842, 4, 7], [5887, 7, 0], [5888, 4, 0], [5891, 5, 3], [5897, 9, 7], [5913, 5, 8], [5918, 0, 8], [5922, 5, 3], [5936, 4, 9], [5955, 3, 8], [5973, 3, 8], [5982, 5, 3], [5985, 5, 8], [6030, 3, 8], [6035, 2, 0], [6043, 5, 3], [6046, 3, 8], [6059, 3, 9], [6065, 3, 1], [6071, 9, 3], [6091, 9, 3], [6101, 1, 8], [6166, 9, 3], [6172, 9, 5], [6238, 8, 2], [6390, 5, 9], [6391, 2, 0], [6424, 0, 6], [6426, 0, 6], [6505, 9, 0], [6554, 2, 8], [6555, 8, 9], [6558, 6, 2], [6560, 9, 3], [6571, 9, 7], [6576, 7, 1], [6597, 0, 7], [6598, 5, 3], [6599, 7, 9], [6625, 8, 7], [6651, 0, 2], [6706, 5, 3], [6765, 8, 5], [6783, 1, 6], [6785, 2, 4], [6847, 6, 4], [6906, 2, 6], [7049, 0, 6], [7404, 6, 4], [7432, 7, 2], [7434, 4, 8], [7441, 6, 4], [7451, 5, 8], [7454, 5, 4], [7473, 4, 5], [7498, 5, 3], [7552, 8, 9], [7800, 3, 2], [7812, 1, 8], [7822, 1, 2], [7849, 3, 2], [7899, 1, 8], [7921, 8, 1], [7991, 9, 8], [8094, 2, 8], [8115, 3, 8], [8123, 6, 2], [8196, 6, 0], [8243, 0, 3], [8246, 3, 5], [8325, 0, 6], [8382, 0, 5], [8444, 5, 8], [8453, 5, 3], [8502, 5, 3], [8519, 7, 2], [8570, 3, 8], [8607, 3, 8], [9009, 7, 2], [9015, 7, 2], [9019, 7, 2], [9022, 3, 2], [9024, 7, 2], [9036, 7, 2], [9045, 7, 2], [9054, 9, 7], [9211, 4, 9], [9482, 5, 3], [9505, 7, 2], [9540, 1, 8], [9556, 1, 2], [9587, 9, 4], [9634, 0, 2], [9642, 9, 7], [9662, 3, 2], [9664, 2, 7], [9669, 4, 7], [9679, 6, 0], [9692, 9, 7], [9729, 5, 6], [9733, 9, 8], [9735, 4, 7], [9745, 4, 2], [9768, 2, 0], [9770, 5, 0], [9777, 5, 0], [9786, 5, 3], [9839, 2, 7], [9856, 9, 5], [9879, 0, 2], [9888, 6, 0], [9892, 8, 6], [9944, 3, 5], [9970, 5, 3], [9975, 3, 2], [9982, 5, 6]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_false_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label =  3\n"
     ]
    }
   ],
   "source": [
    "# check false data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = test_x_data[9944].reshape(28,28)  \n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"label = \", np.argmax(test_t_data[9944]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label =  9\n"
     ]
    }
   ],
   "source": [
    "# check false data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = test_x_data[9918].reshape(28,28)  \n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"label = \", np.argmax(test_t_data[9918]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAN2ElEQVR4nO3dX6xV9ZnG8ecRxRDoBUggREFakGTGScQRjdE6YWLaOJoIXNSo0TiZBnqBCegkM9i5KGbU6DiduaxBi2VMsWmiHUltLErq6Bg1HgUVqlXGHOmphCNjYi0xdIB3Ls7CnOJZv3Xc/z3v95Oc7L3Xu9derzs+rLX2b+/1c0QIwNR3Wr8bANAbhB1IgrADSRB2IAnCDiRxei83ZpuP/oEuiwhPtLytPbvtq2z/xvZ+25vaeS0A3eVWx9ltT5P0jqRvSBqR9IqkGyLi14V12LMDXdaNPfslkvZHxHsR8UdJP5G0qo3XA9BF7YT9bEm/Hfd4pFr2J2yvsz1ke6iNbQFoUzsf0E10qPC5w/SI2CJpi8RhPNBP7ezZRyQtHPf4HEkftNcOgG5pJ+yvSDrP9ldtT5d0vaQdnWkLQKe1fBgfEcds3yrpl5KmSdoaEfs61hmAjmp56K2ljXHODnRdV75UA+DLg7ADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJHo6ZTMw3uzZs4v1RYsWdW3b77//frF+2223Fet79+4t1t95551i/fXXXy/Wu4E9O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kwTg72nLNNdcU69dee21tbeXKlcV1ly5d2kpLk9I0Dn7uuecW62eeeWZb2582bVpb67eirbDbHpb0iaTjko5FxIpONAWg8zqxZ//riDjcgdcB0EWcswNJtBv2kLTT9qu21030BNvrbA/ZHmpzWwDa0O5h/OUR8YHteZKetv12RDw3/gkRsUXSFkmyHW1uD0CL2tqzR8QH1e2opJ9JuqQTTQHovJbDbnum7a+cvC/pm5LKv/sD0DeOaO3I2vbXNLY3l8ZOB7ZHxN0N63AY32NLliwp1tevX1+sr127tlifMWNGsW67WM+qm+PsETHhm97yOXtEvCfpgpY7AtBTDL0BSRB2IAnCDiRB2IEkCDuQBD9xneLOOeecYn3Dhg096qT33n777dravn37etjJYGDPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM7eA3Pnzi3Wm8a6X3jhhWL9qaeeqq0dPXq0uO7HH39crB85cqRYnzlzZrG+c+fO2lrTtMcvv/xysb579+5i/dNPP62tNf13TUXs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiZYvJd3SxqbopaSbxpqff/75Yv2CC8oX6V2zZk2xvmPHjmK9ZPHixcX68PBwsb5o0aJifWRkpLZ24sSJ4rpoTd2lpNmzA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAS/J59kqZPn15b2759e3HdpnH0e+65p1h/5plnivV2NI2jNzlw4EBnGkHXNe7ZbW+1PWp777hlc2w/bfvd6nZ2d9sE0K7JHMb/SNJVpyzbJGlXRJwnaVf1GMAAawx7RDwn6aNTFq+StK26v03S6g73BaDDWj1nnx8RByUpIg7anlf3RNvrJK1rcTsAOqTrH9BFxBZJW6Sp+0MY4Mug1aG3Q7YXSFJ1O9q5lgB0Q6th3yHplur+LZKe6Ew7ALql8ffsth+VtFLSXEmHJH1P0n9K+qmkRZIOSPpWRJz6Id5ErzWwh/GzZs0q1u+4447a2qZN5cGIw4cPF+vLli0r1puu7Q6MV/d79sZz9oi4oaZ0ZVsdAegpvi4LJEHYgSQIO5AEYQeSIOxAEvzEtbJ6dfnr/aXhtaafeV5xxRXFOkNr6AX27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPslcsuu6zldXfv3l2sl6YtBnqFPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJNF4KemObmyALyU9Olqe5+Kss86qrR09erS47n333VesP/FE+bL7e/bsKdaB8eouJc2eHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJy90vQ+nDhxomvbbnrtBx54oFh/6aWXamuLFi0qrrt///5ifd++fcV6k/PPP7+29uKLLxbX5ToArWl5nN32VtujtveOW7bZ9u9s76n+ru5kswA6bzKH8T+SdNUEy/89IpZXf7/obFsAOq0x7BHxnKSPetALgC5q5wO6W22/UR3mz657ku11todsD7WxLQBtajXsP5C0RNJySQclfb/uiRGxJSJWRMSKFrcFoANaCntEHIqI4xFxQtKDki7pbFsAOq2lsNteMO7hGkl7654LYDA0jrPbflTSSklzJR2S9L3q8XJJIWlY0nci4mDjxgZ4nP3+++8v1m+//fYedZLHhx9+WKw/++yzxfr111/fwW6mjrpx9sZJIiLihgkW/7DtjgD0FF+XBZIg7EAShB1IgrADSRB2IAl+4lqZNm1asX7hhRfW1rZv315c9/TTy4MeCxcuLNZPOy3nv8lN/29u3ry5WL/rrrs62M2XB5eSBpIj7EAShB1IgrADSRB2IAnCDiRB2IEkGn/1lsXx48eL9aGh+qtqLVu2rK1tX3nllcX6GWecUayXxpsvvvjiVloaCPaEw8Wfueiii3rUydTAnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcfQDs2rWrrfWXL19eW2saZz927Fix/vDDDxfrDz74YLG+cePG2tqNN95YXBedxZ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnH0K2LlzZ23t7rvvLq7bdE37tWvXFutLly4t1leuXFmst2NkZKRrrz0VNe7ZbS+0/Svbb9neZ3tDtXyO7adtv1vdzu5+uwBaNZnD+GOS/j4i/kzSpZLW2/5zSZsk7YqI8yTtqh4DGFCNYY+IgxHxWnX/E0lvSTpb0ipJ26qnbZO0ultNAmjfFzpnt71Y0oWSXpY0PyIOSmP/INieV7POOknr2msTQLsmHXbbsyQ9JmljRPy+6WKAJ0XEFklbqtcY2IkdgaluUkNvts/QWNB/HBGPV4sP2V5Q1RdIGu1OiwA6oXHKZo/twrdJ+igiNo5bfr+k/42Ie21vkjQnIv6h4bXYs3fBjBkzamtbt24trnvdddd1up1Ja7p895NPPlms33TTTcX6kSNHvnBPU0HdlM2TOYy/XNLNkt60vada9l1J90r6qe1vSzog6VudaBRAdzSGPSL+W1LdCXp5dgMAA4OvywJJEHYgCcIOJEHYgSQIO5BE4zh7RzfGOHvPzZ8/v1h/6KGHivUVK1YU6/PmTfgt6c8MDw/X1h555JHiuqWpqFGvbpydPTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJME4O4puvvnmYv3SSy8t1u+8887a2ugo1zvpBsbZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmBKYZxdiA5wg4kQdiBJAg7kARhB5Ig7EAShB1IojHsthfa/pXtt2zvs72hWr7Z9u9s76n+ru5+uwBa1filGtsLJC2IiNdsf0XSq5JWS7pO0h8i4l8nvTG+VAN0Xd2XaiYzP/tBSQer+5/YfkvS2Z1tD0C3faFzdtuLJV0o6eVq0a2237C91fbsmnXW2R6yPdRWpwDaMunvxtueJem/JN0dEY/bni/psKSQ9M8aO9T/u4bX4DAe6LK6w/hJhd32GZJ+LumXEfFvE9QXS/p5RPxFw+sQdqDLWv4hjG1L+qGkt8YHvfrg7qQ1kva22ySA7pnMp/Ffl/S8pDclnagWf1fSDZKWa+wwfljSd6oP80qvxZ4d6LK2DuM7hbAD3cfv2YHkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0k0XnCyww5Len/c47nVskE0qL0Nal8SvbWqk72dW1fo6e/ZP7dxeygiVvStgYJB7W1Q+5LorVW96o3DeCAJwg4k0e+wb+nz9ksGtbdB7Uuit1b1pLe+nrMD6J1+79kB9AhhB5LoS9htX2X7N7b3297Ujx7q2B62/WY1DXVf56er5tAbtb133LI5tp+2/W51O+Ece33qbSCm8S5MM97X967f05/3/Jzd9jRJ70j6hqQRSa9IuiEift3TRmrYHpa0IiL6/gUM238l6Q+S/uPk1Fq2/0XSRxFxb/UP5eyI+McB6W2zvuA03l3qrW6a8b9VH9+7Tk5/3op+7NkvkbQ/It6LiD9K+omkVX3oY+BFxHOSPjpl8SpJ26r72zT2P0vP1fQ2ECLiYES8Vt3/RNLJacb7+t4V+uqJfoT9bEm/Hfd4RIM133tI2mn7Vdvr+t3MBOafnGarup3X535O1TiNdy+dMs34wLx3rUx/3q5+hH2iqWkGafzv8oj4S0l/I2l9dbiKyfmBpCUamwPwoKTv97OZaprxxyRtjIjf97OX8SboqyfvWz/CPiJp4bjH50j6oA99TCgiPqhuRyX9TGOnHYPk0MkZdKvb0T7385mIOBQRxyPihKQH1cf3rppm/DFJP46Ix6vFfX/vJuqrV+9bP8L+iqTzbH/V9nRJ10va0Yc+Psf2zOqDE9meKembGrypqHdIuqW6f4ukJ/rYy58YlGm866YZV5/fu75Pfx4RPf+TdLXGPpH/H0n/1I8eavr6mqTXq799/e5N0qMaO6z7P40dEX1b0lmSdkl6t7qdM0C9PaKxqb3f0FiwFvSpt69r7NTwDUl7qr+r+/3eFfrqyfvG12WBJPgGHZAEYQeSIOxAEoQdSIKwA0kQdiAJwg4k8f9a6WoZB87T3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label =  5\n"
     ]
    }
   ],
   "source": [
    "# check false data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "img = test_x_data[8].reshape(28,28)  \n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"label = \", np.argmax(test_t_data[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
