{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [[0.56936331]] , W.shape = (1, 1) ,b=  [0.22104268] ,b.shape = (1,)\n",
      "initial error value = 54.090608128990915 Initial W =  [[0.56936331]] \n",
      " , b =  [0.22104268]\n",
      "step = 0 error value =  32.20496731844456 W =  [[1.05084082]] , b =  [0.33357138]\n",
      "step = 400 error value =  0.06263508862278956 W =  [[2.16251954]] , b =  [2.41339651]\n",
      "step = 800 error value =  0.00399648895105242 W =  [[2.04105216]] , b =  [2.85182494]\n",
      "step = 1200 error value =  0.0002549996222094928 W =  [[2.01036971]] , b =  [2.96257123]\n",
      "step = 1600 error value =  1.6270483447705125e-05 W =  [[2.00261937]] , b =  [2.99054556]\n",
      "step = 2000 error value =  1.0381530346112066e-06 W =  [[2.00066165]] , b =  [2.99761182]\n",
      "step = 2400 error value =  6.624030114053919e-08 W =  [[2.00016713]] , b =  [2.99939675]\n",
      "step = 2800 error value =  4.2265228234852405e-09 W =  [[2.00004222]] , b =  [2.99984762]\n",
      "step = 3200 error value =  2.696771431930466e-10 W =  [[2.00001066]] , b =  [2.99996151]\n",
      "step = 3600 error value =  1.7206996054915108e-11 W =  [[2.00000269]] , b =  [2.99999028]\n",
      "step = 4000 error value =  1.097908075618105e-12 W =  [[2.00000068]] , b =  [2.99999754]\n",
      "step = 4400 error value =  7.005302575932781e-14 W =  [[2.00000017]] , b =  [2.99999938]\n",
      "step = 4800 error value =  4.4697972321825374e-15 W =  [[2.00000004]] , b =  [2.99999984]\n",
      "step = 5200 error value =  2.8519947712703334e-16 W =  [[2.00000001]] , b =  [2.99999996]\n",
      "step = 5600 error value =  1.8197411865630178e-17 W =  [[2.]] , b =  [2.99999999]\n",
      "step = 6000 error value =  1.1611012780674758e-18 W =  [[2.]] , b =  [3.]\n",
      "step = 6400 error value =  7.4084936890411e-20 W =  [[2.]] , b =  [3.]\n",
      "step = 6800 error value =  4.726959570027552e-21 W =  [[2.]] , b =  [3.]\n",
      "step = 7200 error value =  3.0157862799983758e-22 W =  [[2.]] , b =  [3.]\n",
      "step = 7600 error value =  1.924871411381565e-23 W =  [[2.]] , b =  [3.]\n",
      "step = 8000 error value =  1.231503538687186e-24 W =  [[2.]] , b =  [3.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([89.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numerical_derivative(f,x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x,flags=['multi_index'],op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    return grad\n",
    "x_data = np.array([1,2,3,4,5]).reshape(5,1)\n",
    "t_data = np.array([5,7,9,11,13]).reshape(5,1)\n",
    "\n",
    "W = np.random.rand(1,1)\n",
    "b = np.random.rand(1)\n",
    "print(\"W =\", W,\", W.shape =\", W.shape, \",b= \", b,\",b.shape =\", b.shape)\n",
    "\n",
    "def loss_func(x,t):\n",
    "    y = np.dot(x,W) + b\n",
    "    return(np.sum((t-y)**2)) / (len(x)) #오차를 양수로 만들기 위해,오차의 가중치를 주기 위해 제곱을 한다.\n",
    "def error_val(x,t):\n",
    "    y = np.dot(x,W) + b\n",
    "    return(np.sum((t-y)**2)) / (len(x)) #np.sum 은 시그마 함수이다.\n",
    "def predict(x):\n",
    "    y = np.dot(x,W) + b\n",
    "    return y\n",
    "\n",
    "#hyper parameter 이 값을 크게 한 경우 목표값을 지나칠수가 있고 너무 작게하면 목표값을 찾는데 오래 걸린다.\n",
    "learning_rate = 1e-2   \n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "print(\"initial error value =\", error_val(x_data,t_data),\"Initial W = \", W, \"\\n\",\", b = \", b)\n",
    "for step in range(8001): #이 값 또한 hyper parameter로 적정값을 대입해주어야 한다.\n",
    "    #미분한 값을 빼는 이유는 미분된 값이 양의 값을 갖는다면, W는 왼쪽으로 이동(감소), 손실함수E(W)는 최소값을 찾는다.\n",
    "    #미분된 값이 음의 값을 갖는다면, W는 오른쪽으로 이동(증가), 손실함수 E(W) 최소값을 찾는다.\n",
    "    W -= learning_rate * numerical_derivative(f,W) \n",
    "    b -= learning_rate * numerical_derivative(f,b)\n",
    "    \n",
    "    if(step % 400 == 0):\n",
    "        print(\"step =\", step, \"error value = \", error_val(x_data,t_data), \"W = \", W,\", b = \",b)\n",
    "test_score = np.array([43])\n",
    "predict(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
