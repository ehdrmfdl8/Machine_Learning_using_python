{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-37edfc5623ff>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "\n",
      " 55000 10000 5000\n",
      "\n",
      "train image shape =  (55000, 784)\n",
      "train label shape =  (55000, 10)\n",
      "test image shape =  (10000, 784)\n",
      "test label shape =  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime      # datetime.now() 를 이용하여 학습 경과 시간 측정\n",
    "\n",
    "# read_data_sets() 를 통해 데이터를 객체형태로 받아오고\n",
    "# one_hot 옵션을 통해 정답(label) 을 one-hot 인코딩된 형태로 받아옴\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# mnist 데이터 셋은 train, test, validation 3개의 데이터 셋으로 구성되어 있으며.\n",
    "# num_examples 값을 통해 데이터의 갯수 확인 가능함\n",
    "\n",
    "print(\"\\n\", mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
    "\n",
    "# 데이터는 784(28x28)개의 픽셀을 가지는 이미지와\n",
    "# 10(0~9)개 클래스를 가지는 one-hot 인코딩된 레이블(정답)을 가지고 있음\n",
    "\n",
    "print(\"\\ntrain image shape = \", np.shape(mnist.train.images))\n",
    "print(\"train label shape = \", np.shape(mnist.train.labels))\n",
    "print(\"test image shape = \", np.shape(mnist.test.images))\n",
    "print(\"test label shape = \", np.shape(mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 # 학습율\n",
    "epochs = 30 # 반복횟수\n",
    "batch_size = 100 # 한번에 입력으로 주어지는 MNIST 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 정답을 위한 플레이스홀더 정의\n",
    "X = tf.placeholder(tf.float32, [None, 784])  \n",
    "\n",
    "A1 = X_img = tf.reshape(X, [-1, 28, 28, 1])   # image 28X28X1 (black/white)\n",
    "\n",
    "\n",
    "T = tf.placeholder(tf.float32, [None, 10])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# 1번째 컨볼루션 층, 5X5X32 필터\n",
    "W2 = tf.Variable(tf.random_normal([5, 5, 1, 32], stddev=0.01))  \n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[32]))   \n",
    "\n",
    "# 1번째 컨볼루션 연산을 통해 28 X 28 X1  => 28 X 28 X 32 \n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# relu\n",
    "Z2 = tf.nn.relu(C2+b2)\n",
    "\n",
    "# 1번째 max pooling을 통해 28 X 28 X 32  => 14 X 14 X 32 \n",
    "A2 = P2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완전연결층, 14X14X32 개 입력 출력은 256개 의 은닉층 개념\n",
    "A2_flat = P2_flat = tf.reshape(A2, [-1, 14*14*32])\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([14*14*32, 256], stddev=0.01))\n",
    "b3 = tf.Variable(tf.random_normal([256]))\n",
    "\n",
    "Z3 = tf.matmul(A2_flat, W3) + b3\n",
    "\n",
    "A3 = tf.nn.relu(Z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.Variable(tf.random_normal([256, 10], stddev = 0.01))\n",
    "\n",
    "b4 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "Z4 = logits = tf.matmul(A3, W4) + b4\n",
    "\n",
    "y = A4 = tf.nn.softmax(Z4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = Z4, labels = T))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size X 10 데이터에 대해 argmax를 통해 행단위로 비교함\n",
    "predicted_val = tf.equal( tf.argmax(A4, 1), tf.argmax(T, 1) )\n",
    "\n",
    "# batch_size X 10 의 True, False 를 1 또는 0 으로 변환\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype=tf.float32))\n",
    "\n",
    "# index list 출력\n",
    "accuracy_index = tf.cast(predicted_val, dtype=tf.float32)\n",
    "\n",
    "# 예측값 처리\n",
    "predicted_list = tf.argmax(A4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.9489434\n",
      "epochs =  0 , step =  100 , loss_val =  0.47301677\n",
      "epochs =  0 , step =  200 , loss_val =  0.24492297\n",
      "epochs =  0 , step =  300 , loss_val =  0.14454538\n",
      "epochs =  0 , step =  400 , loss_val =  0.14683235\n",
      "epochs =  0 , step =  500 , loss_val =  0.0894254\n",
      "epochs =  1 , step =  0 , loss_val =  0.056717668\n",
      "epochs =  1 , step =  100 , loss_val =  0.12429039\n",
      "epochs =  1 , step =  200 , loss_val =  0.15607744\n",
      "epochs =  1 , step =  300 , loss_val =  0.059757862\n",
      "epochs =  1 , step =  400 , loss_val =  0.11255017\n",
      "epochs =  1 , step =  500 , loss_val =  0.030963188\n",
      "epochs =  2 , step =  0 , loss_val =  0.04122034\n",
      "epochs =  2 , step =  100 , loss_val =  0.065564916\n",
      "epochs =  2 , step =  200 , loss_val =  0.029123891\n",
      "epochs =  2 , step =  300 , loss_val =  0.048601698\n",
      "epochs =  2 , step =  400 , loss_val =  0.1617583\n",
      "epochs =  2 , step =  500 , loss_val =  0.084568255\n",
      "epochs =  3 , step =  0 , loss_val =  0.041919574\n",
      "epochs =  3 , step =  100 , loss_val =  0.04380922\n",
      "epochs =  3 , step =  200 , loss_val =  0.03240925\n",
      "epochs =  3 , step =  300 , loss_val =  0.099588156\n",
      "epochs =  3 , step =  400 , loss_val =  0.052531246\n",
      "epochs =  3 , step =  500 , loss_val =  0.09171505\n",
      "epochs =  4 , step =  0 , loss_val =  0.049065493\n",
      "epochs =  4 , step =  100 , loss_val =  0.09775833\n",
      "epochs =  4 , step =  200 , loss_val =  0.02806718\n",
      "epochs =  4 , step =  300 , loss_val =  0.07317171\n",
      "epochs =  4 , step =  400 , loss_val =  0.11143942\n",
      "epochs =  4 , step =  500 , loss_val =  0.010393577\n",
      "epochs =  5 , step =  0 , loss_val =  0.0076989676\n",
      "epochs =  5 , step =  100 , loss_val =  0.05992954\n",
      "epochs =  5 , step =  200 , loss_val =  0.008220893\n",
      "epochs =  5 , step =  300 , loss_val =  0.024356153\n",
      "epochs =  5 , step =  400 , loss_val =  0.016701918\n",
      "epochs =  5 , step =  500 , loss_val =  0.04437919\n",
      "epochs =  6 , step =  0 , loss_val =  0.016478136\n",
      "epochs =  6 , step =  100 , loss_val =  0.00826922\n",
      "epochs =  6 , step =  200 , loss_val =  0.01493747\n",
      "epochs =  6 , step =  300 , loss_val =  0.006769636\n",
      "epochs =  6 , step =  400 , loss_val =  0.013880703\n",
      "epochs =  6 , step =  500 , loss_val =  0.0045116805\n",
      "epochs =  7 , step =  0 , loss_val =  0.0072240066\n",
      "epochs =  7 , step =  100 , loss_val =  0.014236928\n",
      "epochs =  7 , step =  200 , loss_val =  0.008312661\n",
      "epochs =  7 , step =  300 , loss_val =  0.011785873\n",
      "epochs =  7 , step =  400 , loss_val =  0.016358348\n",
      "epochs =  7 , step =  500 , loss_val =  0.009286258\n",
      "epochs =  8 , step =  0 , loss_val =  0.0032743493\n",
      "epochs =  8 , step =  100 , loss_val =  0.03552135\n",
      "epochs =  8 , step =  200 , loss_val =  0.004097854\n",
      "epochs =  8 , step =  300 , loss_val =  0.01638631\n",
      "epochs =  8 , step =  400 , loss_val =  0.01309541\n",
      "epochs =  8 , step =  500 , loss_val =  0.0017716672\n",
      "epochs =  9 , step =  0 , loss_val =  0.010925504\n",
      "epochs =  9 , step =  100 , loss_val =  0.004158508\n",
      "epochs =  9 , step =  200 , loss_val =  0.010041494\n",
      "epochs =  9 , step =  300 , loss_val =  0.014705556\n",
      "epochs =  9 , step =  400 , loss_val =  0.0015292435\n",
      "epochs =  9 , step =  500 , loss_val =  0.0032834602\n",
      "epochs =  10 , step =  0 , loss_val =  0.015910445\n",
      "epochs =  10 , step =  100 , loss_val =  0.0028316153\n",
      "epochs =  10 , step =  200 , loss_val =  0.013591656\n",
      "epochs =  10 , step =  300 , loss_val =  0.0039390237\n",
      "epochs =  10 , step =  400 , loss_val =  0.003448579\n",
      "epochs =  10 , step =  500 , loss_val =  0.00047387485\n",
      "epochs =  11 , step =  0 , loss_val =  0.00075495837\n",
      "epochs =  11 , step =  100 , loss_val =  0.00055206346\n",
      "epochs =  11 , step =  200 , loss_val =  0.0026017171\n",
      "epochs =  11 , step =  300 , loss_val =  0.0020869146\n",
      "epochs =  11 , step =  400 , loss_val =  0.004998663\n",
      "epochs =  11 , step =  500 , loss_val =  0.0017155159\n",
      "epochs =  12 , step =  0 , loss_val =  0.0007796457\n",
      "epochs =  12 , step =  100 , loss_val =  0.007674052\n",
      "epochs =  12 , step =  200 , loss_val =  0.023350526\n",
      "epochs =  12 , step =  300 , loss_val =  0.0045681107\n",
      "epochs =  12 , step =  400 , loss_val =  0.012193629\n",
      "epochs =  12 , step =  500 , loss_val =  0.0043477034\n",
      "epochs =  13 , step =  0 , loss_val =  0.007874723\n",
      "epochs =  13 , step =  100 , loss_val =  0.0003419648\n",
      "epochs =  13 , step =  200 , loss_val =  0.0060381754\n",
      "epochs =  13 , step =  300 , loss_val =  0.0014850491\n",
      "epochs =  13 , step =  400 , loss_val =  0.0006103201\n",
      "epochs =  13 , step =  500 , loss_val =  0.0013075183\n",
      "epochs =  14 , step =  0 , loss_val =  0.0051536537\n",
      "epochs =  14 , step =  100 , loss_val =  0.00026991282\n",
      "epochs =  14 , step =  200 , loss_val =  0.0024974786\n",
      "epochs =  14 , step =  300 , loss_val =  0.005887605\n",
      "epochs =  14 , step =  400 , loss_val =  0.0015808636\n",
      "epochs =  14 , step =  500 , loss_val =  0.0016052744\n",
      "epochs =  15 , step =  0 , loss_val =  0.002974593\n",
      "epochs =  15 , step =  100 , loss_val =  0.028785836\n",
      "epochs =  15 , step =  200 , loss_val =  0.021717003\n",
      "epochs =  15 , step =  300 , loss_val =  0.00024032172\n",
      "epochs =  15 , step =  400 , loss_val =  0.00011866407\n",
      "epochs =  15 , step =  500 , loss_val =  0.01874457\n",
      "epochs =  16 , step =  0 , loss_val =  0.002793951\n",
      "epochs =  16 , step =  100 , loss_val =  0.016654825\n",
      "epochs =  16 , step =  200 , loss_val =  0.00021182564\n",
      "epochs =  16 , step =  300 , loss_val =  0.0013976092\n",
      "epochs =  16 , step =  400 , loss_val =  0.007852144\n",
      "epochs =  16 , step =  500 , loss_val =  0.0009037571\n",
      "epochs =  17 , step =  0 , loss_val =  0.0018557106\n",
      "epochs =  17 , step =  100 , loss_val =  0.0001864805\n",
      "epochs =  17 , step =  200 , loss_val =  0.0011466105\n",
      "epochs =  17 , step =  300 , loss_val =  0.0025096438\n",
      "epochs =  17 , step =  400 , loss_val =  0.0009164632\n",
      "epochs =  17 , step =  500 , loss_val =  0.0063694105\n",
      "epochs =  18 , step =  0 , loss_val =  0.001163696\n",
      "epochs =  18 , step =  100 , loss_val =  2.0018117e-05\n",
      "epochs =  18 , step =  200 , loss_val =  0.014084939\n",
      "epochs =  18 , step =  300 , loss_val =  0.00033214674\n",
      "epochs =  18 , step =  400 , loss_val =  0.022646999\n",
      "epochs =  18 , step =  500 , loss_val =  0.0055179815\n",
      "epochs =  19 , step =  0 , loss_val =  0.0021604728\n",
      "epochs =  19 , step =  100 , loss_val =  0.0026691917\n",
      "epochs =  19 , step =  200 , loss_val =  0.00011006406\n",
      "epochs =  19 , step =  300 , loss_val =  0.0148863625\n",
      "epochs =  19 , step =  400 , loss_val =  6.5583146e-05\n",
      "epochs =  19 , step =  500 , loss_val =  4.5749337e-05\n",
      "epochs =  20 , step =  0 , loss_val =  0.00080582075\n",
      "epochs =  20 , step =  100 , loss_val =  0.0014909962\n",
      "epochs =  20 , step =  200 , loss_val =  0.00026693483\n",
      "epochs =  20 , step =  300 , loss_val =  0.00034729004\n",
      "epochs =  20 , step =  400 , loss_val =  8.461108e-05\n",
      "epochs =  20 , step =  500 , loss_val =  0.00095437246\n",
      "epochs =  21 , step =  0 , loss_val =  9.831022e-05\n",
      "epochs =  21 , step =  100 , loss_val =  0.0043835477\n",
      "epochs =  21 , step =  200 , loss_val =  1.1716787e-05\n",
      "epochs =  21 , step =  300 , loss_val =  0.00019476382\n",
      "epochs =  21 , step =  400 , loss_val =  0.0011938321\n",
      "epochs =  21 , step =  500 , loss_val =  0.00055166334\n",
      "epochs =  22 , step =  0 , loss_val =  0.0008154075\n",
      "epochs =  22 , step =  100 , loss_val =  0.023676138\n",
      "epochs =  22 , step =  200 , loss_val =  0.000994369\n",
      "epochs =  22 , step =  300 , loss_val =  7.362443e-05\n",
      "epochs =  22 , step =  400 , loss_val =  0.051297065\n",
      "epochs =  22 , step =  500 , loss_val =  0.00012490181\n",
      "epochs =  23 , step =  0 , loss_val =  0.0070581585\n",
      "epochs =  23 , step =  100 , loss_val =  0.013251736\n",
      "epochs =  23 , step =  200 , loss_val =  0.0001455663\n",
      "epochs =  23 , step =  300 , loss_val =  0.0001622117\n",
      "epochs =  23 , step =  400 , loss_val =  0.0008838603\n",
      "epochs =  23 , step =  500 , loss_val =  0.0003766155\n",
      "epochs =  24 , step =  0 , loss_val =  0.0042398577\n",
      "epochs =  24 , step =  100 , loss_val =  0.00021034705\n",
      "epochs =  24 , step =  200 , loss_val =  0.00519605\n",
      "epochs =  24 , step =  300 , loss_val =  0.00011260146\n",
      "epochs =  24 , step =  400 , loss_val =  0.00015490422\n",
      "epochs =  24 , step =  500 , loss_val =  3.575981e-05\n",
      "epochs =  25 , step =  0 , loss_val =  0.00034142868\n",
      "epochs =  25 , step =  100 , loss_val =  0.00032374472\n",
      "epochs =  25 , step =  200 , loss_val =  3.9088627e-05\n",
      "epochs =  25 , step =  300 , loss_val =  0.00877944\n",
      "epochs =  25 , step =  400 , loss_val =  0.00583557\n",
      "epochs =  25 , step =  500 , loss_val =  0.00027746306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  26 , step =  0 , loss_val =  0.0001900597\n",
      "epochs =  26 , step =  100 , loss_val =  2.3359682e-05\n",
      "epochs =  26 , step =  200 , loss_val =  4.5823017e-05\n",
      "epochs =  26 , step =  300 , loss_val =  7.364824e-05\n",
      "epochs =  26 , step =  400 , loss_val =  2.751083e-05\n",
      "epochs =  26 , step =  500 , loss_val =  0.00012844981\n",
      "epochs =  27 , step =  0 , loss_val =  3.1106243e-05\n",
      "epochs =  27 , step =  100 , loss_val =  2.8278822e-05\n",
      "epochs =  27 , step =  200 , loss_val =  0.0060794177\n",
      "epochs =  27 , step =  300 , loss_val =  1.1408678e-05\n",
      "epochs =  27 , step =  400 , loss_val =  9.3934956e-05\n",
      "epochs =  27 , step =  500 , loss_val =  0.00042885766\n",
      "epochs =  28 , step =  0 , loss_val =  0.00040789216\n",
      "epochs =  28 , step =  100 , loss_val =  0.0009904021\n",
      "epochs =  28 , step =  200 , loss_val =  0.002331118\n",
      "epochs =  28 , step =  300 , loss_val =  0.00041075464\n",
      "epochs =  28 , step =  400 , loss_val =  0.0015571845\n",
      "epochs =  28 , step =  500 , loss_val =  0.0056060315\n",
      "epochs =  29 , step =  0 , loss_val =  2.7303982e-05\n",
      "epochs =  29 , step =  100 , loss_val =  0.0014080253\n",
      "epochs =  29 , step =  200 , loss_val =  0.023116\n",
      "epochs =  29 , step =  300 , loss_val =  0.00017201666\n",
      "epochs =  29 , step =  400 , loss_val =  1.2099617e-06\n",
      "epochs =  29 , step =  500 , loss_val =  1.959355e-05\n",
      "\n",
      "elapsed time =  0:18:35.046751\n"
     ]
    }
   ],
   "source": [
    "save_file = './train_model.ckpt'\n",
    "saver = tf.train.Saver()\n",
    "index_label_prediction_list = []\n",
    "\n",
    "with  tf.Session()  as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):    # 50 번 반복수행\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size)  # 55,000 / 100\n",
    "\n",
    "        for step in range(total_batch):\n",
    "            \n",
    "            batch_x_data, batch_t_data = mnist.train.next_batch(batch_size)\n",
    "      \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict={X: batch_x_data, T: batch_t_data})    \n",
    "        \n",
    "            if step % 100 == 0:\n",
    "                print(\"epochs = \", i, \", step = \", step, \", loss_val = \", loss_val)             \n",
    "    \n",
    "    end_time = datetime.now() \n",
    "    \n",
    "    print(\"\\nelapsed time = \", end_time - start_time) \n",
    "    saver.save(sess, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./train_model.ckpt\n",
      "\n",
      "Accuracy =  0.9884\n",
      "type(accuracy_val) =  <class 'numpy.float32'> , type(predicted_list_val) =  <class 'numpy.ndarray'> , type(index_label) =  <class 'numpy.ndarray'>\n",
      "index_label.shape =  (10000,)\n",
      "length of index_label_list =  10000\n",
      "false label count =  116\n",
      "\n",
      "length of index_label_false_list 116\n"
     ]
    }
   ],
   "source": [
    "with  tf.Session()  as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "    # Accuracy 확인\n",
    "    test_x_data = mnist.test.images    # 10000 X 784\n",
    "    test_t_data = mnist.test.labels    # 10000 X 10\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict={X: test_x_data, T: test_t_data})\n",
    "    \n",
    "    print(\"\\nAccuracy = \", accuracy_val)\n",
    "    print(\"type(accuracy_val) = \", type(accuracy_val), ', type(predicted_list_val) = ', type(predicted_list_val), ', type(index_label) = ', type(index_label))\n",
    "    print(\"index_label.shape = \", index_label.shape)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "        \n",
    "    # numpy type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label)):\n",
    "        \n",
    "        if index_label[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_prediction_list.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list\", len(index_label_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18, 3, 8], [247, 4, 2], [259, 6, 0], [321, 2, 7], [445, 6, 0], [582, 8, 2], [646, 2, 4], [740, 4, 9], [939, 2, 0], [947, 8, 9], [965, 6, 0], [1014, 6, 5], [1033, 8, 1], [1039, 7, 1], [1128, 3, 7], [1156, 7, 8], [1226, 7, 2], [1232, 9, 4], [1242, 4, 9], [1260, 7, 1], [1319, 8, 0], [1393, 5, 3], [1414, 9, 4], [1425, 8, 4], [1522, 7, 9], [1530, 8, 7], [1678, 2, 0], [1717, 8, 0], [1790, 2, 7], [1901, 9, 4], [2035, 5, 3], [2070, 7, 9], [2098, 2, 0], [2118, 6, 0], [2129, 9, 8], [2130, 4, 9], [2135, 6, 1], [2182, 1, 2], [2280, 3, 9], [2293, 9, 4], [2387, 9, 1], [2462, 2, 0], [2560, 3, 2], [2597, 5, 3], [2607, 7, 8], [2648, 9, 5], [2654, 6, 1], [2720, 9, 4], [2743, 5, 8], [2770, 3, 7], [2896, 8, 0], [2921, 3, 2], [2945, 3, 9], [2995, 6, 8], [3030, 6, 0], [3073, 1, 2], [3225, 7, 9], [3330, 2, 8], [3422, 6, 0], [3451, 7, 9], [3503, 9, 1], [3520, 6, 4], [3534, 4, 8], [3558, 5, 0], [3559, 8, 5], [3727, 8, 9], [3751, 7, 2], [3808, 7, 8], [3853, 6, 0], [3951, 8, 0], [4163, 9, 0], [4176, 2, 7], [4199, 7, 9], [4201, 1, 7], [4248, 2, 8], [4256, 3, 0], [4399, 8, 0], [4443, 3, 2], [4497, 8, 7], [4571, 6, 8], [4699, 6, 1], [4761, 9, 4], [4807, 8, 0], [4823, 9, 4], [5199, 6, 4], [5246, 7, 2], [5634, 2, 8], [5877, 6, 0], [5887, 7, 0], [5937, 5, 3], [5955, 3, 8], [5973, 3, 8], [6011, 3, 9], [6023, 3, 9], [6173, 9, 8], [6560, 9, 5], [6597, 0, 9], [6625, 8, 1], [6631, 8, 0], [6740, 9, 0], [7849, 3, 2], [8094, 2, 8], [8246, 3, 9], [8277, 3, 8], [8508, 3, 2], [8527, 4, 9], [9009, 7, 2], [9015, 7, 2], [9540, 1, 8], [9634, 0, 1], [9664, 2, 7], [9679, 6, 4], [9729, 5, 6], [9768, 2, 0], [9770, 5, 0], [9888, 6, 0]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "70 image is saved now\n",
      "80 image is saved now\n",
      "90 image is saved now\n",
      "100 image is saved now\n",
      "110 image is saved now\n",
      "Elapsed Time =  0:00:32.500308\n",
      "Total  116  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check false data\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "# 현재 디렉토리 저장\n",
    "curr_dir = os.getcwd()\n",
    "\n",
    "#image 저장할 디렉토리 생성, 현재 시간으로 생성\n",
    "now = datetime.now()\n",
    "algorithm_name = 'CNN_1Conv_Adam_'\n",
    "dir_name = algorithm_name + str(now.year) + '-' + str(now.month) + '-' +str(now.day) + '-' + str(now.hour) + str(now.minute) + str(now.second)\n",
    "\n",
    "os.mkdir(dir_name)\n",
    "\n",
    "# change dir\n",
    "os.chdir(dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_prediction_list:\n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "    \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)\n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + ', prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "        \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed Time = ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
