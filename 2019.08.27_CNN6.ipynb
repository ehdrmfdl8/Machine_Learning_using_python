{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-55cac02281db>:6: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "55000 10000 5000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "print(mnist.train.num_examples, mnist.test.num_examples, mnist.validation.num_examples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 28*28])\n",
    "\n",
    "T = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "A1 = tf.reshape(X, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "W2 = tf.Variable(tf.random_normal([5, 5, 1, 32], stddev = 0.01))\n",
    "\n",
    "b2 = tf.Variable(tf.constant(0.1, shape = [32]))\n",
    "\n",
    "C2 = tf.nn.conv2d(A1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "Z2 = tf.nn.relu(C2 + b2)\n",
    "\n",
    "A2 = tf.nn.max_pool(Z2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = tf.Variable(tf.random_normal([4, 4, 32, 64], stddev = 0.01))\n",
    "\n",
    "b3 = tf.Variable(tf.constant(0.1, shape = [64]))\n",
    "\n",
    "C3 = tf.nn.conv2d(A2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "Z3 = tf.nn.relu(C3 + b3)\n",
    "\n",
    "A3 = tf.nn.max_pool(Z3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W4 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev = 0.01))\n",
    "\n",
    "b4 = tf.Variable(tf.constant(0.1, shape = [128]))\n",
    "\n",
    "C4 = tf.nn.conv2d(A3, W4, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "A4 = tf.nn.relu(C4 + b4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "A4_flat = tf.reshape(A4, [-1,7*7*128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W5 = tf.Variable(tf.random_normal([7*7*128, 10], stddev = 0.01))\n",
    "\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "\n",
    "Z5 = tf.matmul(A4_flat, W5) + b5\n",
    "\n",
    "y = A5 = tf.nn.softmax(Z5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = y, labels = T))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_val = tf.equal(tf.argmax(y, 1), tf.argmax(T, 1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(predicted_val, dtype = tf.float32))\n",
    "\n",
    "accuracy_index = tf.cast(predicted_val, dtype = tf.float32)\n",
    "\n",
    "predicted_list = tf.argmax(y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  0 , step =  0 , loss_val =  2.3061237\n",
      "epochs =  0 , step =  100 , loss_val =  1.6516583\n",
      "epochs =  0 , step =  200 , loss_val =  1.6317537\n",
      "epochs =  0 , step =  300 , loss_val =  1.6041816\n",
      "epochs =  0 , step =  400 , loss_val =  1.6008117\n",
      "epochs =  0 , step =  500 , loss_val =  1.6425458\n",
      "epochs =  1 , step =  0 , loss_val =  1.6012282\n",
      "epochs =  1 , step =  100 , loss_val =  1.6052368\n",
      "epochs =  1 , step =  200 , loss_val =  1.600975\n",
      "epochs =  1 , step =  300 , loss_val =  1.6072191\n",
      "epochs =  1 , step =  400 , loss_val =  1.5954813\n",
      "epochs =  1 , step =  500 , loss_val =  1.502746\n",
      "epochs =  2 , step =  0 , loss_val =  1.5717179\n",
      "epochs =  2 , step =  100 , loss_val =  1.4839779\n",
      "epochs =  2 , step =  200 , loss_val =  1.4994644\n",
      "epochs =  2 , step =  300 , loss_val =  1.4738759\n",
      "epochs =  2 , step =  400 , loss_val =  1.472788\n",
      "epochs =  2 , step =  500 , loss_val =  1.477113\n",
      "epochs =  3 , step =  0 , loss_val =  1.4715064\n",
      "epochs =  3 , step =  100 , loss_val =  1.4792022\n",
      "epochs =  3 , step =  200 , loss_val =  1.497868\n",
      "epochs =  3 , step =  300 , loss_val =  1.4927163\n",
      "epochs =  3 , step =  400 , loss_val =  1.461225\n",
      "epochs =  3 , step =  500 , loss_val =  1.465706\n",
      "epochs =  4 , step =  0 , loss_val =  1.5059471\n",
      "epochs =  4 , step =  100 , loss_val =  1.4689728\n",
      "epochs =  4 , step =  200 , loss_val =  1.4799614\n",
      "epochs =  4 , step =  300 , loss_val =  1.4770714\n",
      "epochs =  4 , step =  400 , loss_val =  1.4707919\n",
      "epochs =  4 , step =  500 , loss_val =  1.4715091\n",
      "epochs =  5 , step =  0 , loss_val =  1.4737961\n",
      "epochs =  5 , step =  100 , loss_val =  1.4851664\n",
      "epochs =  5 , step =  200 , loss_val =  1.4712673\n",
      "epochs =  5 , step =  300 , loss_val =  1.5143504\n",
      "epochs =  5 , step =  400 , loss_val =  1.4847283\n",
      "epochs =  5 , step =  500 , loss_val =  1.4822983\n",
      "epochs =  6 , step =  0 , loss_val =  1.4707929\n",
      "epochs =  6 , step =  100 , loss_val =  1.4612094\n",
      "epochs =  6 , step =  200 , loss_val =  1.4707242\n",
      "epochs =  6 , step =  300 , loss_val =  1.4612607\n",
      "epochs =  6 , step =  400 , loss_val =  1.4799134\n",
      "epochs =  6 , step =  500 , loss_val =  1.499543\n",
      "epochs =  7 , step =  0 , loss_val =  1.461163\n",
      "epochs =  7 , step =  100 , loss_val =  1.4822242\n",
      "epochs =  7 , step =  200 , loss_val =  1.4888607\n",
      "epochs =  7 , step =  300 , loss_val =  1.4711505\n",
      "epochs =  7 , step =  400 , loss_val =  1.477921\n",
      "epochs =  7 , step =  500 , loss_val =  1.4617093\n",
      "epochs =  8 , step =  0 , loss_val =  1.4653751\n",
      "epochs =  8 , step =  100 , loss_val =  1.4711245\n",
      "epochs =  8 , step =  200 , loss_val =  1.4732519\n",
      "epochs =  8 , step =  300 , loss_val =  1.5219622\n",
      "epochs =  8 , step =  400 , loss_val =  1.4718155\n",
      "epochs =  8 , step =  500 , loss_val =  1.4611619\n",
      "epochs =  9 , step =  0 , loss_val =  1.4719009\n",
      "epochs =  9 , step =  100 , loss_val =  1.4715946\n",
      "epochs =  9 , step =  200 , loss_val =  1.4850991\n",
      "epochs =  9 , step =  300 , loss_val =  1.4712378\n",
      "epochs =  9 , step =  400 , loss_val =  1.471146\n",
      "epochs =  9 , step =  500 , loss_val =  1.4614393\n",
      "epochs =  10 , step =  0 , loss_val =  1.4702499\n",
      "epochs =  10 , step =  100 , loss_val =  1.4710605\n",
      "epochs =  10 , step =  200 , loss_val =  1.4711505\n",
      "epochs =  10 , step =  300 , loss_val =  1.470824\n",
      "epochs =  10 , step =  400 , loss_val =  1.4710993\n",
      "epochs =  10 , step =  500 , loss_val =  1.4714158\n",
      "epochs =  11 , step =  0 , loss_val =  1.4711504\n",
      "epochs =  11 , step =  100 , loss_val =  1.4699543\n",
      "epochs =  11 , step =  200 , loss_val =  1.4909917\n",
      "epochs =  11 , step =  300 , loss_val =  1.4811511\n",
      "epochs =  11 , step =  400 , loss_val =  1.4911392\n",
      "epochs =  11 , step =  500 , loss_val =  1.4807103\n",
      "epochs =  12 , step =  0 , loss_val =  1.4719411\n",
      "epochs =  12 , step =  100 , loss_val =  1.4611508\n",
      "epochs =  12 , step =  200 , loss_val =  1.4611559\n",
      "epochs =  12 , step =  300 , loss_val =  1.4704938\n",
      "epochs =  12 , step =  400 , loss_val =  1.4620553\n",
      "epochs =  12 , step =  500 , loss_val =  1.4810024\n",
      "epochs =  13 , step =  0 , loss_val =  1.4611832\n",
      "epochs =  13 , step =  100 , loss_val =  1.4612029\n",
      "epochs =  13 , step =  200 , loss_val =  1.499416\n",
      "epochs =  13 , step =  300 , loss_val =  1.471151\n",
      "epochs =  13 , step =  400 , loss_val =  1.4710727\n",
      "epochs =  13 , step =  500 , loss_val =  1.471206\n",
      "epochs =  14 , step =  0 , loss_val =  1.4611505\n",
      "epochs =  14 , step =  100 , loss_val =  1.4711924\n",
      "epochs =  14 , step =  200 , loss_val =  1.4618409\n",
      "epochs =  14 , step =  300 , loss_val =  1.4613485\n",
      "epochs =  14 , step =  400 , loss_val =  1.4667248\n",
      "epochs =  14 , step =  500 , loss_val =  1.4654758\n",
      "epochs =  15 , step =  0 , loss_val =  1.473927\n",
      "epochs =  15 , step =  100 , loss_val =  1.5009677\n",
      "epochs =  15 , step =  200 , loss_val =  1.4611505\n",
      "epochs =  15 , step =  300 , loss_val =  1.4611504\n",
      "epochs =  15 , step =  400 , loss_val =  1.4723636\n",
      "epochs =  15 , step =  500 , loss_val =  1.4736503\n",
      "epochs =  16 , step =  0 , loss_val =  1.4611502\n",
      "epochs =  16 , step =  100 , loss_val =  1.4611505\n",
      "epochs =  16 , step =  200 , loss_val =  1.4714314\n",
      "epochs =  16 , step =  300 , loss_val =  1.4611557\n",
      "epochs =  16 , step =  400 , loss_val =  1.4779916\n",
      "epochs =  16 , step =  500 , loss_val =  1.4681218\n",
      "epochs =  17 , step =  0 , loss_val =  1.4713745\n",
      "epochs =  17 , step =  100 , loss_val =  1.4711255\n",
      "epochs =  17 , step =  200 , loss_val =  1.4653027\n",
      "epochs =  17 , step =  300 , loss_val =  1.4711502\n",
      "epochs =  17 , step =  400 , loss_val =  1.4896982\n",
      "epochs =  17 , step =  500 , loss_val =  1.471192\n",
      "epochs =  18 , step =  0 , loss_val =  1.4811528\n",
      "epochs =  18 , step =  100 , loss_val =  1.4611504\n",
      "epochs =  18 , step =  200 , loss_val =  1.4711276\n",
      "epochs =  18 , step =  300 , loss_val =  1.4611504\n",
      "epochs =  18 , step =  400 , loss_val =  1.4611502\n",
      "epochs =  18 , step =  500 , loss_val =  1.4711504\n",
      "epochs =  19 , step =  0 , loss_val =  1.4611505\n",
      "epochs =  19 , step =  100 , loss_val =  1.4711504\n",
      "epochs =  19 , step =  200 , loss_val =  1.4611502\n",
      "epochs =  19 , step =  300 , loss_val =  1.4611505\n",
      "epochs =  19 , step =  400 , loss_val =  1.4611505\n",
      "epochs =  19 , step =  500 , loss_val =  1.4711744\n",
      "epochs =  20 , step =  0 , loss_val =  1.4611502\n",
      "epochs =  20 , step =  100 , loss_val =  1.4804877\n",
      "epochs =  20 , step =  200 , loss_val =  1.4611504\n",
      "epochs =  20 , step =  300 , loss_val =  1.4711512\n",
      "epochs =  20 , step =  400 , loss_val =  1.4807892\n",
      "epochs =  20 , step =  500 , loss_val =  1.4613818\n",
      "epochs =  21 , step =  0 , loss_val =  1.4702158\n",
      "epochs =  21 , step =  100 , loss_val =  1.4711505\n",
      "epochs =  21 , step =  200 , loss_val =  1.4611504\n",
      "epochs =  21 , step =  300 , loss_val =  1.4611505\n",
      "epochs =  21 , step =  400 , loss_val =  1.461162\n",
      "epochs =  21 , step =  500 , loss_val =  1.4711504\n",
      "epochs =  22 , step =  0 , loss_val =  1.4709584\n",
      "epochs =  22 , step =  100 , loss_val =  1.4611505\n",
      "epochs =  22 , step =  200 , loss_val =  1.491157\n",
      "epochs =  22 , step =  300 , loss_val =  1.4611578\n",
      "epochs =  22 , step =  400 , loss_val =  1.4611502\n",
      "epochs =  22 , step =  500 , loss_val =  1.4611504\n",
      "epochs =  23 , step =  0 , loss_val =  1.4792356\n",
      "epochs =  23 , step =  100 , loss_val =  1.4786675\n",
      "epochs =  23 , step =  200 , loss_val =  1.4911509\n",
      "epochs =  23 , step =  300 , loss_val =  1.4611505\n",
      "epochs =  23 , step =  400 , loss_val =  1.4611502\n",
      "epochs =  23 , step =  500 , loss_val =  1.4788128\n",
      "epochs =  24 , step =  0 , loss_val =  1.4711504\n",
      "epochs =  24 , step =  100 , loss_val =  1.4611505\n",
      "epochs =  24 , step =  200 , loss_val =  1.4711744\n",
      "epochs =  24 , step =  300 , loss_val =  1.4711494\n",
      "epochs =  24 , step =  400 , loss_val =  1.4614172\n",
      "epochs =  24 , step =  500 , loss_val =  1.4710077\n",
      "epochs =  25 , step =  0 , loss_val =  1.4611505\n",
      "epochs =  25 , step =  100 , loss_val =  1.4611505\n",
      "epochs =  25 , step =  200 , loss_val =  1.4611807\n",
      "epochs =  25 , step =  300 , loss_val =  1.4611505\n",
      "epochs =  25 , step =  400 , loss_val =  1.4773196\n",
      "epochs =  25 , step =  500 , loss_val =  1.4611505\n",
      "epochs =  26 , step =  0 , loss_val =  1.4711528\n",
      "epochs =  26 , step =  100 , loss_val =  1.4611504\n",
      "epochs =  26 , step =  200 , loss_val =  1.472805\n",
      "epochs =  26 , step =  300 , loss_val =  1.4711505\n",
      "epochs =  26 , step =  400 , loss_val =  1.4611505\n",
      "epochs =  26 , step =  500 , loss_val =  1.4611504\n",
      "epochs =  27 , step =  0 , loss_val =  1.4811214\n",
      "epochs =  27 , step =  100 , loss_val =  1.481153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs =  27 , step =  200 , loss_val =  1.4663755\n",
      "epochs =  27 , step =  300 , loss_val =  1.461752\n",
      "epochs =  27 , step =  400 , loss_val =  1.4611504\n",
      "epochs =  27 , step =  500 , loss_val =  1.4621627\n",
      "epochs =  28 , step =  0 , loss_val =  1.4611505\n",
      "epochs =  28 , step =  100 , loss_val =  1.4612842\n",
      "epochs =  28 , step =  200 , loss_val =  1.4611505\n",
      "epochs =  28 , step =  300 , loss_val =  1.4611505\n",
      "epochs =  28 , step =  400 , loss_val =  1.4711505\n",
      "epochs =  28 , step =  500 , loss_val =  1.4711504\n",
      "epochs =  29 , step =  0 , loss_val =  1.4611502\n",
      "epochs =  29 , step =  100 , loss_val =  1.4811434\n",
      "epochs =  29 , step =  200 , loss_val =  1.4611505\n",
      "epochs =  29 , step =  300 , loss_val =  1.4611505\n",
      "epochs =  29 , step =  400 , loss_val =  1.4711175\n",
      "epochs =  29 , step =  500 , loss_val =  1.4611502\n",
      "\n",
      "elapsed time =  0:44:20.826416\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "save_file = './CNN6_model.ckpt'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        \n",
    "        for step in range(total_batch):\n",
    "            \n",
    "            batch_x_data , batch_t_data = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            loss_val, _ = sess.run([loss, train], feed_dict = {X : batch_x_data, T : batch_t_data})\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                \n",
    "                print(\"epochs = \", i, \", step = \", step , \", loss_val = \", loss_val)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    saver.save(sess, save_file)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"elapsed time = \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./CNN6_model.ckpt\n",
      "\n",
      "Accuracy =  0.9901\n",
      "type(accuracy_val) =  <class 'numpy.float32'> , type(predicted_list_val) =  <class 'numpy.ndarray'> , type(index_label) =  <class 'numpy.ndarray'>\n",
      "index_label.shape =  (10000,)\n",
      "length of index_label_list =  10000\n",
      "false label count =  99\n",
      "\n",
      "length of index_label_false_list 99\n"
     ]
    }
   ],
   "source": [
    "index_label_prediction_list = []\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "    \n",
    "    test_x_data = mnist.test.images\n",
    "    test_t_data = mnist.test.labels\n",
    "    \n",
    "    accuracy_val, predicted_list_val, index_label = sess.run([accuracy, predicted_list, accuracy_index], feed_dict = {X:test_x_data, T:test_t_data})\n",
    "    print(\"\\nAccuracy = \", accuracy_val)\n",
    "    print(\"type(accuracy_val) = \", type(accuracy_val), ', type(predicted_list_val) = ', type(predicted_list_val), ', type(index_label) = ', type(index_label))\n",
    "    print(\"index_label.shape = \", index_label.shape)\n",
    "    \n",
    "    index_label_list = list(index_label)\n",
    "    print(\"length of index_label_list = \", len(index_label_list))\n",
    "    print(\"false label count = \", index_label_list.count([0]))\n",
    "        \n",
    "    # numpy type 으로 디버그\n",
    "    temp_list = [] \n",
    "    \n",
    "    for index in range(len(index_label)):\n",
    "        \n",
    "        if index_label[index] == 0:\n",
    "            \n",
    "            temp_list.append(index)\n",
    "            temp_list.append(np.argmax(test_t_data[index]))  # one-hot encoding 이므로 argmax 로 정답 추출\n",
    "            temp_list.append(predicted_list_val[index])\n",
    "            \n",
    "            index_label_prediction_list.append(temp_list)\n",
    "            \n",
    "            temp_list = []\n",
    "            \n",
    "    print(\"\\nlength of index_label_false_list\", len(index_label_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8, 5, 6], [321, 2, 7], [324, 0, 6], [326, 2, 1], [449, 3, 5], [582, 8, 2], [646, 2, 4], [720, 5, 8], [740, 4, 9], [883, 3, 5], [938, 3, 5], [947, 8, 9], [965, 6, 0], [1014, 6, 8], [1039, 7, 1], [1114, 3, 8], [1226, 7, 2], [1232, 9, 4], [1247, 9, 5], [1260, 7, 1], [1527, 1, 5], [1530, 8, 7], [1581, 7, 9], [1621, 0, 6], [1681, 3, 7], [1709, 9, 5], [1878, 8, 3], [1901, 9, 4], [1911, 5, 0], [2018, 1, 2], [2109, 3, 8], [2130, 4, 9], [2135, 6, 1], [2148, 4, 9], [2182, 1, 2], [2293, 9, 4], [2387, 9, 1], [2447, 4, 9], [2582, 9, 7], [2597, 5, 3], [2654, 6, 1], [2836, 4, 2], [2921, 3, 2], [2939, 9, 5], [2953, 3, 5], [2959, 2, 3], [2972, 0, 6], [2995, 6, 8], [3073, 1, 2], [3225, 7, 9], [3288, 4, 9], [3384, 2, 6], [3451, 7, 9], [3503, 9, 1], [3558, 5, 0], [3662, 8, 0], [3727, 8, 9], [3806, 5, 8], [3808, 7, 8], [3818, 0, 6], [3869, 9, 4], [3918, 5, 9], [3976, 7, 1], [4151, 7, 9], [4176, 2, 7], [4224, 9, 7], [4238, 7, 3], [4256, 3, 0], [4284, 9, 5], [4369, 9, 4], [4443, 3, 2], [4500, 9, 1], [4639, 8, 9], [4699, 6, 1], [4740, 3, 5], [4761, 9, 4], [4783, 4, 9], [4807, 8, 0], [4860, 4, 9], [5067, 3, 2], [5261, 7, 9], [5623, 3, 5], [5955, 3, 8], [5997, 5, 9], [6065, 3, 8], [6555, 8, 9], [6571, 9, 7], [6576, 7, 1], [6597, 0, 7], [6651, 0, 8], [8094, 2, 8], [8508, 3, 5], [8527, 4, 9], [9158, 0, 9], [9664, 2, 7], [9692, 9, 7], [9700, 2, 8], [9729, 5, 6], [9828, 3, 5]]\n"
     ]
    }
   ],
   "source": [
    "print(index_label_prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 image is saved now\n",
      "20 image is saved now\n",
      "30 image is saved now\n",
      "40 image is saved now\n",
      "50 image is saved now\n",
      "60 image is saved now\n",
      "70 image is saved now\n",
      "80 image is saved now\n",
      "90 image is saved now\n",
      "Elapsed save time =>  0:00:24.004307\n",
      "Total  99  data is saved\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "save_count = 0\n",
    "\n",
    "curr_dir = os.getcwd()\n",
    "\n",
    "now = datetime.now()\n",
    "algorithm_name = 'CNN_6conv_Adam'\n",
    "dir_name = algorithm_name + str(now.year) + '-' + str(now.month) + '-' + str(now.day) + '-' + str(now.hour) + '-' + str(now.minute) + '-' + str(now.second) \n",
    "\n",
    "os.mkdir(dir_name)\n",
    "\n",
    "os.chdir(dir_name)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for list_data in index_label_prediction_list:\n",
    "    \n",
    "    index_int = list_data[0]\n",
    "    label_int = list_data[1]\n",
    "    prediction_int = list_data[2]\n",
    "        \n",
    "    # 저장할 이미지를 인덱스를 이용하여 가져옴\n",
    "    img = test_x_data[index_int].reshape(28,28)  \n",
    "    plt.imshow(img, cmap='gray')\n",
    "    \n",
    "    # 정답 문자열\n",
    "    label_str = str(label_int)\n",
    "    \n",
    "    # 예측값 문자열\n",
    "    prediction_str = str(prediction_int)\n",
    "    \n",
    "    # 정답과 오답을 나타내는 문자열\n",
    "    label_prediction_str = 'label = ' + label_str + '  ,  prediction = ' + prediction_str\n",
    "    \n",
    "    # 저장 파일 이름 생성, str(index_int).png\n",
    "    save_image_name = str(index_int) + '.png'\n",
    "    \n",
    "    plt.title(label_prediction_str)\n",
    "    plt.savefig(save_image_name)\n",
    "    \n",
    "    save_count += 1\n",
    "    \n",
    "    if save_count % 10 == 0:\n",
    "        \n",
    "        print(save_count, 'image is saved now')\n",
    "\n",
    "    \n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Elapsed save time => ', end_time - start_time)\n",
    "print('Total ', save_count, \" data is saved\")\n",
    "\n",
    "# 원래의 dir 로 복귀\n",
    "os.chdir(curr_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
