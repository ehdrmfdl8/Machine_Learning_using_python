{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Class 화 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "class numerical_derivative:\n",
    "    import numpy as np\n",
    "    \n",
    "    def __init__(self,f,x):\n",
    "        self.f = f\n",
    "        self.x = x\n",
    "    def getData(self):\n",
    "        delta_x = 1e-4\n",
    "        grad = np.zeros_like(self.x)\n",
    "        it = np.nditer(self.x,flags=['multi_index'],op_flags = ['readwrite'])\n",
    "    \n",
    "        while not it.finished:\n",
    "            idx = it.multi_index\n",
    "        \n",
    "            tmp_val = self.x[idx]\n",
    "            self.x[idx] = float(tmp_val) + delta_x\n",
    "            fx1 = self.f(self.x)\n",
    "\n",
    "            self.x[idx] = tmp_val - delta_x\n",
    "            fx2 = self.f(self.x)\n",
    "            grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "            self.x[idx] = tmp_val\n",
    "            it.iternext()\n",
    "        return grad\n",
    "def func1(input_obj):\n",
    "    x = input_obj[0]\n",
    "    return x**2\n",
    "f = lambda x : func1(x)\n",
    "# x =3.0 에서의 편미분 값\n",
    "numerical_derivative(f,np.array([3.0])).getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class numerical_derivative:\n",
    "    import numpy as np\n",
    "    \n",
    "    def __init__(self,f,x):\n",
    "        self.f = f\n",
    "        self.x = x\n",
    "    def getData(self):\n",
    "        delta_x = 1e-4\n",
    "        grad = np.zeros_like(self.x)\n",
    "        it = np.nditer(self.x,flags=['multi_index'],op_flags = ['readwrite'])\n",
    "    \n",
    "        while not it.finished:\n",
    "            idx = it.multi_index\n",
    "        \n",
    "            tmp_val = self.x[idx]\n",
    "            self.x[idx] = float(tmp_val) + delta_x\n",
    "            fx1 = self.f(self.x)\n",
    "\n",
    "            self.x[idx] = tmp_val - delta_x\n",
    "            fx2 = self.f(self.x)\n",
    "            grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "            self.x[idx] = tmp_val\n",
    "            it.iternext()\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input_data:\n",
    "    import numpy as np\n",
    "    def __init__(self):\n",
    "        load_data = np.loadtxt('./data-01.csv',delimiter=',',dtype = np.float32)\n",
    "        self.x_data = load_data[:,0:-1]\n",
    "        self.t_data = load_data[:,[-1]]\n",
    "    def get_x_data(self):\n",
    "        return self.x_data\n",
    "    def get_t_data(self):\n",
    "        return self.t_data\n",
    "    def get_W(self):\n",
    "        return np.random.rand(self.x_data.shape[1],1)\n",
    "    def get_b(self):\n",
    "        return np.random.rand(1)\n",
    "    def info(self):\n",
    "        print(\"W =\", W,\", W.shape =\", W.shape, \",b= \", b,\",b.shape =\", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class LinearRegressionTest:\n",
    "    \n",
    "    In = Input_data()\n",
    "    \n",
    "    def __init__(self,x_data,t_data,learning_rate,iteration_count):\n",
    "        self.x_data = x_data\n",
    "        self.t_data = t_data\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iteration_count = iteration_count\n",
    "        self.W = In.get_W()\n",
    "        self.b = In.get_b()\n",
    "        \n",
    "    def loss_func(self,x,t):\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        y = np.dot(self.x,self.W) + self.b\n",
    "        return np.sum((self.t - y)**2) / len(self.x)\n",
    "    def error_val(self,x,t):\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        y = np.dot(self.x,self.W) + self.b\n",
    "        return np.sum((self.t - y)**2) / len(self.x)\n",
    "    def predict(self,x):\n",
    "        self.x = x\n",
    "        y = np.dot(self.x,self.W) + self.b\n",
    "        return y\n",
    "    def train(self):\n",
    "        f = lambda x : self.loss_func(self.x_data,self.t_data)\n",
    "        print(\"initial error value =\", self.error_val(x_data,t_data),\"Initial W = \", self.W, \"\\n\",\", b = \", self.b)\n",
    "        for step in range(self.iteration_count):\n",
    "            self.W -= self.learning_rate * numerical_derivative(f,self.W).getData()\n",
    "            self.b -= self.learning_rate * numerical_derivative(f,self.b).getData()\n",
    "            \n",
    "            if(step % 400 == 0):\n",
    "                print(\"step = \", step, \"error value = \",self.error_val(self.x_data,self.t_data), \"W = \", self.W,\", b = \",self.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial error value = 3875.833940381458 Initial W =  [[0.08576918]\n",
      " [0.58941357]\n",
      " [0.56515394]] \n",
      " , b =  [0.87712934]\n",
      "step =  0 error value =  1439.5800158649206 W =  [[0.18511905]\n",
      " [0.68917239]\n",
      " [0.66751304]] , b =  [0.87787667]\n",
      "step =  400 error value =  9.150066399505311 W =  [[0.33962944]\n",
      " [0.79386852]\n",
      " [0.87488235]] , b =  [0.8785459]\n",
      "step =  800 error value =  8.287762794075059 W =  [[0.34017011]\n",
      " [0.75165966]\n",
      " [0.91561028]] , b =  [0.87800182]\n",
      "step =  1200 error value =  7.683119477328021 W =  [[0.34082487]\n",
      " [0.71622109]\n",
      " [0.94961188]] , b =  [0.87741426]\n",
      "step =  1600 error value =  7.259085981232081 W =  [[0.3415559 ]\n",
      " [0.68645992]\n",
      " [0.97799179]] , b =  [0.87679045]\n",
      "step =  2000 error value =  6.961661275904143 W =  [[0.34233336]\n",
      " [0.66146035]\n",
      " [1.00167385]] , b =  [0.87613641]\n",
      "step =  2400 error value =  6.752997080162983 W =  [[0.34313396]\n",
      " [0.64045493]\n",
      " [1.02143063]] , b =  [0.87545718]\n",
      "step =  2800 error value =  6.606565024822012 W =  [[0.34393966]\n",
      " [0.62280044]\n",
      " [1.03790814]] , b =  [0.87475695]\n",
      "step =  3200 error value =  6.50377000557449 W =  [[0.34473675]\n",
      " [0.60795774]\n",
      " [1.05164653]] , b =  [0.87403926]\n",
      "step =  3600 error value =  6.43157692355155 W =  [[0.34551496]\n",
      " [0.5954749 ]\n",
      " [1.06309737]] , b =  [0.87330702]\n",
      "step =  4000 error value =  6.3808475438663255 W =  [[0.34626681]\n",
      " [0.58497303]\n",
      " [1.07263816]] , b =  [0.87256269]\n",
      "step =  4400 error value =  6.3451749659662084 W =  [[0.34698704]\n",
      " [0.57613441]\n",
      " [1.08058444]] , b =  [0.87180832]\n",
      "step =  4800 error value =  6.320066798043981 W =  [[0.34767216]\n",
      " [0.56869265]\n",
      " [1.08719994]] , b =  [0.8710456]\n",
      "step =  5200 error value =  6.302372691674808 W =  [[0.34832006]\n",
      " [0.5624243 ]\n",
      " [1.09270501]] , b =  [0.87027598]\n",
      "step =  5600 error value =  6.2898831193019 W =  [[0.34892974]\n",
      " [0.55714192]\n",
      " [1.09728381]] , b =  [0.86950062]\n",
      "step =  6000 error value =  6.281048158058859 W =  [[0.34950101]\n",
      " [0.55268828]\n",
      " [1.10109014]] , b =  [0.86872052]\n",
      "step =  6400 error value =  6.274780375800544 W =  [[0.35003434]\n",
      " [0.5489314 ]\n",
      " [1.10425251]] , b =  [0.86793651]\n",
      "step =  6800 error value =  6.270316659017217 W =  [[0.35053067]\n",
      " [0.54576056]\n",
      " [1.1068782 ]] , b =  [0.86714928]\n",
      "step =  7200 error value =  6.267121350851327 W =  [[0.35099127]\n",
      " [0.54308278]\n",
      " [1.10905682]] , b =  [0.8663594]\n",
      "step =  7600 error value =  6.264818342997582 W =  [[0.35141768]\n",
      " [0.54082   ]\n",
      " [1.11086315]] , b =  [0.86556733]\n",
      "step =  8000 error value =  6.263143462120635 W =  [[0.35181158]\n",
      " [0.53890667]\n",
      " [1.11235962]] , b =  [0.86477349]\n",
      "step =  8400 error value =  6.261911082034573 W =  [[0.35217475]\n",
      " [0.53728771]\n",
      " [1.1135983 ]] , b =  [0.8639782]\n",
      "step =  8800 error value =  6.260990708324606 W =  [[0.35250902]\n",
      " [0.53591686]\n",
      " [1.11462264]] , b =  [0.86318174]\n",
      "step =  9200 error value =  6.260290554324763 W =  [[0.35281621]\n",
      " [0.5347552 ]\n",
      " [1.11546888]] , b =  [0.86238433]\n",
      "step =  9600 error value =  6.259746018957347 W =  [[0.35309813]\n",
      " [0.53377005]\n",
      " [1.1161672 ]] , b =  [0.86158617]\n",
      "step =  10000 error value =  6.259311601789717 W =  [[0.35335655]\n",
      " [0.53293388]\n",
      " [1.11674278]] , b =  [0.8607874]\n"
     ]
    }
   ],
   "source": [
    "In = Input_data()\n",
    "x_data = In.get_x_data()\n",
    "t_data = In.get_t_data()\n",
    "obj = LinearRegressionTest(x_data,t_data,1e-5,10001)\n",
    "obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([178.88012771])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100,98,81])\n",
    "obj.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
