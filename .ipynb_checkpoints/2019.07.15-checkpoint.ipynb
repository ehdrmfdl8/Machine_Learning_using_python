{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "W = [[0.55032737]] , W.shape = (1, 1) ,b=  [0.52970604] ,b.shape = (1,)\n",
      "initial error value = 3.714306563586078 Initial W =  [[0.55032737]] \n",
      " , b =  [0.52970604]\n",
      "step = 0 error value =  3.42079745280913 W =  [[0.5687267]] , b =  [0.54773739]\n",
      "step = 0 error value =  2.7332477092241283 W =  [[0.62131907]] , b =  [0.57192988]\n",
      "step = 0 error value =  1.7421117434121094 W =  [[0.71516584]] , b =  [0.59758133]\n",
      "step = 0 error value =  0.8019986737314341 W =  [[0.83850627]] , b =  [0.6185492]\n",
      "step = 0 error value =  0.2510037208675784 W =  [[0.95739821]] , b =  [0.63043839]\n",
      "step = 400 error value =  1.1845628103424737e-09 W =  [[1.0000205]] , b =  [0.99991995]\n",
      "step = 400 error value =  1.1462718305638221e-09 W =  [[1.00002206]] , b =  [0.99992067]\n",
      "step = 400 error value =  1.1559230467261817e-09 W =  [[1.00002285]] , b =  [0.99992088]\n",
      "step = 400 error value =  1.143533161712595e-09 W =  [[1.00002187]] , b =  [0.99992072]\n",
      "step = 400 error value =  1.2404076557244622e-09 W =  [[1.00001886]] , b =  [0.99992042]\n",
      "step = 800 error value =  6.440374729768982e-17 W =  [[1.]] , b =  [0.99999998]\n",
      "step = 800 error value =  6.232189933962151e-17 W =  [[1.00000001]] , b =  [0.99999998]\n",
      "step = 800 error value =  6.284663074424546e-17 W =  [[1.00000001]] , b =  [0.99999998]\n",
      "step = 800 error value =  6.217299768535593e-17 W =  [[1.00000001]] , b =  [0.99999998]\n",
      "step = 800 error value =  6.743998510990479e-17 W =  [[1.]] , b =  [0.99999998]\n",
      "step = 1200 error value =  3.500522580276519e-24 W =  [[1.]] , b =  [1.]\n",
      "step = 1200 error value =  3.3875468912544686e-24 W =  [[1.]] , b =  [1.]\n",
      "step = 1200 error value =  3.41657965469368e-24 W =  [[1.]] , b =  [1.]\n",
      "step = 1200 error value =  3.379349048727412e-24 W =  [[1.]] , b =  [1.]\n",
      "step = 1200 error value =  3.6655340984048896e-24 W =  [[1.]] , b =  [1.]\n",
      "step = 1600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 1600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 1600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 1600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 1600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 2800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 3200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 3200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 3200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 3200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 3200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 3600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 3600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 3600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 3600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 3600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 4800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 5200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 5200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 5200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 5200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 5200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 5600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 5600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 5600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 5600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 5600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6400 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 6800 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 7200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 7200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 7200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 7200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 7200 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 7600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 7600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 7600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 7600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 7600 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 8000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 8000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 8000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 8000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "step = 8000 error value =  2.3665827156630354e-30 W =  [[1.]] , b =  [1.]\n",
      "\n",
      "Time :  0:00:02.083428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([31.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "##################### 미분함수 ####################\n",
    "def numerical_derivative(f,x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x,flags=['multi_index'],op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    return grad\n",
    "##########################################################\n",
    "#####################입력부분#############################\n",
    "#load_data = np.loadtxt('./regression_testdata_03.csv',delimiter=',', dtype = np.float32)\n",
    "x_data = np.array([1,2,3,4,5])\n",
    "t_data = np.array([2,3,4,5,6])\n",
    "print(x_data.ndim,t_data.ndim)\n",
    "W = np.random.rand(1,1)\n",
    "b = np.random.raload_data = np.loadtxt('./regression_testdata_03.csv',delimiter=',', dtype = np.float32)\n",
    "x_data = load_data[:,0:-1]\n",
    "t_data = load_data[:,[-1]]nd(1)\n",
    "print(\"W =\", W,\", W.shape =\", W.shape, \",b= \", b,\",b.shape =\", b.shape)\n",
    "###########################################################\n",
    "def loss_func(x,t):\n",
    "    y = np.dot(x,W) + b\n",
    "    return np.sum((t-y)**2) / len(x)\n",
    "\n",
    "def error_val(x,t):\n",
    "    y = np.dot(x,W) + b\n",
    "    return np.sum((t-y)**2) / len(x)\n",
    "\n",
    "def predict(x):\n",
    "    y = np.dot(x,W) + b\n",
    "    return y\n",
    "\n",
    "learning_rate = 1e-2\n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "print(\"initial error value =\", error_val(x_data.reshape(5,1),t_data.reshape(5,1)),\"Initial W = \", W, \"\\n\",\", b = \", b)\n",
    "start_time = datetime.now()\n",
    "for step in range(8001):\n",
    "    for index in range(len(x_data)): # 행렬로 하지 않고 벡터로 하는경우 시간이 10배정도 더 걸린다.\n",
    "        input_x_data = x_data[index]\n",
    "        input_t_data = t_data[index]\n",
    "        \n",
    "        f = lambda x : loss_func(np.array([input_x_data]), np.array([input_t_data]))  \n",
    "        W -= learning_rate * numerical_derivative(f,W)\n",
    "        b -= learning_rate * numerical_derivative(f,b)\n",
    "\n",
    "        if(step % 400 == 0):\n",
    "            print(\"step =\", step, \"error value = \", error_val(x_data.reshape(5,1),t_data.reshape(5,1)), \"W = \", W,\", b = \",b)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"\")\n",
    "print(\"Time : \",end_time - start_time)\n",
    "test_score = np.array([30])\n",
    "predict(test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([1,2,3,4,5])\n",
    "t_data = np.array([2,3,4,5,6])\n",
    "print(x_data)\n",
    "x = x_data.T\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivative(f,x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x,flags=['multi_index'],op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.ndim =  2 , x_data.shape =  (50, 4)\n",
      "t_data.ndim =  2 , t_data.shape =  (50, 1)\n"
     ]
    }
   ],
   "source": [
    "load_data = np.loadtxt('./regression_testdata_03.csv',delimiter=',', dtype = np.float32)\n",
    "x_data = load_data[:,0:-1]\n",
    "t_data = load_data[:,[-1]]\n",
    "\n",
    "#데이터 차원 및 shape 확인\n",
    "print(\"x_data.ndim = \", x_data.ndim,\", x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.ndim = \", t_data.ndim,\", t_data.shape = \", t_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionTest:\n",
    "    def __init__(self,x_data,t_data,learning_rate,iteration_count):\n",
    "        self.x_data = x_data\n",
    "        self.t_data = t_data\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iteration_count = iteration_count\n",
    "        W = np.random.rand(self.x_data.shape[1],1)\n",
    "        b = np.random.rand(1)\n",
    "        print(\"W =\", W,\", W.shape =\", W.shape, \",b= \", b,\",b.shape =\", b.shape)\n",
    "    def loss_func(self,x,t):\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        y = np.dot(self.x,W) + b\n",
    "        return np.sum((self.t-y)**2) / len(self.x)\n",
    "    def error_val(self,x,t):\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        y = np.dot(self.x,W) + b\n",
    "        return np.sum((self.t-y)**2) / len(self.x)\n",
    "    def predict(self,x):\n",
    "        self.x = x\n",
    "        y = np.dot(self.x,W) + b\n",
    "        return y\n",
    "    def train(self):\n",
    "        f = lambda x : self.loss_func(self.x_data,self.t_data)\n",
    "        print(\"initial error value =\", self.error_val(self.x_data,self.t_data),\"Initial W = \", W, \"\\n\",\", b = \", b)\n",
    "        for step in range(self.iteration_count):\n",
    "            W -= self.learning_rate * numerical_derivative(f,W)\n",
    "            b -= self.learning_rate * numerical_derivative(f,b)\n",
    "            \n",
    "            if(step % 400 == 0):\n",
    "                print(\"step =\", step, \"error value = \", self.error_val(self.x_data,self.t_data), \"W = \", W,\", b = \",b)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [[0.3179132 ]\n",
      " [0.92602089]\n",
      " [0.85686808]\n",
      " [0.33802655]] , W.shape = (4, 1) ,b=  [0.41277385] ,b.shape = (1,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (50,4) and (1,1) not aligned: 4 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-a789cb20842a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLinearRegressionTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1e-5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-e4c635bd0539>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"initial error value =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Initial W = \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\", b = \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteration_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mW\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnumerical_derivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-29faef9cfa69>\u001b[0m in \u001b[0;36merror_val\u001b[1;34m(x, t)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0merror_val\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (50,4) and (1,1) not aligned: 4 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "obj = LinearRegressionTest(x_data,t_data,1e-5,10001)\n",
    "obj.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
