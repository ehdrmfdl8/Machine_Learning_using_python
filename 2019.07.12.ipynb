{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [[0.64119618]\n",
      " [0.87351612]\n",
      " [0.85486251]] , W.shape = (3, 1) ,b=  [0.93162057] ,b.shape = (1,)\n",
      "initial error value = 846.2150008958663 Initial W =  [[0.64119618]\n",
      " [0.87351612]\n",
      " [0.85486251]] \n",
      " , b =  [0.93162057]\n",
      "step = 0 error value =  319.8145160766225 W =  [[0.59497016]\n",
      " [0.82696495]\n",
      " [0.80750262]] , b =  [0.93127175]\n",
      "step = 400 error value =  9.640567608532313 W =  [[0.50616182]\n",
      " [0.71255704]\n",
      " [0.79187079]] , b =  [0.93034092]\n",
      "step = 800 error value =  8.67234108927207 W =  [[0.49083433]\n",
      " [0.67760122]\n",
      " [0.84093154]] , b =  [0.92988677]\n",
      "step = 1200 error value =  7.986647403893759 W =  [[0.47713483]\n",
      " [0.64880189]\n",
      " [0.88239458]] , b =  [0.92937929]\n",
      "step = 1600 error value =  7.500229021709921 W =  [[0.46488078]\n",
      " [0.62511215]\n",
      " [0.91746026]] , b =  [0.92882674]\n",
      "step = 2000 error value =  7.154511465477728 W =  [[0.45391147]\n",
      " [0.60565984]\n",
      " [0.94713695]] , b =  [0.92823604]\n",
      "step = 2400 error value =  6.908258288720025 W =  [[0.4440853 ]\n",
      " [0.58971866]\n",
      " [0.97227196]] , b =  [0.92761304]\n",
      "step = 2800 error value =  6.732416736367433 W =  [[0.43527728]\n",
      " [0.57668408]\n",
      " [0.99357745]] , b =  [0.92696268]\n",
      "step = 3200 error value =  6.606499797293682 W =  [[0.42737695]\n",
      " [0.56605313]\n",
      " [1.01165221]] , b =  [0.92628912]\n",
      "step = 3600 error value =  6.516045940209893 W =  [[0.4202866 ]\n",
      " [0.55740761]\n",
      " [1.02699986]] , b =  [0.92559586]\n",
      "step = 4000 error value =  6.450834912938031 W =  [[0.41391964]\n",
      " [0.55039997]\n",
      " [1.04004413]] , b =  [0.92488589]\n",
      "step = 4400 error value =  6.403634079049729 W =  [[0.40819928]\n",
      " [0.54474157]\n",
      " [1.05114166]] , b =  [0.9241617]\n",
      "step = 4800 error value =  6.369317128626964 W =  [[0.40305736]\n",
      " [0.54019289]\n",
      " [1.06059276]] , b =  [0.92342543]\n",
      "step = 5200 error value =  6.344244225477658 W =  [[0.39843324]\n",
      " [0.53655529]\n",
      " [1.06865044]] , b =  [0.92267886]\n",
      "step = 5600 error value =  6.3258257642671545 W =  [[0.39427301]\n",
      " [0.5336642 ]\n",
      " [1.0755279 ]] , b =  [0.92192353]\n",
      "step = 6000 error value =  6.312215128574399 W =  [[0.39052861]\n",
      " [0.53138339]\n",
      " [1.08140494]] , b =  [0.92116072]\n",
      "step = 6400 error value =  6.302092123053781 W =  [[0.38715722]\n",
      " [0.52960021]\n",
      " [1.08643325]] , b =  [0.92039153]\n",
      "step = 6800 error value =  6.294510173001461 W =  [[0.38412061]\n",
      " [0.52822165]\n",
      " [1.09074087]] , b =  [0.9196169]\n",
      "step = 7200 error value =  6.288788395896477 W =  [[0.38138465]\n",
      " [0.52717095]\n",
      " [1.09443598]] , b =  [0.9188376]\n",
      "step = 7600 error value =  6.284435270537564 W =  [[0.3789188 ]\n",
      " [0.52638492]\n",
      " [1.09760999]] , b =  [0.91805432]\n",
      "step = 8000 error value =  6.281094574258406 W =  [[0.37669577]\n",
      " [0.52581157]\n",
      " [1.10034022]] , b =  [0.91726763]\n",
      "step = 8400 error value =  6.278507027950778 W =  [[0.37469111]\n",
      " [0.52540825]\n",
      " [1.1026921 ]] , b =  [0.91647802]\n",
      "step = 8800 error value =  6.2764830332030455 W =  [[0.37288293]\n",
      " [0.52513999]\n",
      " [1.10472109]] , b =  [0.9156859]\n",
      "step = 9200 error value =  6.27488325184215 W =  [[0.37125158]\n",
      " [0.52497822]\n",
      " [1.10647417]] , b =  [0.91489164]\n",
      "step = 9600 error value =  6.273604738111911 W =  [[0.36977947]\n",
      " [0.52489967]\n",
      " [1.1079912 ]] , b =  [0.91409554]\n",
      "step = 10000 error value =  6.272571008648057 W =  [[0.36845078]\n",
      " [0.5248854 ]\n",
      " [1.10930605]] , b =  [0.91329786]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([179.05093545])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "##################### 미분함수 ####################\n",
    "def numerical_derivative(f,x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x,flags=['multi_index'],op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    return grad\n",
    "##########################################################\n",
    "#####################입력부분#############################\n",
    "load_data = np.loadtxt('./data-01.csv',delimiter=',', dtype = np.float32)\n",
    "x_data = load_data[:,0:-1]\n",
    "t_data = load_data[:,[-1]]\n",
    "\n",
    "W = np.random.rand(x_data.shape[1],1)\n",
    "b = np.random.rand(1)\n",
    "print(\"W =\", W,\", W.shape =\", W.shape, \",b= \", b,\",b.shape =\", b.shape)\n",
    "###########################################################\n",
    "def loss_func(x,t):\n",
    "    y = np.dot(x,W) + b\n",
    "    return np.sum((t-y)**2) / len(x)\n",
    "\n",
    "def error_val(x,t):\n",
    "    y = np.dot(x,W) + b\n",
    "    return np.sum((t-y)**2) / len(x)\n",
    "\n",
    "def pridict(x):\n",
    "    y = np.dot(x,W) + b\n",
    "    return y\n",
    "\n",
    "learning_rate = 1e-5\n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "print(\"initial error value =\", error_val(x_data,t_data),\"Initial W = \", W, \"\\n\",\", b = \", b)\n",
    "for step in range(10001):\n",
    "    W -= learning_rate * numerical_derivative(f,W)\n",
    "    b -= learning_rate * numerical_derivative(f,b)\n",
    "    \n",
    "    if(step % 400 == 0):\n",
    "        print(\"step =\", step, \"error value = \", error_val(x_data,t_data), \"W = \", W,\", b = \",b)\n",
    "test_score = np.array([100,98,81])\n",
    "pridict(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W = [[0.64703314]\n",
      " [0.45234959]\n",
      " [0.8261562 ]\n",
      " [0.11984194]] , W.shape = (4, 1) ,b=  [0.02674058] ,b.shape = (1,)\n",
      "initial error value = 39.814338824355765 Initial W =  [[0.64703314]\n",
      " [0.45234959]\n",
      " [0.8261562 ]\n",
      " [0.11984194]] \n",
      " , b =  [0.02674058]\n",
      "step = 0 error value =  39.57122286631432 W =  [[0.6462369 ]\n",
      " [0.44903492]\n",
      " [0.82481202]\n",
      " [0.11658402]] , b =  [0.0261757]\n",
      "step = 2000 error value =  0.03493475278802152 W =  [[ 0.97854105]\n",
      " [-0.96321931]\n",
      " [ 0.98091086]\n",
      " [-0.9571196 ]] , b =  [-0.09416521]\n",
      "step = 4000 error value =  0.003210059982686655 W =  [[ 1.00756515]\n",
      " [-0.99150706]\n",
      " [ 1.00036356]\n",
      " [-0.99520295]] , b =  [-0.07627766]\n",
      "step = 6000 error value =  0.0020649953047504155 W =  [[ 1.00745198]\n",
      " [-0.99359561]\n",
      " [ 1.00079583]\n",
      " [-0.99760337]] , b =  [-0.06167511]\n",
      "step = 8000 error value =  0.0013527892157248597 W =  [[ 1.00610167]\n",
      " [-0.9948264 ]\n",
      " [ 1.00066129]\n",
      " [-0.99813432]] , b =  [-0.04991568]\n",
      "step = 10000 error value =  0.0008862788101398162 W =  [[ 1.00494239]\n",
      " [-0.99581262]\n",
      " [ 1.00053592]\n",
      " [-0.99849364]] , b =  [-0.04040211]\n",
      "step = 12000 error value =  0.0005806450196464998 W =  [[ 1.00400062]\n",
      " [-0.99661068]\n",
      " [ 1.00043381]\n",
      " [-0.99878092]] , b =  [-0.03270197]\n",
      "step = 14000 error value =  0.00038040922889780025 W =  [[ 1.00323817]\n",
      " [-0.99725664]\n",
      " [ 1.00035113]\n",
      " [-0.99901327]] , b =  [-0.0264694]\n",
      "step = 16000 error value =  0.00024922487324023564 W =  [[ 1.00262101]\n",
      " [-0.99777949]\n",
      " [ 1.00028421]\n",
      " [-0.99920133]] , b =  [-0.02142468]\n",
      "step = 18000 error value =  0.00016327952300538456 W =  [[ 1.00212148]\n",
      " [-0.99820269]\n",
      " [ 1.00023004]\n",
      " [-0.99935355]] , b =  [-0.01734141]\n",
      "step = 20000 error value =  0.00010697247945697368 W =  [[ 1.00171716]\n",
      " [-0.99854523]\n",
      " [ 1.0001862 ]\n",
      " [-0.99947675]] , b =  [-0.01403636]\n",
      "step = 22000 error value =  7.008295437508594e-05 W =  [[ 1.00138989]\n",
      " [-0.99882249]\n",
      " [ 1.00015071]\n",
      " [-0.99957648]] , b =  [-0.01136122]\n",
      "step = 24000 error value =  4.591480461958809e-05 W =  [[ 1.00112499]\n",
      " [-0.99904691]\n",
      " [ 1.00012199]\n",
      " [-0.99965719]] , b =  [-0.00919592]\n",
      "step = 26000 error value =  3.0081056114902322e-05 W =  [[ 1.00091058]\n",
      " [-0.99922856]\n",
      " [ 1.00009874]\n",
      " [-0.99972253]] , b =  [-0.00744329]\n",
      "step = 28000 error value =  1.9707585483266025e-05 W =  [[ 1.00073704]\n",
      " [-0.99937558]\n",
      " [ 1.00007992]\n",
      " [-0.99977541]] , b =  [-0.0060247]\n",
      "step = 30000 error value =  1.2911412554687507e-05 W =  [[ 1.00059657]\n",
      " [-0.99949459]\n",
      " [ 1.00006469]\n",
      " [-0.99981821]] , b =  [-0.00487647]\n",
      "step = 32000 error value =  8.458904024486862e-06 W =  [[ 1.00048287]\n",
      " [-0.99959091]\n",
      " [ 1.00005236]\n",
      " [-0.99985286]] , b =  [-0.00394708]\n",
      "step = 34000 error value =  5.54184578894186e-06 W =  [[ 1.00039084]\n",
      " [-0.99966888]\n",
      " [ 1.00004238]\n",
      " [-0.9998809 ]] , b =  [-0.00319482]\n",
      "step = 36000 error value =  3.6307368731797553e-06 W =  [[ 1.00031635]\n",
      " [-0.99973199]\n",
      " [ 1.0000343 ]\n",
      " [-0.9999036 ]] , b =  [-0.00258593]\n",
      "step = 38000 error value =  2.3786750379406074e-06 W =  [[ 1.00025606]\n",
      " [-0.99978307]\n",
      " [ 1.00002777]\n",
      " [-0.99992197]] , b =  [-0.00209308]\n",
      "step = 40000 error value =  1.5583874937124079e-06 W =  [[ 1.00020726]\n",
      " [-0.99982441]\n",
      " [ 1.00002247]\n",
      " [-0.99993684]] , b =  [-0.00169417]\n",
      "step = 42000 error value =  1.0209766116944686e-06 W =  [[ 1.00016776]\n",
      " [-0.99985788]\n",
      " [ 1.00001819]\n",
      " [-0.99994888]] , b =  [-0.00137128]\n",
      "step = 44000 error value =  6.688922016070249e-07 W =  [[ 1.00013578]\n",
      " [-0.99988496]\n",
      " [ 1.00001472]\n",
      " [-0.99995862]] , b =  [-0.00110993]\n",
      "step = 46000 error value =  4.3822431605861913e-07 W =  [[ 1.00010991]\n",
      " [-0.99990689]\n",
      " [ 1.00001192]\n",
      " [-0.99996651]] , b =  [-0.00089839]\n",
      "step = 48000 error value =  2.871023921695923e-07 W =  [[ 1.00008896]\n",
      " [-0.99992463]\n",
      " [ 1.00000965]\n",
      " [-0.99997289]] , b =  [-0.00072717]\n",
      "step = 50000 error value =  1.8809495632456663e-07 W =  [[ 1.000072  ]\n",
      " [-0.999939  ]\n",
      " [ 1.00000781]\n",
      " [-0.99997806]] , b =  [-0.00058858]\n",
      "\n",
      "Time :  0:00:05.673469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([53.0138808])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "##################### 미분함수 ####################\n",
    "def numerical_derivative(f,x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    it = np.nditer(x,flags=['multi_index'],op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "    return grad\n",
    "##########################################################\n",
    "#####################입력부분#############################\n",
    "load_data = np.loadtxt('./regression_testdata_03.csv',delimiter=',', dtype = np.float32)\n",
    "x_data = load_data[:,0:-1]\n",
    "t_data = load_data[:,[-1]]\n",
    "\n",
    "W = np.random.rand(x_data.shape[1],1)\n",
    "b = np.random.rand(1)\n",
    "print(\"W =\", W,\", W.shape =\", W.shape, \",b= \", b,\",b.shape =\", b.shape)\n",
    "###########################################################\n",
    "def loss_func(x,t):\n",
    "    y = np.dot(x,W) + b\n",
    "    return np.sum((t-y)**2) / len(x)\n",
    "\n",
    "def error_val(x,t):\n",
    "    y = np.dot(x,W) + b\n",
    "    return np.sum((t-y)**2) / len(x)\n",
    "\n",
    "def predict(x):\n",
    "    y = np.dot(x,W) + b\n",
    "    return y\n",
    "\n",
    "learning_rate = 1e-4\n",
    "f = lambda x : loss_func(x_data,t_data)\n",
    "print(\"initial error value =\", error_val(x_data,t_data),\"Initial W = \", W, \"\\n\",\", b = \", b)\n",
    "start_time = datetime.now()\n",
    "for step in range(10001):\n",
    "    W -= learning_rate * numerical_derivative(f,W)\n",
    "    b -= learning_rate * numerical_derivative(f,b)\n",
    "    \n",
    "    if(step % 2000 == 0):\n",
    "        print(\"step =\", step, \"error value = \", error_val(x_data,t_data), \"W = \", W,\", b = \",b)\n",
    "\n",
    "end_time = datetime.now()\n",
    "print(\"\")\n",
    "print(\"Time : \",end_time - start_time)\n",
    "test_score = np.array([100,98,81,30])\n",
    "predict(test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value =  [-0.00409646]\n"
     ]
    }
   ],
   "source": [
    "ex_data_01 = np.array([4,4,4,4])\n",
    "print(\"predicted value = \",predict(ex_data_01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted value =  [5.00055411]\n"
     ]
    }
   ],
   "source": [
    "ex_data_02 = np.array([5,2,4,2])\n",
    "print(\"predicted value = \",predict(ex_data_02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
